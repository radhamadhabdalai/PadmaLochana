{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2004 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b825fc55",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.15 Diﬀerent amortization strategies for Sylvester normalizing ﬂows and inverse autore- gressive ﬂows (a) Our inference network produces amortized ﬂow parameters. This strategy is also employed by planar ﬂows. (b) Inverse autoregressive ﬂow [18] introduces a measure of .x dependence through a context variable .h(x). This context acts as an additional input for each transformation. The ﬂow parameters themselves are independent of .x.\n",
    "\n",
    "## Amortizing Flow Parameters\n",
    "\n",
    "When using normalizing flows in an amortized inference setting, the parameters of the base distribution as well as the flow parameters can be functions of the data point $ \\mathbf{x} $ [19]. Figure 5.15 (left) shows a diagram of one Sylvester Normalizing Flow (SNF) step and the amortization procedure.\n",
    "\n",
    "The inference network takes datapoints $ \\mathbf{x} $ as input and provides as an output the mean and variance of $ \\mathbf{z}^{(0)} $, such that $ \\mathbf{z}^{(0)} \\sim \\mathcal{N}(\\mathbf{z} | \\mu_0, \\sigma_0) $. Several SNF transformations are then applied to $ \\mathbf{z}^{(0)} \\rightarrow \\mathbf{z}^{(1)} \\rightarrow \\dots \\rightarrow \\mathbf{z}^{(T)} $, producing a flexible posterior distribution for $ \\mathbf{z}^{(T)} $. \n",
    "\n",
    "All of the flow parameters $ (\\mathbf{R}, \\mathbf{R}^\\sim, \\mathbf{Q}) $ for each transformation are produced as an output by the inference network and are thus fully amortized.\n",
    "\n",
    "### Different Amortization Strategies\n",
    "1. **Amortized Flow Parameters (SNF)**: Our inference network produces amortized flow parameters. This strategy is also employed by planar flows.\n",
    "2. **Inverse Autoregressive Flow (IAF)**: The inverse autoregressive flow [18] introduces a measure of $ \\mathbf{x} $-dependence through a context variable $ h(\\mathbf{x}) $. This context acts as an additional input for each transformation, and the flow parameters themselves are independent of $ \\mathbf{x} $.\n",
    "\n",
    "---\n",
    "\n",
    "## Hyperspherical Latent Space\n",
    "\n",
    "### Motivation\n",
    "\n",
    "In the VAE framework, choosing Gaussian priors and Gaussian posteriors for mathematical convenience leads to a Euclidean latent space. However, this choice could be limiting for the following reasons:\n",
    "\n",
    "- **Low-Dimensional Issues**: In low dimensions, the standard Gaussian probability presents a concentrated probability mass around the mean, encouraging points to cluster at the center. This becomes problematic when the data is divided into multiple clusters. A better-suited prior would be uniform, but this is not well-defined on the hyperplane.\n",
    "- **High-Dimensional Issues**: The standard Gaussian distribution in high dimensions tends to resemble a uniform distribution on the surface of a hypersphere, with the majority of its mass concentrated on the hyperspherical shell (the \"soap bubble\" effect).\n",
    "\n",
    "A natural question is whether it would be better to use a distribution defined on the hypersphere. One such distribution that solves both problems is the **von-Mises-Fisher (vMF)** distribution.\n",
    "\n",
    "### von-Mises-Fisher Distribution\n",
    "\n",
    "The von-Mises-Fisher (vMF) distribution is often described as the Gaussian distribution on a hypersphere. Analogous to a Gaussian, it is parameterized by $ \\mu $ (mean direction) and $ \\kappa \\in \\mathbb{R}, \\mu \\in \\mathbb{R}^{\\geq 0} $. For the special case of $ \\kappa = 0 $, the vMF represents a uniform distribution.\n",
    "\n",
    "The probability density function of the vMF distribution for a random unit vector $ \\mathbf{z} \\in \\mathbb{R}^m $ (or $ \\mathbf{z} \\in S^{m-1} $) is:\n",
    "\n",
    "$$\n",
    "q(\\mathbf{z} | \\mu, \\kappa) = C_m (\\kappa) \\exp \\left( \\kappa \\mu^T \\mathbf{z} \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "C_m (\\kappa) = \\frac{\\kappa^{\\frac{m}{2} - 1}}{(2\\pi)^{\\frac{m}{2}} I_{\\frac{m}{2}-1} (\\kappa)}\n",
    "$$\n",
    "\n",
    "Here, $ I_v(\\kappa) $ is the modified Bessel function of the first kind at order $ v $, and $ \\| \\mu \\|_2 = 1 $.\n",
    "\n",
    "Interestingly, since we define a distribution over a hypersphere, it is possible to formulate a uniform prior over the hypersphere. Using the vMF distribution as the variational posterior, the Kullback-Leibler (KL) divergence between the vMF distribution and the uniform distribution over $ S^{m-1} $ can be calculated analytically as:\n",
    "\n",
    "$$\n",
    "KL[vMF(\\mu, \\kappa) || Unif(S^{m-1})] = \\frac{1}{2} \\kappa + \\log C_m (\\kappa) - \\log \\Gamma\\left( \\frac{m}{2} \\right)\n",
    "$$\n",
    "\n",
    "### Sampling from vMF\n",
    "\n",
    "Sampling from the von-Mises-Fisher distribution requires the acceptance-rejection sampling procedure. The reparameterization trick can be extended to distributions that can be simulated via rejection sampling, as shown in [62].\n",
    "\n",
    "This allows the creation of a **Hyperspherical VAE** that can efficiently model latent space on the hypersphere, making it more appropriate for complex, multi-modal data distributions.\n",
    "\n",
    "For further details and the reparameterization trick, refer to [33] and [62].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0768bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class InferenceNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, flow_dim):\n",
    "        super(InferenceNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc_mu = nn.Linear(64, flow_dim)  # Mean for z(0)\n",
    "        self.fc_sigma = nn.Linear(64, flow_dim)  # Variance for z(0)\n",
    "        self.fc_R = nn.Linear(64, flow_dim)  # Flow parameter R\n",
    "        self.fc_Q = nn.Linear(64, flow_dim)  # Flow parameter Q\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        sigma = self.fc_sigma(x)\n",
    "        R = self.fc_R(x)\n",
    "        Q = self.fc_Q(x)\n",
    "        return mu, sigma, R, Q\n",
    "def snf_flow(z, R, Q, h, num_steps=5):\n",
    "    \"\"\"\n",
    "    Applies Sylvester normalizing flow (SNF) to the latent vector z\n",
    "    using flow parameters R, Q, and a function h (activation).\n",
    "    \"\"\"\n",
    "    for _ in range(num_steps):\n",
    "        Rz = torch.matmul(R, z)  # R * z(t-1)\n",
    "        h_Rz = h(Rz)  # Apply activation\n",
    "        z = z + torch.matmul(Q, h_Rz)  # z(t) = z(t-1) + Q * h(R * z(t-1))\n",
    "    return z\n",
    "import math\n",
    "import torch\n",
    "from torch.distributions import Distribution\n",
    "\n",
    "class vonMisesFisher(Distribution):\n",
    "    def __init__(self, mu, kappa):\n",
    "        self.mu = mu  # Mean direction (normalized)\n",
    "        self.kappa = kappa  # Concentration parameter\n",
    "        self.dim = mu.size(0)  # Dimensionality of the latent space\n",
    "\n",
    "    def log_prob(self, z):\n",
    "        \"\"\"\n",
    "        Compute the log probability of a point z under the vMF distribution.\n",
    "        \"\"\"\n",
    "        dot_product = torch.matmul(self.mu, z)\n",
    "        normalization_constant = self._log_normalizing_constant(self.kappa)\n",
    "        return self.kappa * dot_product - normalization_constant\n",
    "\n",
    "    def _log_normalizing_constant(self, kappa):\n",
    "        \"\"\"\n",
    "        Compute the log normalizing constant of the vMF distribution.\n",
    "        \"\"\"\n",
    "        return (self.dim / 2 - 1) * torch.log(kappa) - self._log_bessel(self.dim / 2 - 1, kappa)\n",
    "\n",
    "    def _log_bessel(self, v, kappa):\n",
    "        \"\"\"\n",
    "        Compute the log Bessel function for the given order v and parameter kappa.\n",
    "        \"\"\"\n",
    "        # Use an approximation or numerical implementation of the Bessel function\n",
    "        return torch.log(torch.i0(kappa))\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Sample from the von-Mises-Fisher distribution using rejection sampling.\n",
    "        \"\"\"\n",
    "        # Implement the acceptance-rejection procedure for sampling from vMF\n",
    "        pass\n",
    "class HypersphericalVAE(nn.Module):\n",
    "    def __init__(self, input_dim, flow_dim):\n",
    "        super(HypersphericalVAE, self).__init__()\n",
    "        self.inference_network = InferenceNetwork(input_dim, flow_dim)\n",
    "        self.z0_dim = flow_dim  # Dimensionality of the latent variable\n",
    "        self.flow = snf_flow\n",
    "        self.mu_prior = torch.zeros(flow_dim)  # Prior mean (centered at origin)\n",
    "        self.kappa_prior = 1.0  # Prior concentration\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode input x into the parameters for the prior distribution and flow.\n",
    "        \"\"\"\n",
    "        mu, sigma, R, Q = self.inference_network(x)\n",
    "        return mu, sigma, R, Q\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decode latent variable z back into the original space (e.g., reconstruction).\n",
    "        \"\"\"\n",
    "        # Implement decoder network if needed (not shown here)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform forward pass: encoding, SNF flow, and decoding.\n",
    "        \"\"\"\n",
    "        mu, sigma, R, Q = self.encode(x)\n",
    "        z = mu + sigma * torch.randn_like(mu)  # Sampling from N(mu, sigma)\n",
    "        z_transformed = self.flow(z, R, Q, torch.relu)\n",
    "        return self.decode(z_transformed)\n",
    "\n",
    "    def loss_function(self, x, z):\n",
    "        \"\"\"\n",
    "        Compute the loss function, which includes KL divergence and reconstruction loss.\n",
    "        \"\"\"\n",
    "        # Prior distribution (vMF)\n",
    "        vMF_dist = vonMisesFisher(self.mu_prior, self.kappa_prior)\n",
    "        log_p_z = vMF_dist.log_prob(z)\n",
    "\n",
    "        # Likelihood of data given z (reconstruction term)\n",
    "        # Use reconstruction loss (e.g., MSE, CrossEntropy, depending on data)\n",
    "        reconstruction_loss = torch.mean((x - self.decode(z)) ** 2)\n",
    "\n",
    "        # Total loss = reconstruction loss + KL divergence\n",
    "        return reconstruction_loss - torch.mean(log_p_z)\n",
    "\n",
    "# Example training loop\n",
    "input_dim = 20  # Example input dimension\n",
    "flow_dim = 10   # Latent dimension\n",
    "vae = HypersphericalVAE(input_dim, flow_dim)\n",
    "\n",
    "# Example optimizer\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# Dummy input data\n",
    "x_data = torch.randn(64, input_dim)  # Batch of 64 samples, each of dimension input_dim\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    z = vae(x_data)  # Forward pass\n",
    "    loss = vae.loss_function(x_data, z)  # Calculate loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8ad64279",
   "metadata": {},
   "source": [
    "## Hierarchical Latent Variable Models\n",
    "\n",
    "###  Introduction\n",
    "\n",
    "The main goal of AI is to formulate and implement systems that can interact with an environment, process, store, and transmit information. In other words, we wish an AI system understands the world around it by identifying and disentangling hidden factors in the observed low sensory data [63]. If we think about the problem of building such a system, we can formulate it as learning a probabilistic model, i.e., a joint distribution over observed data, $\\mathbf{x}$, and hidden factors, $\\mathbf{z}$, namely, $p(\\mathbf{x}, \\mathbf{z})$. Then learning a useful representation is equivalent to finding a posterior distribution over the hidden factors, $p(\\mathbf{z} | \\mathbf{x})$. However, it is rather unclear what we really mean by \"useful\" in this context. In a beautiful blog post [64], Ferenc Huszar outlines why learning a latent variable model by maximizing the likelihood function is not necessarily useful from the representation learning perspective. Here, we will use it as a good starting point for a discussion of why applying hierarchical latent variable models could be beneficial. \n",
    "\n",
    "Let us start by defining the setup. We assume the empirical distribution $p_{\\text{data}}(\\mathbf{x})$ and a latent variable model $p_{\\theta}(\\mathbf{x}, \\mathbf{z})$. The way we parameterize the latent variable model is not constrained in any manner; however, we assume that the distribution is parameterized using deep neural networks (DNNs). This is important for two reasons: \n",
    "\n",
    "1. DNNs are nonlinear transformations, and as such, they are flexible and allow parameterizing a wide range of distributions. \n",
    "2. We must remember that DNNs will not solve all problems for us! In the end, we need to think about the model as a whole, not only about the parameterization. What I mean by that is the distribution we choose and how random variables interact, etc. DNNs are definitely helpful, but there are many potential pitfalls (we will discuss some of them later on) that even the largest and coolest DNN is unable to take care of.\n",
    "\n",
    "It is worth remembering that the joint distribution could be factorized in two ways, namely:\n",
    "\n",
    "$$\n",
    "p_{\\theta}(\\mathbf{x}, \\mathbf{z}) = p_{\\theta}(\\mathbf{x} | \\mathbf{z}) p_{\\theta}(\\mathbf{z}) \\tag{5.69}\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$\n",
    "p_{\\theta}(\\mathbf{x}, \\mathbf{z}) = p_{\\theta}(\\mathbf{z} | \\mathbf{x}) p_{\\theta}(\\mathbf{x}) \\tag{5.70}\n",
    "$$\n",
    "\n",
    "Moreover, the training problem of learning $\\theta$ could be defined as an unconstrained optimization problem with the following training objective:\n",
    "\n",
    "$$\n",
    "\\text{KL}[p_{\\text{data}}(\\mathbf{x}) \\| p_{\\theta}(\\mathbf{x})] = -H[p_{\\text{data}}(\\mathbf{x})] + \\text{CE}[p_{\\text{data}}(\\mathbf{x}) \\| p_{\\theta}(\\mathbf{x})] \\tag{5.71}\n",
    "$$\n",
    "\n",
    "which simplifies to:\n",
    "\n",
    "$$\n",
    "\\text{KL}[p_{\\text{data}}(\\mathbf{x}) \\| p_{\\theta}(\\mathbf{x})] = \\text{const} + \\text{CE}[p_{\\text{data}}(\\mathbf{x}) \\| p_{\\theta}(\\mathbf{x})] \\tag{5.72}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "p_{\\theta}(\\mathbf{x}) = \\int p_{\\theta}(\\mathbf{x}, \\mathbf{z}) \\, d\\mathbf{z}\n",
    "$$\n",
    "\n",
    "$H[\\cdot]$ denotes the entropy and $\\text{CE}[\\cdot || \\cdot]$ is the cross-entropy. Notice that the entropy of the empirical distribution is simply a constant, since it does not contain $\\theta$. The cross-entropy could be further rewritten as follows:\n",
    "\n",
    "$$\n",
    "\\text{CE}[p_{\\text{data}}(\\mathbf{x}) \\| p_{\\theta}(\\mathbf{x})] = - \\int p_{\\text{data}}(\\mathbf{x}) \\ln p_{\\theta}(\\mathbf{x}) \\, d\\mathbf{x} \\tag{5.73}\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{n=1}^{N} - \\ln p_{\\theta}(\\mathbf{x}_n) \\tag{5.74}\n",
    "$$\n",
    "\n",
    "Eventually, we obtained the objective function we use all the time, namely, the negative log-likelihood function. If we think of the usefulness of a representation (i.e., hidden factors) $\\mathbf{z}$, we intuitively think of some kind of information that is shared between $\\mathbf{z}$ and $\\mathbf{x}$. However, the unconstrained training problem we consider, i.e., the minimization of the negative log-likelihood function, does not necessarily say anything about the latent representation. In the end, we optimize the marginal over observable variables, because we do not have access to values of latent variables. Even more, typically we do not know what these hidden factors are or should be! As a result, our latent variable model can learn to disregard the latent variables completely.\n",
    "\n",
    "### A Potential Problem with Latent Variable Models\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.16 A schematic diagram representing a dependency between usefulness and the objective function for all possible latent variable models. The darker the color, the better the objective function value. (Reproduced based on [64]).\n",
    "\n",
    "\n",
    "Following the discussion presented in [64], we can visualize two scenarios that are pretty common in deep generative modeling with latent variable models. Before delving into that, it is beneficial to explain the general picture. We are interested in analyzing a class of latent variable models with respect to the usefulness of latents and the value of the objective function $\\text{KL}[p_{\\text{data}}(\\mathbf{x}) \\| p_{\\theta}(\\mathbf{x})]$. In Fig.16, we depict a case when all models are possible, namely, a search space where models are evaluated according to the training objective (x-axis) and usefulness (y-axis). The ideal model is the one in the top left corner that maximizes both criteria. However, it is possible to find a model that completely disregards the latents (the bottom left corner).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the Encoder network\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc21 = nn.Linear(512, latent_dim)  # Mean of latent space\n",
    "        self.fc22 = nn.Linear(512, latent_dim)  # Log variance of latent space\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = torch.relu(self.fc1(x))\n",
    "        mu = self.fc21(h1)\n",
    "        logvar = self.fc22(h1)\n",
    "        return mu, logvar\n",
    "\n",
    "# Define the Decoder network\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc3 = nn.Linear(latent_dim, 512)\n",
    "        self.fc4 = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h3 = torch.relu(self.fc3(z))\n",
    "        x_recon = torch.sigmoid(self.fc4(h3))  # Sigmoid to ensure outputs are between 0 and 1\n",
    "        return x_recon\n",
    "\n",
    "# Define the VAE class which integrates the encoder and decoder\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x.view(-1, 784))  # Flatten 28x28 input image\n",
    "        std = torch.exp(0.5 * logvar)  # Standard deviation (for sampling)\n",
    "        eps = torch.randn_like(std)  # Sample from the unit Gaussian\n",
    "        z = mu + eps * std  # Reparameterization trick\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "# Define the loss function (Reconstruction loss + KL Divergence)\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    # KL Divergence\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # where sigma = exp(logvar / 2)\n",
    "    # Reference: Kingma & Welling, ICLR 2014 (VAE)\n",
    "    # KL Divergence between the approximate posterior q(z|x) and the prior p(z)\n",
    "    # for each element in the mini-batch:\n",
    "    #   KL[q(z|x) || p(z)] = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # where sigma^2 = exp(logvar)\n",
    "    MSE = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + MSE\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize VAE model and optimizer\n",
    "model = VAE(input_dim=784, latent_dim=20)  # 28x28 images, latent dimension 20\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
    "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
    "    \n",
    "    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "\n",
    "# Visualize some of the reconstructed images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    data, _ = next(iter(train_loader))\n",
    "    recon_batch, _, _ = model(data)\n",
    "    n = min(data.size(0), 8)\n",
    "    comparison = torch.cat([data[:n],\n",
    "                           recon_batch.view(128, 1, 28, 28)[:n]])\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.imshow(comparison.numpy().reshape(2, n, 28, 28).transpose(0, 2, 1).reshape(28, -1), cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Activation functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# Loss functions\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-10  # To prevent log(0)\n",
    "    return -np.mean(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))\n",
    "\n",
    "# Define the Encoder network (fully connected layers)\n",
    "class Encoder:\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Initialize weights for the encoder\n",
    "        self.W1 = np.random.randn(input_dim, 512) * 0.01\n",
    "        self.b1 = np.zeros(512)\n",
    "        self.W2 = np.random.randn(512, latent_dim) * 0.01\n",
    "        self.b2 = np.zeros(latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = relu(np.dot(x, self.W1) + self.b1)\n",
    "        mu = np.dot(h1, self.W2) + self.b2\n",
    "        logvar = np.dot(h1, self.W2) + self.b2\n",
    "        return mu, logvar\n",
    "\n",
    "# Define the Decoder network (fully connected layers)\n",
    "class Decoder:\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Initialize weights for the decoder\n",
    "        self.W3 = np.random.randn(latent_dim, 512) * 0.01\n",
    "        self.b3 = np.zeros(512)\n",
    "        self.W4 = np.random.randn(512, output_dim) * 0.01\n",
    "        self.b4 = np.zeros(output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h3 = relu(np.dot(z, self.W3) + self.b3)\n",
    "        x_recon = sigmoid(np.dot(h3, self.W4) + self.b4)\n",
    "        return x_recon\n",
    "\n",
    "# Define the VAE model that uses both encoder and decoder\n",
    "class VAE:\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        self.encoder = Encoder(input_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder.forward(x)\n",
    "        std = np.exp(0.5 * logvar)  # Standard deviation (for sampling)\n",
    "        eps = np.random.randn(*std.shape)  # Sample from unit Gaussian\n",
    "        z = mu + eps * std  # Reparameterization trick\n",
    "        x_recon = self.decoder.forward(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "# Simple training loop (using gradient descent)\n",
    "def train_vae(model, X_train, learning_rate=0.001, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x in X_train:\n",
    "            # Forward pass\n",
    "            recon_x, mu, logvar = model.forward(x)\n",
    "            \n",
    "            # Compute the loss: Reconstruction + KL Divergence\n",
    "            recon_loss = binary_cross_entropy(x, recon_x)\n",
    "            kl_loss = -0.5 * np.sum(1 + logvar - mu**2 - np.exp(logvar))  # KL divergence\n",
    "            loss = recon_loss + kl_loss\n",
    "            \n",
    "            # Backpropagation (Gradient Descent)\n",
    "            # For simplicity, we update weights directly (not optimized)\n",
    "            model.encoder.W1 -= learning_rate * recon_loss  # Dummy update\n",
    "            model.encoder.W2 -= learning_rate * kl_loss  # Dummy update\n",
    "            model.decoder.W3 -= learning_rate * recon_loss  # Dummy update\n",
    "            model.decoder.W4 -= learning_rate * kl_loss  # Dummy update\n",
    "\n",
    "            total_loss += loss\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(X_train)}')\n",
    "\n",
    "# Load images (for example MNIST)\n",
    "def load_images(image_folder, size=(28, 28)):\n",
    "    images = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(image_folder, filename)\n",
    "            img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "            img = img.resize(size)  # Resize to 28x28\n",
    "            img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img_array.flatten())  # Flatten to 1D vector\n",
    "    return np.array(images)\n",
    "\n",
    "# Example: Load a folder with MNIST-like images\n",
    "X_train = load_images('')  # Update with the actual folder\n",
    "\n",
    "# Initialize VAE model\n",
    "vae_model = VAE(input_dim=784, latent_dim=20)  # 28x28 image input, 20 latent dimensions\n",
    "\n",
    "# Train the model\n",
    "train_vae(vae_model, X_train, epochs=10)\n",
    "\n",
    "# Visualize some of the images and reconstructions\n",
    "def visualize_images(original, reconstruction, n=8):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    comparison = np.concatenate([original[:n].reshape(n, 28, 28), \n",
    "                                reconstruction[:n].reshape(n, 28, 28)], axis=1)\n",
    "    plt.imshow(comparison, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example: Visualize the first 8 original vs reconstructed images\n",
    "recon_images, _, _ = vae_model.forward(X_train)\n",
    "visualize_images(X_train, recon_images)\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1e384d95",
   "metadata": {},
   "source": [
    "# Understanding Latent Variable Models and Their Usefulness\n",
    "\n",
    "## The Challenge of Latent Variable Models\n",
    "\n",
    "A potential issue with latent variable models is that they may lead to infinitely many models with equivalent values for the objective function but with completely different posterior distributions over latents. This is shown in **Fig. 5.16**, which demonstrates the relationship between the usefulness of latent variables and the objective function for all possible latent variable models. The darker the color, the better the objective function value.\n",
    "\n",
    "### Problem of Ambiguity in Latent Representations\n",
    "Running a numerical optimization procedure could lead to many models that are equally good with respect to \\( \\text{KL}[p_{\\text{data}}(x) \\parallel p_{\\theta}(x)] \\) but result in different posterior distributions over the latent variables. This ambiguity questions the applicability of latent variable models.\n",
    "\n",
    "### The Role of Inductive Bias\n",
    "Despite these issues, latent variables in practice often still provide useful information about observables. As pointed out by [64], the reason for this is the **inductive bias** of the chosen model class. By selecting a very specific class of deep neural networks (DNNs), we implicitly constrain the search space, thus making latent variables useful.\n",
    "\n",
    "- The models depicted on the left of **Fig. 5.16** are often unattainable.\n",
    "- Using bottlenecks in our model class could force the latent variables to contain meaningful information about the observable data.\n",
    "\n",
    "### Schematic Diagram: Dependency Between Usefulness and Objective Function\n",
    "In **Fig. 5.17**, we can see a scenario after running a training algorithm. This scenario highlights the two possible \"spikes\" where the training objective is highest and usefulness is non-zero. However, we could end up with two different models that achieve the same objective but differ in terms of the usefulness of their latent variables.\n",
    "\n",
    "### The Danger of Too Flexible Models\n",
    "When the conditional likelihood \\( p(x|z) \\) is parameterized by a very flexible and large DNN, the model might disregard the latent variables \\( z \\) entirely, treating them as noise. This results in the distribution \\( p(x|z) \\) becoming almost identical to the unconditional distribution \\( p_{\\text{data}}(x) \\). Though this might seem unrealistic at first glance, this phenomenon has been observed in practice. \n",
    "\n",
    "For instance, in [10], it was found that using a PixelCNN++-based decoder in a VAE could cause the model to fail at reconstructing images. The model ended up in the bottom left corner of **Fig. 5.18**, where the latent variables no longer provide any useful information.\n",
    "\n",
    "## How to Define a Proper Class of Models?\n",
    "\n",
    "Choosing the right class of models is crucial for learning useful latent representations. This process might seem difficult because it feels like randomly experimenting with various DNN architectures in hopes of obtaining meaningful representations.\n",
    "\n",
    "Fortunately, there are strategies to tackle this issue:\n",
    "1. **Constrained optimization problems** have been proposed, where the optimization process is designed to ensure that latent variables contain useful information.\n",
    "2. **Auxiliary regularizers** can be added to the loss function to implicitly guide the usefulness of the latent variables.\n",
    "\n",
    "### The Role of Hierarchical Models\n",
    "Hierarchical models have a long-standing history in generative modeling and deep learning. The hypothesis behind hierarchical models is that the world around us can be described in a hierarchical manner, with different levels of abstraction. A hierarchical structure in a latent variable model could impose an inductive bias, constraining the model class and ensuring that latent variables contain useful information.\n",
    "\n",
    "In the next sections, we will explore **hierarchical variational autoencoders** (VAE), which are one approach to achieving useful latent representations.\n",
    "\n",
    "### A Side Note: Hierarchical Models vs. Bayesian Hierarchical Models\n",
    "It’s important to distinguish between **hierarchical models** in deep learning and **Bayesian hierarchical models**:\n",
    "- **Bayesian hierarchical modeling** involves treating parameters as random variables and defining distributions over those parameters.\n",
    "- In the case of **hierarchical latent variable models**, we focus on defining a hierarchy among the latent variables themselves, not the parameters.\n",
    "\n",
    "## Figures\n",
    "\n",
    "- **Fig.16**: A schematic diagram representing a dependency between usefulness and the objective function for all possible latent variable models.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.17 A schematic diagram representing a dependency between usefulness and the objective function for a constrained class of models. The darker the color, the better the objective function value. (Reproduced based on [64]).\n",
    "\n",
    "- **Fig.17**: A schematic diagram representing the dependency between usefulness and the objective function for a constrained class of models.\n",
    "![image-2.png](attachment:image-2.png)\n",
    "- Fig.18 A schematic diagram representing a dependency between usefulness and the objective function for a class of models with ﬂexible . p(x|z). The darker the color, the better the objective function value. (Reproduced based on [64]).\n",
    "\n",
    "**Fig.18**: A schematic diagram representing the dependency between usefulness and the objective function for a class of models with flexible $p(x|z) $.\n",
    "\n",
    "## Hierarchical VAEs\n",
    "\n",
    "##  Two-Level VAEs\n",
    "\n",
    "Let's start by considering a VAE with two latent variables: $ z_1 $ and $ z_2 $. The joint distribution can be factorized as follows:\n",
    "\n",
    "$$ p(x, z_1, z_2) = p(x|z_1)p(z_1|z_2)p(z_2). \\tag{5.75} $$\n",
    "\n",
    "This model defines a straightforward generative process: \n",
    "1. First, sample $ z_2 $.\n",
    "2. Then, sample $ z_1 $ given $ z_2 $.\n",
    "3. Finally, sample $ x $ given $ z_1 $.\n",
    "\n",
    "Since we know that calculating posteriors over latents is intractable for a single latent variable (except in the linear Gaussian case), we can use **variational inference** with a family of variational posteriors $ Q(z_1, z_2 | x) $. Now, the key part is how to define the variational posteriors.\n",
    "\n",
    "A natural approach would be to reverse the dependencies and factorize the posterior as:\n",
    "\n",
    "$$ Q(z_1, z_2 | x) = q(z_1 | x)q(z_2 | z_1, x). \\tag{5.76} $$\n",
    "\n",
    "Alternatively, we can simplify it by dropping the dependency on $ x $ for the second latent variable:\n",
    "\n",
    "$$ Q(z_1, z_2 | x) = q(z_1 | x)q(z_2 | z_1). \\tag{5.77} $$\n",
    "\n",
    "For continuous latents, we can use Gaussian distributions:\n",
    "\n",
    "$$ p(z_1 | z_2) = \\mathcal{N}(z_1 | \\mu(z_2), \\sigma^2(z_2)), \\tag{5.78} $$\n",
    "\n",
    "$$ p(z_2) = \\mathcal{N}(z_2 | 0, 1), \\tag{5.79} $$\n",
    "\n",
    "$$ q(z_1 | x) = \\mathcal{N}(z_1 | \\mu(x), \\sigma^2(x)), \\tag{5.80} $$\n",
    "\n",
    "$$ q(z_2 | z_1) = \\mathcal{N}(z_2 | \\mu(z_1), \\sigma^2(z_1)). \\tag{5.81} $$\n",
    "\n",
    "In these equations, $ \\mu_i(v) $ represents the mean parameter, which is parameterized by a neural network that takes a random variable $ v $ as input. Similarly, the variances (i.e., diagonal covariance matrices) are parameterized in the same manner.\n",
    "\n",
    "As shown in **Fig. 5.19**, this is a straightforward extension of the standard VAE. The two-level VAE is illustrated in the figure, with the generative part and the variational part clearly depicted.\n",
    "\n",
    "### A Potential Pitfall\n",
    "\n",
    "So, are we done? Have we created a better class of VAEs? Unfortunately, the answer is no. The two-level VAE is essentially just a straightforward extension of the one-level VAE. Therefore, the same issues with latent variable models still apply.\n",
    "\n",
    "Looking at the **ELBO** (Evidence Lower Bound) for the two-level VAE, we notice the following:\n",
    "\n",
    "$$ \\mathbb{E}_{Q(z_1, z_2 | x)} \\left[ \\ln p(x|z_1) - \\ln p(z_1|z_2) - \\text{KL}[q(z_2|z_1) || p(z_2)] \\right]. \\tag{5.82} $$\n",
    "\n",
    "To gain some insight into the ELBO for the two-level VAE:\n",
    "1. All conditions $ (z_1, z_2, x) $ are either samples from $ Q(z_1, z_2 | x) $ or $ p_{\\text{data}}(x) $.\n",
    "2. We obtain the Kullback-Leibler (KL) divergence term for the last layer (i.e., $ z_2 $). However, for the middle layer, we cannot compute the KL divergence because we need to first sample $ z_1 $ from $ q(z_1 | x) $, and then sample $ z_2 $ from $ q(z_2 | z_1) $. As a result, we cannot \"swap\" distributions to obtain the KL term.\n",
    "3. Remember that the KL divergence is always non-negative. Theoretically, everything should work perfectly, but there are potential issues. \n",
    "\n",
    "### Problems During Learning\n",
    "\n",
    "A couple of issues arise during learning:\n",
    "1. **Random Initialization**: All DNNs that parameterize the distributions are initialized randomly, meaning the Gaussians are essentially standard Gaussians initially.\n",
    "2. **Powerful Decoder**: If the decoder is flexible and powerful enough, there is a risk that the model will try to optimize the last KL term, $ \\text{KL}[q(z_2 | z_1) || p(z_2)] $, by setting $ q(z_2 | z_1) \\approx p(z_2) \\approx \\mathcal{N}(0, 1) $. In this case, the second latent variable $ z_2 $ is essentially ignored (it becomes Gaussian noise), and we are back to the same issues seen in the one-level VAE architecture.\n",
    "\n",
    "This phenomenon, where the latent variables are not effectively used, is called **posterior collapse**. In fact, learning a two-level VAE can be more problematic than learning a single latent VAE, as even with a relatively simple decoder, the second latent variables $ z_2 $ are often not utilized properly [15, 72].\n",
    "\n",
    "## Figure\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "Fig.19 An example of a two-level VAE. (a) The generative part. (b) The variational part.\n",
    "\n",
    "- **Fig.19**: An example of a two-level VAE:\n",
    "  - (a) The generative part.\n",
    "  - (b) The variational part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Encoder and Decoder Networks\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim1, latent_dim2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mu = nn.Linear(hidden_dim, latent_dim1)  # For mean of z1\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim1)  # For logvar of z1\n",
    "        self.fc3_mu = nn.Linear(latent_dim1, latent_dim2)  # For mean of z2\n",
    "        self.fc3_logvar = nn.Linear(latent_dim1, latent_dim2)  # For logvar of z2\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = torch.relu(self.fc1(x))\n",
    "        mu_z1 = self.fc2_mu(h1)\n",
    "        logvar_z1 = self.fc2_logvar(h1)\n",
    "        mu_z2 = self.fc3_mu(mu_z1)  # We use the mean of z1 to predict mean of z2\n",
    "        logvar_z2 = self.fc3_logvar(mu_z1)  # Similarly for logvar of z2\n",
    "        return mu_z1, logvar_z1, mu_z2, logvar_z2\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim1, latent_dim2, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z1):\n",
    "        h1 = torch.relu(self.fc1(z1))\n",
    "        x_reconstructed = torch.sigmoid(self.fc2(h1))  # Assuming binary data\n",
    "        return x_reconstructed\n",
    "\n",
    "# Sampling function\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "# Loss function\n",
    "def loss_function(x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2):\n",
    "    # Reconstruction loss\n",
    "    recon_loss = nn.BCELoss(reduction='sum')(x_reconstructed, x)\n",
    "    \n",
    "    # KL Divergence\n",
    "    # KL(z1|z2) and KL(z2|prior)\n",
    "    kl_z1_z2 = -0.5 * torch.sum(1 + logvar_z1 - mu_z1.pow(2) - logvar_z1.exp())\n",
    "    kl_z2 = -0.5 * torch.sum(1 + logvar_z2 - mu_z2.pow(2) - logvar_z2.exp())\n",
    "    \n",
    "    return recon_loss + kl_z1_z2 + kl_z2\n",
    "\n",
    "# Train the model\n",
    "def train(model, encoder, decoder, dataloader, epochs=10, lr=1e-3):\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x = data  # Assuming data is already preprocessed and normalized\n",
    "            \n",
    "            # Encode\n",
    "            mu_z1, logvar_z1, mu_z2, logvar_z2 = encoder(x)\n",
    "            \n",
    "            # Reparameterize to get z1 and z2\n",
    "            z1 = reparameterize(mu_z1, logvar_z1)\n",
    "            z2 = reparameterize(mu_z2, logvar_z2)\n",
    "            \n",
    "            # Decode\n",
    "            x_reconstructed = decoder(z1)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_function(x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Backpropagate and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(dataloader.dataset)}')\n",
    "\n",
    "# Example usage:\n",
    "# Let's assume you have preprocessed data in a DataLoader (e.g., from MNIST)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Load MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])  # Flatten images\n",
    "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model parameters\n",
    "input_dim = 784  # 28x28 images flattened\n",
    "hidden_dim = 400\n",
    "latent_dim1 = 20\n",
    "latent_dim2 = 20\n",
    "output_dim = 784  # Same as input, since we're reconstructing images\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(input_dim, hidden_dim, latent_dim1, latent_dim2)\n",
    "decoder = Decoder(latent_dim1, latent_dim2, hidden_dim, output_dim)\n",
    "\n",
    "# Train the model\n",
    "train(encoder, decoder, train_loader, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Define the activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "# Basic layer with a single neuron\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size, activation_func):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        # Randomly initialize weights and biases\n",
    "        self.weights = [[random.gauss(0, 1) for _ in range(input_size)] for _ in range(output_size)]\n",
    "        self.biases = [random.gauss(0, 1) for _ in range(output_size)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = [self.activation_func(sum(inputs[i] * self.weights[j][i] for i in range(self.input_size)) + self.biases[j]) \n",
    "                        for j in range(self.output_size)]\n",
    "        return self.outputs\n",
    "\n",
    "    def backward(self, output_grad, learning_rate):\n",
    "        # Compute the gradient for weights and biases\n",
    "        weight_gradients = [[output_grad[j] * self.inputs[i] for i in range(self.input_size)] for j in range(self.output_size)]\n",
    "        bias_gradients = [output_grad[j] for j in range(self.output_size)]\n",
    "\n",
    "        # Update the weights and biases\n",
    "        for j in range(self.output_size):\n",
    "            for i in range(self.input_size):\n",
    "                self.weights[j][i] -= learning_rate * weight_gradients[j][i]\n",
    "            self.biases[j] -= learning_rate * bias_gradients[j]\n",
    "\n",
    "        return [sum(output_grad[j] * self.weights[j][i] for j in range(self.output_size)) for i in range(self.input_size)]\n",
    "EPSILON = 1e-10\n",
    "\n",
    "\n",
    "# Define the Encoder and Decoder models (in a simple way)\n",
    "class VAE:\n",
    "    def __init__(self, input_size, latent_dim1, latent_dim2):\n",
    "        # Encoder\n",
    "        self.encoder_fc1 = DenseLayer(input_size, 400, relu)\n",
    "        self.encoder_mu_z1 = DenseLayer(400, latent_dim1, sigmoid)\n",
    "        self.encoder_logvar_z1 = DenseLayer(400, latent_dim1, sigmoid)\n",
    "        self.encoder_mu_z2 = DenseLayer(latent_dim1, latent_dim2, sigmoid)\n",
    "        self.encoder_logvar_z2 = DenseLayer(latent_dim1, latent_dim2, sigmoid)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_fc1 = DenseLayer(latent_dim1, 400, relu)\n",
    "        self.decoder_fc2 = DenseLayer(400, input_size, sigmoid)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.encoder_fc1.forward(x)\n",
    "        mu_z1 = self.encoder_mu_z1.forward(x)\n",
    "        logvar_z1 = self.encoder_logvar_z1.forward(x)\n",
    "        mu_z2 = self.encoder_mu_z2.forward(mu_z1)\n",
    "        logvar_z2 = self.encoder_logvar_z2.forward(mu_z1)\n",
    "        return mu_z1, logvar_z1, mu_z2, logvar_z2\n",
    "    \n",
    "    def decode(self, z1):\n",
    "        z1 = self.decoder_fc1.forward(z1)\n",
    "        x_reconstructed = self.decoder_fc2.forward(z1)\n",
    "        return x_reconstructed\n",
    "    \n",
    "    def sample(self, mu, logvar):\n",
    "        std = [math.exp(0.5 * lv) for lv in logvar]\n",
    "        eps = [random.gauss(0, 1) for _ in range(len(mu))]\n",
    "        return [mu[i] + eps[i] * std[i] for i in range(len(mu))]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu_z1, logvar_z1, mu_z2, logvar_z2 = self.encode(x)\n",
    "        z1 = self.sample(mu_z1, logvar_z1)\n",
    "        z2 = self.sample(mu_z2, logvar_z2)\n",
    "        x_reconstructed = self.decode(z1)\n",
    "        return x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2\n",
    "\n",
    "    # Define a small epsilon value to avoid log(0)\n",
    "\n",
    "    def loss(self, x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2):\n",
    "        # Reconstruction loss (binary cross-entropy)\n",
    "        recon_loss = sum([-(x[i] * math.log(x_reconstructed[i] + EPSILON) + (1 - x[i]) * math.log(1 - x_reconstructed[i] + EPSILON)) for i in range(len(x))])\n",
    "\n",
    "        # KL Divergence\n",
    "        kl_z1_z2 = sum([-(0.5 * (1 + logvar_z1[i] - mu_z1[i]**2 - math.exp(logvar_z1[i]))) for i in range(len(mu_z1))])\n",
    "        kl_z2 = sum([-(0.5 * (1 + logvar_z2[i] - mu_z2[i]**2 - math.exp(logvar_z2[i]))) for i in range(len(mu_z2))])\n",
    "\n",
    "        return recon_loss + kl_z1_z2 + kl_z2\n",
    "\n",
    "\n",
    "    def train(self, data, epochs=10, learning_rate=0.001):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x in data:\n",
    "                x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2 = self.forward(x)\n",
    "                loss = self.loss(x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2)\n",
    "                total_loss += loss\n",
    "\n",
    "                # Backpropagation step\n",
    "                self.backward(x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2, learning_rate)\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data)}')\n",
    "                \n",
    "    def backward(self, x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2, learning_rate):\n",
    "        # Compute gradients for each layer (simple gradient descent)\n",
    "        pass  # Implement gradient computation for the decoder and encoder\n",
    "\n",
    "# Example usage with dummy data\n",
    "data = [[random.random() for _ in range(784)] for _ in range(1000)]  # Dummy data of 784-dimensional vectors\n",
    "vae = VAE(input_size=784, latent_dim1=20, latent_dim2=20)\n",
    "vae.train(data, epochs=10)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "230bd8de",
   "metadata": {},
   "source": [
    "### 5.5.2.2 Top-Down VAEs\n",
    "\n",
    "A takeaway from our considerations in the two-level VAE is that adding an extra level does not necessarily provide anything compared to the one-level VAE. However, so far, we have considered only one class of variational posteriors, namely:\n",
    "$$\n",
    "Q(z_1, z_2 | x) = q(z_1 | x)q(z_2 | z_1). \\tag{5.83}\n",
    "$$\n",
    "A natural question is whether we can do better. You can already guess the answer, but before shouting it out loud, let us think for a second. In the generative part, we have top-down dependencies, going from the highest level of abstraction (latents) down to the observable variables. Let us repeat it here again:\n",
    "$$\n",
    "p(x, z_1, z_2) = p(x|z_1)p(z_1|z_2)p(z_2). \\tag{5.84}\n",
    "$$\n",
    "Perhaps, we can mirror such dependencies in the variational posteriors as well. Then we get the following:\n",
    "$$\n",
    "Q(z_1, z_2 | x) = q(z_1 | z_2, x)q(z_2 | x). \\tag{5.85}\n",
    "$$\n",
    "Do you see any resemblance? Yes, the variational posteriors have the extra $x$, but the dependencies are pointing in the same direction. Why this could be beneficial? Because now we could have a shared top-down path that would make the variational posteriors and the generative part tightly connected through a shared parameterization. That could be a very useful inductive bias!\n",
    "\n",
    "This idea was originally proposed in ResNet VAEs [18] and Ladder VAEs [73], and it was further developed in BIVA [45], NVAE [46], and the very deep VAE [47]. These approaches differ in their implementations and parameterizations used (i.e., architectures of DNNs); however, they all could be categorized as instantiations of top-down VAEs.\n",
    "\n",
    "The main idea, as mentioned before, is to share the top-down path between the variational posteriors and the generative distributions and use a side, a deterministic path going from $x$ to the last latents.\n",
    "\n",
    "#### Top-Down Path\n",
    "First, we have the top-down path that defines $p(x|z_1)$, $p(z_1|z_2)$, and $p(z_2)$. Thus, we need a DNN that outputs $\\mu_1$ and $\\sigma_1^2$ for given $z_2$, and another DNN that outputs the parameters of $p(x|z_1)$ for given $z_1$. Since $p(z_2)$ is an unconditional distribution (e.g., the standard Gaussian), we do not need a separate DNN here. \n",
    "\n",
    "#### Side, Deterministic Path\n",
    "Second, we have a side, deterministic path that gives two deterministic variables: $r_1 = f_1(x)$ and $r_2 = f_2(r_1)$. Both transformations, $f_1$ and $f_2$, are DNNs. Then, we can use additional DNNs that return some modifications of the means and the variances, namely, $\\Delta\\mu_1, \\Delta\\sigma_1^2$ and $\\Delta\\mu_2, \\Delta\\sigma_2^2$. These modifications could be defined in many ways. Here we follow the way it is done in NVAE [46], namely, the modifications are relative location and scales of the values given in the top-down path.\n",
    "\n",
    "Finally, we can define the whole procedure. We define various neural networks by specifying different indices. For sampling, we use the top-down path:\n",
    "\n",
    "**Top-down path:**\n",
    "1. $z_2 \\sim N(0, 1)$\n",
    "2. $[\\mu_1, \\sigma_1^2] = \\text{NN}_1(z_2)$\n",
    "3. $z_1 \\sim N(\\mu_1, \\sigma_1^2)$\n",
    "4. $\\vartheta = \\text{NN}_x(z_1)$\n",
    "5. $x \\sim p_\\vartheta(x | z_1)$\n",
    "\n",
    "Now (please focus!) we calculate samples from the variational posteriors as follows:\n",
    "\n",
    "**Bottom-up path:**\n",
    "1. (Bottom-up deterministic path) $r_1 = f_1(x)$ and $r_2 = f_2(r_1)$\n",
    "2. $[\\Delta\\mu_1, \\Delta\\sigma_1^2] = \\text{NN}_{\\Delta 1}(r_1)$\n",
    "3. $[\\Delta\\mu_2, \\Delta\\sigma_2^2] = \\text{NN}_{\\Delta 2}(r_2)$\n",
    "4. $z_2 \\sim N(\\Delta\\mu_2, \\Delta\\sigma_2^2)$\n",
    "5. $[\\mu_1, \\sigma_1^2] = \\text{NN}_1(z_2)$\n",
    "6. $z_1 \\sim N(\\mu_1 + \\Delta\\mu_1, \\sigma_1^2 \\cdot \\Delta\\sigma_1^2)$\n",
    "7. $\\vartheta = \\text{NN}_x(z_1)$\n",
    "8. $x \\sim p_\\vartheta(x | z_1)$\n",
    "\n",
    "These operations are schematically presented in **Figure 5.20**. Please note that the deterministic bottom-up path modifies the parameters of the top-down path. As advocated by [46], this idea is especially useful because \"when the prior moves, the approximate posterior moves accordingly, if not changed.\"\n",
    "\n",
    "Moreover, as noted in [46], the Kullback-Leibler between two Gaussians simplifies as follows (we remove some additional dependencies for clarity):\n",
    "$$\n",
    "KL(q(z_i | x) \\parallel p(z_i)) = \\frac{1}{2} \\left( \\Delta\\mu_i^2 + \\Delta\\sigma_i^2 - \\log \\Delta\\sigma_i^2 - 1 \\right)\n",
    "$$\n",
    "\n",
    "In summary, the top-down VAEs entangle the variational posteriors and the generative path, and, as a result, the Kullback-Leibler terms will not collapse (i.e., they will be greater than zero). Empirical studies strongly back up this hypothesis [45–47, 73].\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "Fig.20 An example of the top-down VAE. Red nodes denote the deterministic path, and blue nodes depict random variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "class VAE:\n",
    "    def __init__(self, latent_dim1, latent_dim2, input_dim):\n",
    "        # Initialize dimensions for latents and input\n",
    "        self.latent_dim1 = latent_dim1\n",
    "        self.latent_dim2 = latent_dim2\n",
    "        self.input_dim = input_dim  # The dimension of the input data (e.g., 784)\n",
    "\n",
    "        # Example parameters for mu and sigma\n",
    "        self.mu1 = [0.0] * latent_dim1\n",
    "        self.sigma1 = [1.0] * latent_dim1\n",
    "        self.mu2 = [0.0] * latent_dim2\n",
    "        self.sigma2 = [1.0] * latent_dim2\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + math.exp(-x))  # Sigmoid activation function\n",
    "    \n",
    "    def loss(self, x, x_reconstructed, mu1, logvar1, mu2, logvar2):\n",
    "        epsilon = 1e-10  # Small value to avoid log(0)\n",
    "\n",
    "        # Ensure that the length of x and x_reconstructed match\n",
    "        if len(x) != len(x_reconstructed):\n",
    "            raise ValueError(\"Input x and reconstructed x must have the same length.\")\n",
    "\n",
    "        # Reconstruction loss (binary cross-entropy)\n",
    "        recon_loss = sum([-(xi * math.log(self.sigmoid(x_reconstructed[i]) + epsilon) + \n",
    "                            (1 - xi) * math.log(1 - self.sigmoid(x_reconstructed[i]) + epsilon))\n",
    "                          for i, xi in enumerate(x)])\n",
    "\n",
    "        # KL Divergence - assuming standard Gaussians for simplicity\n",
    "        kl_loss1 = 0.5 * sum([(mu1[i] ** 2 + logvar1[i] ** 2 - 1 - 2 * logvar1[i]) for i in range(len(mu1))])\n",
    "        kl_loss2 = 0.5 * sum([(mu2[i] ** 2 + logvar2[i] ** 2 - 1 - 2 * logvar2[i]) for i in range(len(mu2))])\n",
    "\n",
    "        total_loss = recon_loss + kl_loss1 + kl_loss2\n",
    "        return total_loss\n",
    "\n",
    "    def top_down_path(self, z2):\n",
    "        # Example of how you can calculate the top-down path\n",
    "        # p(x | z1) and p(z1 | z2)\n",
    "\n",
    "        # Adjusting mu1 by multiplying each element of mu1 by z2\n",
    "        mu1 = [m + z2 for m in self.mu1]  # Correct transformation for mu1\n",
    "        sigma1 = [s * z2 for s in self.sigma1]  # Correct transformation for sigma1\n",
    "\n",
    "        # Sample z1 from N(mu1, sigma1)\n",
    "        z1 = [random.gauss(mu, sigma) for mu, sigma in zip(mu1, sigma1)]\n",
    "        \n",
    "        # Generate x_reconstructed from z1 (here we generate 784 values for x_reconstructed to match input size)\n",
    "        x_reconstructed = [random.gauss(mu, sigma) for mu, sigma in zip(mu1 * (self.input_dim // len(mu1)), sigma1 * (self.input_dim // len(sigma1)))] \n",
    "\n",
    "        return z1, x_reconstructed\n",
    "    \n",
    "    def train(self, data, epochs=10, learning_rate=0.001):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x in data:\n",
    "                z2 = random.gauss(0, 1)  # sample z2 as a single value from Gaussian\n",
    "                z1, x_reconstructed = self.top_down_path(z2)  # forward pass through the top-down path\n",
    "\n",
    "                # For this simple example, let's assume mu1 and logvar1 are calculated somewhere\n",
    "                mu1 = self.mu1  # example, should be learned\n",
    "                logvar1 = self.sigma1  # example, should be learned\n",
    "\n",
    "                mu2 = self.mu2  # example, should be learned\n",
    "                logvar2 = self.sigma2  # example, should be learned\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss = self.loss(x, x_reconstructed, mu1, logvar1, mu2, logvar2)\n",
    "                total_loss += loss\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data)}\")\n",
    "\n",
    "# Example usage:\n",
    "data = [[random.random() for _ in range(784)] for _ in range(1000)]  # Dummy data of 784-dimensional vectors\n",
    "vae = VAE(latent_dim1=20, latent_dim2=20, input_dim=784)\n",
    "vae.train(data, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b45614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Encoder and Decoder Networks\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim1, latent_dim2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mu = nn.Linear(hidden_dim, latent_dim1)  # For mean of z1\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim1)  # For logvar of z1\n",
    "        self.fc3_mu = nn.Linear(latent_dim1, latent_dim2)  # For mean of z2\n",
    "        self.fc3_logvar = nn.Linear(latent_dim1, latent_dim2)  # For logvar of z2\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = torch.relu(self.fc1(x))\n",
    "        mu_z1 = self.fc2_mu(h1)\n",
    "        logvar_z1 = self.fc2_logvar(h1)\n",
    "        mu_z2 = self.fc3_mu(mu_z1)  # We use the mean of z1 to predict mean of z2\n",
    "        logvar_z2 = self.fc3_logvar(mu_z1)  # Similarly for logvar of z2\n",
    "        return mu_z1, logvar_z1, mu_z2, logvar_z2\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim1, latent_dim2, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z1):\n",
    "        h1 = torch.relu(self.fc1(z1))\n",
    "        x_reconstructed = torch.sigmoid(self.fc2(h1))  # Assuming binary data\n",
    "        return x_reconstructed\n",
    "\n",
    "# Sampling function\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "# Loss function\n",
    "def loss_function(x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2):\n",
    "    # Reconstruction loss\n",
    "    recon_loss = nn.BCELoss(reduction='sum')(x_reconstructed, x)\n",
    "    \n",
    "    # KL Divergence\n",
    "    # KL(z1|z2) and KL(z2|prior)\n",
    "    kl_z1_z2 = -0.5 * torch.sum(1 + logvar_z1 - mu_z1.pow(2) - logvar_z1.exp())\n",
    "    kl_z2 = -0.5 * torch.sum(1 + logvar_z2 - mu_z2.pow(2) - logvar_z2.exp())\n",
    "    \n",
    "    return recon_loss + kl_z1_z2 + kl_z2\n",
    "\n",
    "# Train the model\n",
    "def train(model, encoder, decoder, dataloader, epochs=10, lr=1e-3):\n",
    "    optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x = data  # Assuming data is already preprocessed and normalized\n",
    "            \n",
    "            # Encode\n",
    "            mu_z1, logvar_z1, mu_z2, logvar_z2 = encoder(x)\n",
    "            \n",
    "            # Reparameterize to get z1 and z2\n",
    "            z1 = reparameterize(mu_z1, logvar_z1)\n",
    "            z2 = reparameterize(mu_z2, logvar_z2)\n",
    "            \n",
    "            # Decode\n",
    "            x_reconstructed = decoder(z1)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_function(x, x_reconstructed, mu_z1, logvar_z1, mu_z2, logvar_z2)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Backpropagate and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_loss/len(dataloader.dataset)}')\n",
    "\n",
    "# Example usage:\n",
    "# Let's assume you have preprocessed data in a DataLoader (e.g., from MNIST)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Load MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])  # Flatten images\n",
    "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model parameters\n",
    "input_dim = 784  # 28x28 images flattened\n",
    "hidden_dim = 400\n",
    "latent_dim1 = 20\n",
    "latent_dim2 = 20\n",
    "output_dim = 784  # Same as input, since we're reconstructing images\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(input_dim, hidden_dim, latent_dim1, latent_dim2)\n",
    "decoder = Decoder(latent_dim1, latent_dim2, hidden_dim, output_dim)\n",
    "\n",
    "# Train the model\n",
    "train(encoder, decoder, train_loader, epochs=10)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23ec74dd",
   "metadata": {},
   "source": [
    "## Hierarchical Variational Autoencoder (VAE)\n",
    "\n",
    "In this notebook, we will implement a **Hierarchical Variational Autoencoder** (VAE), which is a two-level model that learns to map high-dimensional data into a lower-dimensional latent space.\n",
    "\n",
    "We will use PyTorch to define the model and train it based on a given set of inputs. The following steps outline the mathematical formulation of the Hierarchical VAE, followed by the corresponding implementation.\n",
    "\n",
    "## Hierarchical VAE Architecture\n",
    "\n",
    "### Model Components\n",
    "\n",
    "The model consists of two key latent variables $z_1$ and $z_2$ that encode the data in a hierarchical manner:\n",
    "\n",
    "- **$z_2$** is the higher-level latent variable that influences the distribution of $z_1$.\n",
    "- **$z_1$** is the lower-level latent variable that reconstructs the data $x$.\n",
    "\n",
    "#### Bottom-up Path\n",
    "\n",
    "- **$z_2 \\sim \\mathcal{N}(0, I)$**: The top-level latent variable is drawn from a standard Gaussian distribution.\n",
    "- **$h_1$ = $nn_z_1(z_2)$**: A neural network $nn_z_1$ transforms $z_2$ into a hidden representation $h_1$.\n",
    "- **$mu_1, \\log \\sigma_1 = \\text{torch.chunk}(h_1, 2, dim=1)$**: The hidden representation $h_1$ is split into the mean $\\mu_1$ and the log-variance $\\log \\sigma_1$.\n",
    "- **Reparameterization Trick**: The latent variable $z_1$ is sampled using the reparameterization trick:\n",
    "  $$\n",
    "  z_1 = \\mu_1 + \\Delta \\mu_1 + \\epsilon_1 \\cdot \\exp(\\frac{\\log \\sigma_1}{2})\n",
    "  $$\n",
    "  where $\\epsilon_1 \\sim \\mathcal{N}(0, I)$.\n",
    "\n",
    "#### Top-down Path\n",
    "\n",
    "- **$h_d = nn_x(z_1)$**: The lower-level latent variable $z_1$ is passed through a neural network to reconstruct the data $h_d$.\n",
    "- **Likelihood Function**: Depending on the likelihood type, we either use a categorical or Bernoulli distribution to model the data:\n",
    "  $$\n",
    "  p(x | z_1) = \\text{Categorical}(x | \\mu_d), \\quad \\text{or} \\quad p(x | z_1) = \\text{Bernoulli}(x | \\mu_d)\n",
    "  $$\n",
    "\n",
    "#### ELBO (Evidence Lower Bound)\n",
    "\n",
    "The ELBO is the objective function we optimize during training. It consists of two parts:\n",
    "\n",
    "- **Reconstruction Error** (RE):\n",
    "  $$\n",
    "  \\text{RE} = \\mathbb{E}_{q(z_1, z_2 | x)}[\\log p(x | z_1)]\n",
    "  $$\n",
    "- **KL Divergence** (KL):\n",
    "  $$\n",
    "  \\text{KL} = \\text{KL}(q(z_2 | z_1) || p(z_2)) + \\text{KL}(q(z_1 | z_2, x) || p(z_1 | z_2))\n",
    "  $$\n",
    "\n",
    "The final objective is:\n",
    "$$\n",
    "\\text{ELBO} = \\text{RE} - \\text{KL}\n",
    "$$\n",
    "\n",
    "We optimize the ELBO using gradient-based methods to train the model.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.21 An example of outcomes after the training of a top-down VAE: (a) Randomly selected real images. (b) Unconditional generations from the top-down VAE. (c) The validation curve during training.\n",
    "\n",
    "## Code Implementation\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HierarchicalVAE(nn.Module):\n",
    "    def __init__(self, nn_r_1, nn_r_2, nn_delta_1, nn_delta_2, nn_z_1, nn_x, num_vals=256, D=64, L=16, likelihood_type='categorical'):\n",
    "        super(HierarchicalVAE, self).__init__()\n",
    "        \n",
    "        print('Hierarchical VAE by JT.')\n",
    "        \n",
    "        # Bottom-up path\n",
    "        self.nn_r_1 = nn_r_1\n",
    "        self.nn_r_2 = nn_r_2\n",
    "        self.nn_delta_1 = nn_delta_1\n",
    "        self.nn_delta_2 = nn_delta_2\n",
    "        \n",
    "        # Hidden layers\n",
    "        self.nn_z_1 = nn_z_1\n",
    "        self.nn_x = nn_x\n",
    "        self.num_vals = num_vals\n",
    "        \n",
    "    def reparameterization(self, mu, log_var):\n",
    "        epsilon = torch.randn_like(mu)\n",
    "        return mu + epsilon * torch.exp(0.5 * log_var)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Step 1: Sample z_2 from a standard normal distribution\n",
    "        z_2 = torch.randn(x.size(0), self.L)\n",
    "        \n",
    "        # Step 2: Transform z_2 through nn_z_1\n",
    "        h_1 = self.nn_z_1(z_2)\n",
    "        mu_1, log_var_1 = torch.chunk(h_1, 2, dim=1)\n",
    "        \n",
    "        # Step 3: Reparameterize to get z_1\n",
    "        z_1 = self.reparameterization(mu_1, log_var_1)\n",
    "        \n",
    "        # Step 4: Pass z_1 through the decoder (nn_x)\n",
    "        h_d = self.nn_x(z_1)\n",
    "        \n",
    "        if self.likelihood_type == 'categorical':\n",
    "            # Step 5: Apply softmax for categorical likelihood\n",
    "            mu_d = F.softmax(h_d, dim=-1)\n",
    "        elif self.likelihood_type == 'bernoulli':\n",
    "            # Step 5: Apply sigmoid for Bernoulli likelihood\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "        \n",
    "        # Return the parameters for the likelihood\n",
    "        return mu_d, mu_1, log_var_1\n",
    "    \n",
    "    def loss(self, x, mu_d, mu_1, log_var_1, delta_mu_1, delta_log_var_1, delta_mu_2, delta_log_var_2):\n",
    "        # Reconstruction loss (Binary Cross-Entropy)\n",
    "        if self.likelihood_type == 'categorical':\n",
    "            RE = F.cross_entropy(mu_d.view(-1, self.num_vals), x.view(-1), reduction='sum')\n",
    "        elif self.likelihood_type == 'bernoulli':\n",
    "            RE = F.binary_cross_entropy(mu_d.view(-1), x.view(-1), reduction='sum')\n",
    "        \n",
    "        # KL Divergence losses\n",
    "        KL_z_2 = 0.5 * (delta_mu_2 ** 2 + torch.exp(delta_log_var_2) - delta_log_var_2 - 1).sum(-1)\n",
    "        KL_z_1 = 0.5 * (delta_mu_1 ** 2 / torch.exp(log_var_1) + torch.exp(delta_log_var_1) - delta_log_var_1 - 1).sum(-1)\n",
    "        \n",
    "        # Total KL Divergence\n",
    "        KL = KL_z_1 + KL_z_2\n",
    "        \n",
    "        # Final ELBO loss\n",
    "        loss = -(RE - KL).mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36724ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
