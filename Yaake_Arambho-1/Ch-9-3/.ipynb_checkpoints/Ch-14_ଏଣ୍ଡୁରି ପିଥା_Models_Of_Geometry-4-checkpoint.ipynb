{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2004 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a19b8",
   "metadata": {},
   "source": [
    "### Random Classification Trees (Single Branch per Data Point)\n",
    "\n",
    "Unlike in section 9.8, we will assume that each data point passes into just one branch. In a random classification tree, the data are evaluated against a function $q[x]$ that was randomly chosen from a predefined family of possible functions. For example, this might be the response of a randomly chosen filter. The data proceeds one way in the tree if the response of this function exceeds a threshold $\\tau$ and the other way if not.\n",
    "\n",
    "While the functions $q[x]$ are chosen randomly, the threshold $\\tau$ is carefully selected. We select the threshold that maximizes the log-likelihood $L$ of the data:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^{I} (1 - \\text{heaviside}[q[x_i] - \\tau]) \\log \\text{Cat}_{w_i}[\\lambda^{[l]}] + \\text{heaviside}[q[x_i] - \\tau] \\log \\text{Cat}_{w_i}[\\lambda^{[r]}] \\quad (9.63)\n",
    "$$\n",
    "\n",
    "Here the first term represents the contribution of the data $x_i$ with true class $w_i$ that passes down the left branch (where $q[x_i] \\le \\tau$), and the second term represents the contribution of the data that passes down the right branch (where $q[x_i] > \\tau$). In each case, the data are evaluated against a categorical distribution with parameters $\\lambda^{[l]}$ and $\\lambda^{[r]}$, respectively. These parameters represent the distribution of classes in the left and right child nodes.\n",
    "\n",
    "These parameters are set using maximum likelihood based on the data partitioned by the threshold $\\tau$:\n",
    "\n",
    "$$\n",
    "\\lambda_k^{[l]} = \\frac{\\sum_{i=1}^{I} \\delta[w_i - k](1 - \\text{heaviside}[q[x_i] - \\tau])}{\\sum_{i=1}^{I} (1 - \\text{heaviside}[q[x_i] - \\tau])}\n",
    "$$\n",
    "$$\n",
    "\\lambda_k^{[r]} = \\frac{\\sum_{i=1}^{I} \\delta[w_i - k](\\text{heaviside}[q[x_i] - \\tau])}{\\sum_{i=1}^{I} (\\text{heaviside}[q[x_i] - \\tau])} \\quad (9.64)\n",
    "$$\n",
    "\n",
    "Here, $\\lambda_k^{[l]}$ is the proportion of data points in the left branch belonging to class $k$, and $\\lambda_k^{[r]}$ is the proportion for the right branch. The term $\\delta[w_i - k]$ is 1 if the true class $w_i$ is $k$, and 0 otherwise.\n",
    "\n",
    "The log likelihood $L$ is not a smooth function of the threshold $\\tau$, and so in practice we maximize the log likelihood by empirically trying a number of different threshold values and choosing the one that gives the best result (i.e., the best split according to the log-likelihood objective).\n",
    "\n",
    "We then perform this same procedure recursively: the data that pass to the left branch has a new randomly chosen classifier $q'[x]$ applied to them and a new threshold $\\tau'$ is chosen that splits it again. This can be done without recourse to the data in the right branch, and vice versa. This process continues until a stopping criterion is met (e.g., maximum depth, minimum number of samples per node).\n",
    "\n",
    "When we classify a new data example $x^*$, we pass it down the tree according to the learned functions $q[\\cdot]$ and thresholds $\\tau$ at each node until it reaches one of the leaves. The posterior distribution $Pr(w^*|x^*)$ over the world state (class) $w^*$ is set to $\\text{Cat}_{w^*}[\\lambda]$ where the parameters $\\lambda$ are the categorical parameters (calculated using Eq. 9.64 during training) associated with this leaf.\n",
    "\n",
    "The random classification tree is attractive because it is very fast to train â€“ after all, most of its parameters (the functions $q[x]$) are chosen randomly. It can also be trained with very large amounts of data as its complexity is linear in the number of data examples $I$ (assuming the number of thresholds tested per node is constant or logarithmic in $I$).\n",
    "\n",
    "There are two important variations on this model:\n",
    "\n",
    "1.  **Fern:** A fern is a tree where the randomly chosen functions $q[\\cdot]$ at each *level* of the tree are constrained to be the same. In other words, the data that pass through the left and right branches at any node *at a given depth* are subsequently acted on by the same function (although the threshold level $\\tau$ may optionally be different in each branch). In practice, this means that every data point is acted on by the same sequence of functions as it traverses the tree depth. This can make implementation extremely efficient when we are evaluating the classifier repeatedly, as the same set of function responses can be calculated once and reused for threshold comparisons at each node of a given level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfac02da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Classification Tree...\n",
      "Training complete.\n",
      "\n",
      "Predicting probabilities on test set...\n",
      "\n",
      "Predicting classes on test set...\n",
      "\n",
      "Accuracy on test set: 1.0000\n",
      "\n",
      "--- Example with make_classification ---\n",
      "Training on make_classification data...\n",
      "Training complete.\n",
      "Accuracy on make_classification test set: 0.4667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "# Increase recursion depth limit if needed for deep trees\n",
    "# sys.setrecursionlimit(2000) \n",
    "\n",
    "# Small epsilon to avoid log(0)\n",
    "EPSILON = 1e-9 \n",
    "\n",
    "class Node:\n",
    "    \"\"\"Represents a node in the Random Classification Tree.\"\"\"\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_index (int, optional): Index of the feature used for splitting.\n",
    "            threshold (float, optional): Threshold value for the split.\n",
    "            left (Node, optional): Left child node (q(x) <= threshold).\n",
    "            right (Node, optional): Right child node (q(x) > threshold).\n",
    "            value (dict, optional): The class distribution (lambda) if this is a leaf node.\n",
    "                                    Keys are class labels, values are probabilities.\n",
    "        \"\"\"\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value # Stores class distribution for leaf nodes\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        \"\"\"Checks if the node is a leaf node.\"\"\"\n",
    "        return self.value is not None\n",
    "\n",
    "class RandomClassificationTree:\n",
    "    \"\"\"\n",
    "    A Random Classification Tree implementation based on the provided text.\n",
    "    Splits are based on a randomly chosen feature and an optimized threshold\n",
    "    maximizing log-likelihood of categorical distributions in child nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=10, min_samples_leaf=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_depth (int): Maximum depth of the tree.\n",
    "            min_samples_leaf (int): Minimum number of samples required at a leaf node.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root = None\n",
    "        self.n_classes = None\n",
    "        self.classes_ = None # Store unique classes seen during fit\n",
    "\n",
    "    def _calculate_lambda(self, W):\n",
    "        \"\"\"Calculates the categorical distribution parameters (MLE) for labels W.\n",
    "           Corresponds to Eq. 9.64's numerator/denominator logic.\n",
    "\n",
    "        Args:\n",
    "            W (np.array): Array of class labels.\n",
    "\n",
    "        Returns:\n",
    "            dict: Class distribution {class_label: probability}. Returns empty dict\n",
    "                  if W is empty or None.\n",
    "        \"\"\"\n",
    "        if W is None or len(W) == 0:\n",
    "            # Return a uniform distribution over known classes if empty?\n",
    "            # Or handle upstream. For now, return empty or uniform default.\n",
    "            # Let's return uniform based on classes seen overall\n",
    "            if self.classes_ is not None and len(self.classes_) > 0:\n",
    "                 return {c: 1.0 / self.n_classes for c in self.classes_}\n",
    "            else:\n",
    "                 return {} # Should not happen if called after fit\n",
    "\n",
    "        n_samples = len(W)\n",
    "        counts = Counter(W)\n",
    "        # Ensure all known classes are represented, even if with 0 probability\n",
    "        lambda_dist = {c: counts.get(c, 0) / n_samples for c in self.classes_}\n",
    "        return lambda_dist\n",
    "\n",
    "    def _calculate_log_likelihood(self, W_left, lambda_left, W_right, lambda_right):\n",
    "        \"\"\"Calculates the log-likelihood based on Eq. 9.63.\n",
    "\n",
    "        Args:\n",
    "            W_left (np.array): Labels in the left split.\n",
    "            lambda_left (dict): Class distribution for the left split.\n",
    "            W_right (np.array): Labels in the right split.\n",
    "            lambda_right (dict): Class distribution for the right split.\n",
    "\n",
    "        Returns:\n",
    "            float: The calculated log-likelihood L.\n",
    "        \"\"\"\n",
    "        log_likelihood = 0.0\n",
    "\n",
    "        # Left branch contribution\n",
    "        if W_left is not None and len(W_left) > 0:\n",
    "            for w_i in W_left:\n",
    "                prob = lambda_left.get(w_i, 0.0) # Get prob of true class w_i\n",
    "                log_likelihood += np.log(prob + EPSILON) # Add EPSILON to avoid log(0)\n",
    "\n",
    "        # Right branch contribution\n",
    "        if W_right is not None and len(W_right) > 0:\n",
    "            for w_i in W_right:\n",
    "                prob = lambda_right.get(w_i, 0.0) # Get prob of true class w_i\n",
    "                log_likelihood += np.log(prob + EPSILON) # Add EPSILON to avoid log(0)\n",
    "\n",
    "        return log_likelihood\n",
    "\n",
    "\n",
    "    def _find_best_split(self, X, W, n_features):\n",
    "        \"\"\"Finds the best feature and threshold to split the data.\n",
    "\n",
    "        Args:\n",
    "            X (np.array): Feature data for the current node.\n",
    "            W (np.array): Labels for the current node.\n",
    "            n_features (int): Total number of features in the original dataset.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (best_feature_idx, best_threshold, best_log_likelihood,\n",
    "                    left_indices, right_indices)\n",
    "                   Returns (None, None, -np.inf, None, None) if no good split found.\n",
    "        \"\"\"\n",
    "        best_log_likelihood = -np.inf\n",
    "        best_split = (None, None, None, None) # feature_idx, threshold, left_idx, right_idx\n",
    "        n_samples, current_n_features = X.shape # current_n_features might differ if using feature subsets\n",
    "\n",
    "        if n_samples <= self.min_samples_leaf * 2: # Need enough samples for two leaves\n",
    "             return None, None, best_log_likelihood, None, None\n",
    "\n",
    "        # --- Randomly choose the function q(x) ---\n",
    "        # In this simple case, it means randomly choosing a feature index\n",
    "        # Consider only features present in the current subset X if applicable\n",
    "        # For simplicity, choose from all original features\n",
    "        feature_idx = np.random.choice(n_features) \n",
    "        \n",
    "        # Ensure the chosen feature actually exists in the current X subset if applicable\n",
    "        # This simple version assumes X always has n_features columns\n",
    "        \n",
    "        feature_values = X[:, feature_idx]\n",
    "        potential_thresholds = np.unique(feature_values)\n",
    "\n",
    "        if len(potential_thresholds) <= 1: # Cannot split if only one unique value\n",
    "            return None, None, best_log_likelihood, None, None\n",
    "\n",
    "        # Iterate through potential split points (thresholds)\n",
    "        # A common strategy is to test midpoints between unique sorted values\n",
    "        # Here, we test unique values themselves for simplicity\n",
    "        for threshold in potential_thresholds:\n",
    "            # Split data based on q(x) = x[feature_idx] and threshold\n",
    "            # Using <= for left as per (1 - heaviside) which is 1 when q(x)-tau <= 0\n",
    "            left_indices = np.where(feature_values <= threshold)[0]\n",
    "            right_indices = np.where(feature_values > threshold)[0]\n",
    "\n",
    "            # Ensure the split is non-trivial and meets min leaf size\n",
    "            if (len(left_indices) < self.min_samples_leaf or\n",
    "                len(right_indices) < self.min_samples_leaf):\n",
    "                continue\n",
    "\n",
    "            # Calculate lambda for each potential child node\n",
    "            W_left, W_right = W[left_indices], W[right_indices]\n",
    "            lambda_left = self._calculate_lambda(W_left)\n",
    "            lambda_right = self._calculate_lambda(W_right)\n",
    "\n",
    "            # Calculate the log-likelihood for this split\n",
    "            current_log_likelihood = self._calculate_log_likelihood(\n",
    "                W_left, lambda_left, W_right, lambda_right\n",
    "            )\n",
    "\n",
    "            # Update best split if this one is better\n",
    "            if current_log_likelihood > best_log_likelihood:\n",
    "                best_log_likelihood = current_log_likelihood\n",
    "                best_split = (feature_idx, threshold, left_indices, right_indices)\n",
    "\n",
    "        # Check if a valid split was found\n",
    "        if best_log_likelihood == -np.inf:\n",
    "            return None, None, best_log_likelihood, None, None\n",
    "        else:\n",
    "            return best_split[0], best_split[1], best_log_likelihood, best_split[2], best_split[3]\n",
    "\n",
    "\n",
    "    def _grow_tree(self, X, W, depth=0):\n",
    "        \"\"\"Recursively builds the tree.\n",
    "\n",
    "        Args:\n",
    "            X (np.array): Feature data for the current node.\n",
    "            W (np.array): Labels for the current node.\n",
    "            depth (int): Current depth in the tree.\n",
    "\n",
    "        Returns:\n",
    "            Node: The root node of the constructed sub-tree.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        n_node_classes = len(np.unique(W))\n",
    "\n",
    "        # --- Stopping Criteria ---\n",
    "        if (depth >= self.max_depth or\n",
    "            n_samples < self.min_samples_leaf or\n",
    "            n_node_classes == 1):\n",
    "            # Create a leaf node\n",
    "            leaf_value = self._calculate_lambda(W)\n",
    "            # print(f\"Leaf Node at depth {depth}: Samples={n_samples}, Classes={n_node_classes}, Dist={leaf_value}\")\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        # --- Find the best split ---\n",
    "        best_feature_idx, best_threshold, best_ll, left_indices, right_indices = self._find_best_split(X, W, n_features)\n",
    "\n",
    "        # --- Check if a valid split was found ---\n",
    "        if best_feature_idx is None:\n",
    "            # Could not find a split improving likelihood or satisfying constraints\n",
    "            leaf_value = self._calculate_lambda(W)\n",
    "            # print(f\"Leaf Node (no split) at depth {depth}: Samples={n_samples}, Classes={n_node_classes}, Dist={leaf_value}\")\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        # --- Recurse ---\n",
    "        # print(f\"Split Node at depth {depth}: Feature={best_feature_idx}, Threshold={best_threshold:.2f}, LL={best_ll:.2f}, Samples={n_samples}->({len(left_indices)}, {len(right_indices)})\")\n",
    "        left_child = self._grow_tree(X[left_indices, :], W[left_indices], depth + 1)\n",
    "        right_child = self._grow_tree(X[right_indices, :], W[right_indices], depth + 1)\n",
    "\n",
    "        return Node(feature_index=best_feature_idx, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "\n",
    "    def fit(self, X, W):\n",
    "        \"\"\"Builds the Random Classification Tree from training data.\n",
    "\n",
    "        Args:\n",
    "            X (np.array): Training feature data (samples x features).\n",
    "            W (np.array): Training class labels (samples).\n",
    "        \"\"\"\n",
    "        self.classes_ = np.unique(W)\n",
    "        self.n_classes = len(self.classes_)\n",
    "        _, n_features = X.shape\n",
    "        self.root = self._grow_tree(X, W)\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        \"\"\"Traverses the tree to find the leaf node for a given sample.\"\"\"\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        # Apply the node's function q(x) (using the stored feature index)\n",
    "        q_x = x[node.feature_index]\n",
    "\n",
    "        if q_x <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predicts class probabilities for each sample in X.\n",
    "\n",
    "        Args:\n",
    "            X (np.array): Feature data for prediction (samples x features).\n",
    "\n",
    "        Returns:\n",
    "            np.array: Array of shape (samples, n_classes) containing class probabilities.\n",
    "                      The order of columns corresponds to self.classes_.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        predictions = np.zeros((n_samples, self.n_classes))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            leaf_distribution = self._traverse_tree(X[i], self.root)\n",
    "            for j, class_label in enumerate(self.classes_):\n",
    "                predictions[i, j] = leaf_distribution.get(class_label, 0.0) # Ensure all classes have a value\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the class label for each sample in X.\n",
    "\n",
    "        Args:\n",
    "            X (np.array): Feature data for prediction (samples x features).\n",
    "\n",
    "        Returns:\n",
    "            np.array: Array of predicted class labels (samples).\n",
    "        \"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        # Return the class index with the highest probability\n",
    "        return self.classes_[np.argmax(probabilities, axis=1)]\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == '__main__':\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # Load data\n",
    "    iris = load_iris()\n",
    "    X, W = iris.data, iris.target\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, W_train, W_test = train_test_split(X, W, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create and train the tree\n",
    "    # Use smaller depth for faster example run\n",
    "    rct = RandomClassificationTree(max_depth=5, min_samples_leaf=3) \n",
    "    print(\"Training Random Classification Tree...\")\n",
    "    rct.fit(X_train, W_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Predict probabilities\n",
    "    print(\"\\nPredicting probabilities on test set...\")\n",
    "    probabilities = rct.predict_proba(X_test)\n",
    "    # print(\"Sample Probabilities (first 5):\")\n",
    "    # print(probabilities[:5])\n",
    "    # print(\"Predicted classes correspond to:\", rct.classes_)\n",
    "\n",
    "\n",
    "    # Predict classes\n",
    "    print(\"\\nPredicting classes on test set...\")\n",
    "    predictions = rct.predict(X_test)\n",
    "    # print(\"Sample Predictions (first 5):\", predictions[:5])\n",
    "    # print(\"True Labels (first 5):      \", W_test[:5])\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(W_test, predictions)\n",
    "    print(f\"\\nAccuracy on test set: {accuracy:.4f}\")\n",
    "\n",
    "    # Example with different dataset (make_classification)\n",
    "    print(\"\\n--- Example with make_classification ---\")\n",
    "    from sklearn.datasets import make_classification\n",
    "    X_mc, W_mc = make_classification(n_samples=500, n_features=20, n_informative=10, \n",
    "                                     n_redundant=5, n_classes=3, random_state=123)\n",
    "    X_mc_train, X_mc_test, W_mc_train, W_mc_test = train_test_split(X_mc, W_mc, test_size=0.3, random_state=123)\n",
    "    \n",
    "    rct_mc = RandomClassificationTree(max_depth=8, min_samples_leaf=5)\n",
    "    print(\"Training on make_classification data...\")\n",
    "    rct_mc.fit(X_mc_train, W_mc_train)\n",
    "    print(\"Training complete.\")\n",
    "    \n",
    "    pred_mc = rct_mc.predict(X_mc_test)\n",
    "    acc_mc = accuracy_score(W_mc_test, pred_mc)\n",
    "    print(f\"Accuracy on make_classification test set: {acc_mc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23dd669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Classification Tree (Pure Python)...\n",
      "Training complete.\n",
      "\n",
      "Predicting probabilities on test set...\n",
      "\n",
      "Predicting classes on test set...\n",
      "\n",
      "Accuracy on test set (calculated manually): 0.7778\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Increase recursion depth limit if needed for deep trees\n",
    "# import sys\n",
    "# sys.setrecursionlimit(2000)\n",
    "\n",
    "# Small epsilon to avoid log(0)\n",
    "EPSILON = 1e-9\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_column(data, index):\n",
    "    \"\"\"Extracts a column from a list of lists.\"\"\"\n",
    "    if not data:\n",
    "        return []\n",
    "    return [row[index] for row in data]\n",
    "\n",
    "def unique_values(data_list):\n",
    "    \"\"\"Gets unique values from a list.\"\"\"\n",
    "    return list(set(data_list))\n",
    "\n",
    "def class_counts(data_list):\n",
    "    \"\"\"Counts occurrences of each item in a list.\"\"\"\n",
    "    counts = {}\n",
    "    for item in data_list:\n",
    "        counts[item] = counts.get(item, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def split_data(X, W, indices):\n",
    "    \"\"\"Creates subsets of X and W based on indices.\"\"\"\n",
    "    X_subset = [X[i] for i in indices]\n",
    "    W_subset = [W[i] for i in indices]\n",
    "    return X_subset, W_subset\n",
    "\n",
    "# --- Node Class (No changes needed) ---\n",
    "class Node:\n",
    "    \"\"\"Represents a node in the Random Classification Tree.\"\"\"\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value # Stores class distribution for leaf nodes\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        \"\"\"Checks if the node is a leaf node.\"\"\"\n",
    "        return self.value is not None\n",
    "\n",
    "# --- Random Classification Tree Class (No External Libraries) ---\n",
    "class RandomClassificationTreePurePython:\n",
    "    \"\"\"\n",
    "    A Random Classification Tree implementation using only standard Python libraries.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth=10, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root = None\n",
    "        self.n_classes = None\n",
    "        self.classes_ = None # Use a sorted list for consistent output order\n",
    "\n",
    "    def _calculate_lambda(self, W):\n",
    "        \"\"\"Calculates the categorical distribution parameters (MLE) for labels W.\"\"\"\n",
    "        if not W: # Check for empty list\n",
    "            if self.classes_ is not None and len(self.classes_) > 0:\n",
    "                 # Return uniform distribution if node is empty but classes are known\n",
    "                 return {c: 1.0 / self.n_classes for c in self.classes_}\n",
    "            else:\n",
    "                 return {} # Should not happen in normal flow after fit\n",
    "\n",
    "        n_samples = len(W)\n",
    "        counts = class_counts(W)\n",
    "        # Ensure all known classes are represented, even if with 0 probability\n",
    "        lambda_dist = {c: counts.get(c, 0) / n_samples for c in self.classes_}\n",
    "        return lambda_dist\n",
    "\n",
    "    def _calculate_log_likelihood(self, W_left, lambda_left, W_right, lambda_right):\n",
    "        \"\"\"Calculates the log-likelihood based on Eq. 9.63.\"\"\"\n",
    "        log_likelihood = 0.0\n",
    "\n",
    "        # Left branch contribution\n",
    "        if W_left: # Check if list is not empty\n",
    "            for w_i in W_left:\n",
    "                prob = lambda_left.get(w_i, 0.0)\n",
    "                log_likelihood += math.log(prob + EPSILON)\n",
    "\n",
    "        # Right branch contribution\n",
    "        if W_right: # Check if list is not empty\n",
    "            for w_i in W_right:\n",
    "                prob = lambda_right.get(w_i, 0.0)\n",
    "                log_likelihood += math.log(prob + EPSILON)\n",
    "\n",
    "        return log_likelihood\n",
    "\n",
    "    def _find_best_split(self, X, W, n_features):\n",
    "        \"\"\"Finds the best feature and threshold to split the data.\"\"\"\n",
    "        best_log_likelihood = float('-inf')\n",
    "        best_split = (None, None, None, None) # feature_idx, threshold, left_idx, right_idx\n",
    "        n_samples = len(X)\n",
    "\n",
    "        if n_samples <= self.min_samples_leaf * 2 or not X:\n",
    "             return None, None, best_log_likelihood, None, None\n",
    "\n",
    "        # --- Randomly choose the function q(x) -> feature index ---\n",
    "        feature_idx = random.randrange(n_features)\n",
    "\n",
    "        feature_values = get_column(X, feature_idx)\n",
    "        potential_thresholds = unique_values(feature_values)\n",
    "\n",
    "        if len(potential_thresholds) <= 1:\n",
    "            return None, None, best_log_likelihood, None, None\n",
    "\n",
    "        # Iterate through potential split points (thresholds)\n",
    "        for threshold in potential_thresholds:\n",
    "            # Split data indices based on q(x) = x[feature_idx] and threshold\n",
    "            left_indices = [i for i, val in enumerate(feature_values) if val <= threshold]\n",
    "            right_indices = [i for i, val in enumerate(feature_values) if val > threshold]\n",
    "\n",
    "            # Ensure the split is non-trivial and meets min leaf size\n",
    "            if (len(left_indices) < self.min_samples_leaf or\n",
    "                len(right_indices) < self.min_samples_leaf):\n",
    "                continue\n",
    "\n",
    "            # Get actual labels for split data (less efficient than just indices)\n",
    "            W_left = [W[i] for i in left_indices]\n",
    "            W_right = [W[i] for i in right_indices]\n",
    "            # _, W_left = split_data(X, W, left_indices) # Avoid splitting X here\n",
    "            # _, W_right = split_data(X, W, right_indices)\n",
    "\n",
    "            # Calculate lambda for each potential child node\n",
    "            lambda_left = self._calculate_lambda(W_left)\n",
    "            lambda_right = self._calculate_lambda(W_right)\n",
    "\n",
    "            # Calculate the log-likelihood for this split\n",
    "            current_log_likelihood = self._calculate_log_likelihood(\n",
    "                W_left, lambda_left, W_right, lambda_right\n",
    "            )\n",
    "\n",
    "            # Update best split if this one is better\n",
    "            if current_log_likelihood > best_log_likelihood:\n",
    "                best_log_likelihood = current_log_likelihood\n",
    "                # Store indices, not the data itself\n",
    "                best_split = (feature_idx, threshold, left_indices, right_indices)\n",
    "\n",
    "        # Check if a valid split was found\n",
    "        if best_log_likelihood == float('-inf'):\n",
    "             return None, None, best_log_likelihood, None, None\n",
    "        else:\n",
    "            return best_split[0], best_split[1], best_log_likelihood, best_split[2], best_split[3]\n",
    "\n",
    "\n",
    "    def _grow_tree(self, X, W, depth=0):\n",
    "        \"\"\"Recursively builds the tree.\"\"\"\n",
    "        if not X: # Handle empty data subset\n",
    "             return Node(value=self._calculate_lambda(W))\n",
    "\n",
    "        n_samples = len(X)\n",
    "        # Need number of features from the first sample, assume all have same length\n",
    "        n_features = len(X[0]) if X else 0\n",
    "        n_node_classes = len(unique_values(W))\n",
    "\n",
    "        # --- Stopping Criteria ---\n",
    "        if (depth >= self.max_depth or\n",
    "            n_samples < self.min_samples_leaf or\n",
    "            n_node_classes == 1):\n",
    "            leaf_value = self._calculate_lambda(W)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        # --- Find the best split ---\n",
    "        best_feature_idx, best_threshold, best_ll, left_indices, right_indices = self._find_best_split(X, W, n_features)\n",
    "\n",
    "        # --- Check if a valid split was found ---\n",
    "        if best_feature_idx is None:\n",
    "            leaf_value = self._calculate_lambda(W)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        # --- Recurse ---\n",
    "        # Split data for recursion (less efficient than passing indices+original data)\n",
    "        X_left, W_left = split_data(X, W, left_indices)\n",
    "        X_right, W_right = split_data(X, W, right_indices)\n",
    "\n",
    "        left_child = self._grow_tree(X_left, W_left, depth + 1)\n",
    "        right_child = self._grow_tree(X_right, W_right, depth + 1)\n",
    "\n",
    "        return Node(feature_index=best_feature_idx, threshold=best_threshold, left=left_child, right=right_child)\n",
    "\n",
    "\n",
    "    def fit(self, X, W):\n",
    "        \"\"\"Builds the Random Classification Tree from training data.\n",
    "\n",
    "        Args:\n",
    "            X (list[list]): Training feature data.\n",
    "            W (list): Training class labels.\n",
    "        \"\"\"\n",
    "        if not X or not W:\n",
    "            raise ValueError(\"Input data X and W cannot be empty.\")\n",
    "        if len(X) != len(W):\n",
    "             raise ValueError(\"Length of X and W must be the same.\")\n",
    "\n",
    "        # Get unique classes and sort them for consistent output order\n",
    "        self.classes_ = sorted(list(unique_values(W)))\n",
    "        self.n_classes = len(self.classes_)\n",
    "        n_features = len(X[0]) # Assume non-empty X checked above\n",
    "        self.root = self._grow_tree(X, W)\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        \"\"\"Traverses the tree to find the leaf node for a given sample.\"\"\"\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        # Apply the node's function q(x)\n",
    "        # Ensure feature index is valid for x\n",
    "        if node.feature_index is None or node.feature_index >= len(x):\n",
    "             # Should not happen in a properly built tree, but good for robustness\n",
    "             # Default behavior? Maybe return parent's distribution or average?\n",
    "             # For now, let's assume tree is valid and index exists.\n",
    "             # A better approach might be needed for corrupted data/trees.\n",
    "             print(f\"Warning: Invalid feature index {node.feature_index} for sample.\")\n",
    "             # Fallback: return uniform? or handle error? Let's try uniform.\n",
    "             return {c: 1.0 / self.n_classes for c in self.classes_}\n",
    "\n",
    "\n",
    "        q_x = x[node.feature_index]\n",
    "\n",
    "        if q_x <= node.threshold:\n",
    "             # Check if left child exists\n",
    "             if node.left is None:\n",
    "                  # Should not happen in a properly built tree where split occured\n",
    "                  print(f\"Warning: Left child is None at non-leaf node.\")\n",
    "                  return {c: 1.0 / self.n_classes for c in self.classes_} # Fallback\n",
    "             return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "             # Check if right child exists\n",
    "             if node.right is None:\n",
    "                  print(f\"Warning: Right child is None at non-leaf node.\")\n",
    "                  return {c: 1.0 / self.n_classes for c in self.classes_} # Fallback\n",
    "             return self._traverse_tree(x, node.right)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predicts class probabilities for each sample in X.\n",
    "\n",
    "        Args:\n",
    "            X (list[list]): Feature data for prediction.\n",
    "\n",
    "        Returns:\n",
    "            list[list]: List of lists containing class probabilities.\n",
    "                        The inner list order corresponds to self.classes_.\n",
    "        \"\"\"\n",
    "        if self.root is None:\n",
    "             raise RuntimeError(\"Tree has not been fitted yet.\")\n",
    "        if not X:\n",
    "             return []\n",
    "\n",
    "        predictions = []\n",
    "        for x_sample in X:\n",
    "            leaf_distribution = self._traverse_tree(x_sample, self.root)\n",
    "            # Ensure probabilities are in the order of self.classes_\n",
    "            probabilities = [leaf_distribution.get(c, 0.0) for c in self.classes_]\n",
    "            predictions.append(probabilities)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the class label for each sample in X.\n",
    "\n",
    "        Args:\n",
    "            X (list[list]): Feature data for prediction.\n",
    "\n",
    "        Returns:\n",
    "            list: List of predicted class labels.\n",
    "        \"\"\"\n",
    "        probabilities_list = self.predict_proba(X)\n",
    "        predictions = []\n",
    "        for probabilities in probabilities_list:\n",
    "            if not probabilities: # Handle case of empty prediction\n",
    "                predictions.append(None) # Or a default class?\n",
    "                continue\n",
    "            # Find index of max probability\n",
    "            max_prob = -1.0\n",
    "            max_idx = -1\n",
    "            for i, prob in enumerate(probabilities):\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_idx = i\n",
    "            # Map index back to class label\n",
    "            if max_idx != -1:\n",
    "                 predictions.append(self.classes_[max_idx])\n",
    "            else:\n",
    "                 # Handle case where all probabilities might be 0 (due to epsilon issues?)\n",
    "                 # Return first class or None?\n",
    "                 predictions.append(self.classes_[0] if self.classes_ else None)\n",
    "\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == '__main__':\n",
    "    # NOTE: Using sklearn here JUST for data loading and splitting/accuracy.\n",
    "    # The tree implementation itself uses no external libs.\n",
    "    try:\n",
    "        from sklearn.datasets import load_iris\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        # Load data\n",
    "        iris = load_iris()\n",
    "        # Convert to lists of lists / lists\n",
    "        X_list = iris.data.tolist()\n",
    "        W_list = iris.target.tolist()\n",
    "\n",
    "        # Split data manually (since train_test_split returns numpy arrays)\n",
    "        # Simple shuffle and split\n",
    "        combined = list(zip(X_list, W_list))\n",
    "        random.seed(42) # for reproducibility\n",
    "        random.shuffle(combined)\n",
    "        split_idx = int(len(combined) * 0.7)\n",
    "        train_data = combined[:split_idx]\n",
    "        test_data = combined[split_idx:]\n",
    "\n",
    "        X_train = [item[0] for item in train_data]\n",
    "        W_train = [item[1] for item in train_data]\n",
    "        X_test = [item[0] for item in test_data]\n",
    "        W_test = [item[1] for item in test_data]\n",
    "\n",
    "\n",
    "        # Create and train the tree\n",
    "        rct_pure = RandomClassificationTreePurePython(max_depth=5, min_samples_leaf=3)\n",
    "        print(\"Training Random Classification Tree (Pure Python)...\")\n",
    "        rct_pure.fit(X_train, W_train)\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "        # Predict probabilities\n",
    "        print(\"\\nPredicting probabilities on test set...\")\n",
    "        probabilities = rct_pure.predict_proba(X_test)\n",
    "        # print(\"Sample Probabilities (first 5):\")\n",
    "        # for i in range(min(5, len(probabilities))):\n",
    "        #      print([f\"{p:.4f}\" for p in probabilities[i]])\n",
    "        # print(\"Predicted classes correspond to:\", rct_pure.classes_)\n",
    "\n",
    "\n",
    "        # Predict classes\n",
    "        print(\"\\nPredicting classes on test set...\")\n",
    "        predictions = rct_pure.predict(X_test)\n",
    "        # print(\"Sample Predictions (first 5):\", predictions[:5])\n",
    "        # print(\"True Labels (first 5):      \", W_test[:5])\n",
    "\n",
    "        # Evaluate manually\n",
    "        correct_count = 0\n",
    "        for i in range(len(W_test)):\n",
    "            if W_test[i] == predictions[i]:\n",
    "                correct_count += 1\n",
    "        accuracy = correct_count / len(W_test) if W_test else 0\n",
    "\n",
    "        # Or use sklearn.metrics if available just for the final number\n",
    "        # accuracy_sk = accuracy_score(W_test, predictions)\n",
    "        # print(f\"(Accuracy calculated by sklearn: {accuracy_sk:.4f})\")\n",
    "        print(f\"\\nAccuracy on test set (calculated manually): {accuracy:.4f}\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"\\nScikit-learn not found. Cannot run example usage.\")\n",
    "        print(\"You can test the RandomClassificationTreePurePython class manually \")\n",
    "        print(\"by providing X (list of lists) and W (list) to the fit method.\")\n",
    "        # Example manual test:\n",
    "        # X_manual = [[1, 1], [1, 2], [2, 2], [2, 3], [3, 3], [3, 4]]\n",
    "        # W_manual = [0, 0, 0, 1, 1, 1]\n",
    "        # tree = RandomClassificationTreePurePython(max_depth=2)\n",
    "        # tree.fit(X_manual, W_manual)\n",
    "        # print(\"Manual Predict Proba:\", tree.predict_proba([[1.5, 2.5]]))\n",
    "        # print(\"Manual Predict Class:\", tree.predict([[1.5, 2.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10eb3a",
   "metadata": {},
   "source": [
    "2.  A **random forest** is a collection of random trees, each of which uses a different randomly chosen set of functions $q[\\cdot]$. By averaging together the probabilities $Pr(w^*|x^*)$ predicted by these trees, a more robust classifier is produced. One way to think of this is as approximating the Bayesian approach; we are constructing the final answer by taking a weighted sum of the predictions suggested by different sets of parameters (in this case, different tree structures and associated parameters).\n",
    "\n",
    "### 9.11 Relation to non-probabilistic models\n",
    "\n",
    "In this chapter, we have described a family of probabilistic algorithms for classification. Each is based on maximizing either the log Bernoulli probability of the training class labels given the data (two-class case) or the log categorical probability of the training class labels given the data (multi-class case).\n",
    "\n",
    "However, it is more common in the computer vision literature to use non-probabilistic classification algorithms such as the **multilayer perceptron**, **adaboost** or **support vector classification**. At their core, these algorithms optimize different objective functions and so are neither directly equivalent to each other, nor to the models in this chapter.\n",
    "\n",
    "We chose to describe the less common probabilistic algorithms because:\n",
    "\n",
    "* they have no serious disadvantages relative to non-probabilistic techniques,\n",
    "* they naturally produce estimates of certainty (probabilities),\n",
    "* they are easily extensible to the multi-class case whereas non-probabilistic algorithms usually rely on one-against-all formulations, and\n",
    "* they are more easily related to one another and to the rest of the book.\n",
    "\n",
    "In short, it can reasonably be argued that the dominance of non-probabilistic approaches to classification is largely for historical reasons. We will now briefly describe the relationship between our models and common non-probabilistic approaches.\n",
    "\n",
    "The **multi-layer perceptron** or **neural network** is very similar to our nonlinear logistic regression model in the special case where the nonlinear transform consists of a set of sigmoid functions applied to linear projections of data (e.g., $z_k = \\arctan[\\alpha_k^T x]$). In the MLP, learning is known as **back propagation** and the transformed variable $z$ is known as the **hidden layer**.\n",
    "\n",
    "**Adaboost** is very closely related to the the **logitboost** model described in this chapter, but adaboost is not probabilistic. Performance of the two algorithms is similar.\n",
    "\n",
    "The **support vector machine (SVM)** is similar to **relevance vector classification**; it is a kernelized classifier that depends sparsely on the data. It has the advantage that its objective function is convex, whereas the objective function in relevance vector classification is non-convex and only guarantees to converge to a local minimum. However, the SVM has several disadvantages: it does not assign certainty to its class predictions, it is not so easily extended to the multi-class case, it produces"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "aaf1650b",
   "metadata": {},
   "source": [
    "solutions that are less sparse than **relevance vector classification**, and it places more restrictions on the form of the kernel function. In practice, classification performance of the two models is again similar.\n",
    "\n",
    "### Applications\n",
    "\n",
    "We now present a number of examples of the use of classification in computer vision from the research literature. In many of the examples, the method used was non-probabilistic (e.g., **adaboost**), but is very closely related to the algorithms in this chapter, and one would not expect the performance to differ significantly if these were substituted.\n",
    "\n",
    "#### Gender classification\n",
    "\n",
    "The algorithms in this chapter were motivated by the problem of gender detection in unconstrained facial images. The goal is to assign a label $w \\in \\{0, 1\\}$ indicating whether a small patch of an image $x$ contains a male or a female face.\n",
    "\n",
    "Prince & Aghajanian (2009) developed a system of this type. First, a bounding box around the face was identified using a face detector (see next section). The data within this bounding box was resized to $60 \\times 60$, converted to grayscale and histogram equalized. The resulting image was convolved with a bank of Gabor functions and the filtered images sampled at regular intervals that were proportionate to the wavelength to create a final feature vector of length 1064. Each dimension was whitened to have mean zero and unit standard deviation. Chapter 13 contains information about these and other preprocessing methods.\n",
    "\n",
    "A training database of 32000 examples was used to learn a nonlinear logistic regression model of the form:\n",
    "\n",
    "$$\n",
    "Pr(w_i | x_i) = \\text{Bern}_{w_i} \\left[ \\frac{1}{1 + \\exp \\left(-\\phi_0 - \\sum_{k=1}^{K} \\phi_k f[x_i, \\xi_k] \\right)} \\right] \\quad (9.65)\n",
    "$$\n",
    "\n",
    "where the nonlinear functions $f[\\cdot]$ were arc tangents of linear projections of the data so that:\n",
    "\n",
    "$$\n",
    "f[x_i, \\xi_k] = \\arctan[\\xi_k^T x_i] \\quad (9.66)\n",
    "$$\n",
    "\n",
    "As usual the data were augmented by prepending a 1 so the projection vectors $\\{\\xi_k\\}$ were of length $D + 1$. This model was learned using an incremental approach so that at each stage the parameters $\\phi_0$, $\\phi_k$ and $\\xi_k$ were modified.\n",
    "\n",
    "The system achieved 87.5% performance with $K = 300$ arc tangent functions on a challenging real-world database that contained large variations in scale, pose, lighting and expression similar to the faces in fig.1. Human observers managed only 95% performance on the same database using the resized face region alone.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "a) Each weak classiï¬er consists of the response of the image to a Haar- like ï¬lter, which is then passed through a step function. b) The ï¬rst two weak classiï¬ers learned in this implementation have clear interpretations: the ï¬rst responds to the dark horizontal region belonging to the eyes and the second responds to the relative brightness of the bridge of the nose. c) The data passes through a cascade: most regions can be quickly rejected after evaluating only a few weak classiï¬ers as they look nothing like faces. More ambiguous regions undergo further preprocessing. d) Example results. Adapted from Viola & Jones (2004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b494ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of female face: 0.996532654021118\n",
      "Predicted gender: Female\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit  # Sigmoid function for logistic regression\n",
    "\n",
    "def gender_classification(features, phi_0, phi_k, xi_k):\n",
    "    \"\"\"\n",
    "    Performs gender classification using the logistic regression model described.\n",
    "\n",
    "    Args:\n",
    "        features (numpy.ndarray): Feature vector (x_i) of shape (D,).\n",
    "        phi_0 (float): Bias term.\n",
    "        phi_k (numpy.ndarray): Coefficients (phi_k) of shape (K,).\n",
    "        xi_k (numpy.ndarray): Projection vectors (xi_k) of shape (K, D+1).\n",
    "\n",
    "    Returns:\n",
    "        float: Probability of the image containing a female face (w_i = 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Augment the feature vector with 1\n",
    "    features_augmented = np.concatenate(([1], features))\n",
    "    \n",
    "    # Calculate f[x_i, xi_k]\n",
    "    f_values = np.arctan(np.dot(xi_k, features_augmented))\n",
    "\n",
    "    # Calculate the linear combination\n",
    "    linear_combination = phi_0 + np.sum(phi_k * f_values)\n",
    "\n",
    "    # Calculate the probability using the sigmoid function\n",
    "    probability = expit(linear_combination)\n",
    "\n",
    "    return probability\n",
    "\n",
    "# Example Usage (Illustrative)\n",
    "# Assuming D = 1064, K = 300\n",
    "D = 1064\n",
    "K = 300\n",
    "\n",
    "# Generate some example features (replace with actual feature extraction)\n",
    "example_features = np.random.randn(D)\n",
    "\n",
    "# Generate some random parameters (replace with learned parameters)\n",
    "phi_0_example = np.random.randn()\n",
    "phi_k_example = np.random.randn(K)\n",
    "xi_k_example = np.random.randn(K, D + 1)\n",
    "\n",
    "# Perform classification\n",
    "probability_female = gender_classification(example_features, phi_0_example, phi_k_example, xi_k_example)\n",
    "\n",
    "print(f\"Probability of female face: {probability_female}\")\n",
    "\n",
    "# Example of how to determine the predicted gender.\n",
    "def predicted_gender(probability):\n",
    "  if probability >0.5:\n",
    "    return \"Female\"\n",
    "  else:\n",
    "    return \"Male\"\n",
    "\n",
    "predicted_gender_result = predicted_gender(probability_female)\n",
    "print(f\"Predicted gender: {predicted_gender_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b9ef9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of female face: 0.9999999996095736\n",
      "Predicted gender: Female\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Calculates the sigmoid function.\"\"\"\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def gender_classification(features, phi_0, phi_k, xi_k):\n",
    "    \"\"\"\n",
    "    Performs gender classification using the logistic regression model described.\n",
    "\n",
    "    Args:\n",
    "        features (list): Feature vector (x_i) of floats.\n",
    "        phi_0 (float): Bias term.\n",
    "        phi_k (list): Coefficients (phi_k) of floats.\n",
    "        xi_k (list): Projection vectors (xi_k) of lists of floats.\n",
    "\n",
    "    Returns:\n",
    "        float: Probability of the image containing a female face (w_i = 1).\n",
    "    \"\"\"\n",
    "\n",
    "    # Augment the feature vector with 1\n",
    "    features_augmented = [1.0] + features\n",
    "\n",
    "    # Calculate f[x_i, xi_k]\n",
    "    f_values = []\n",
    "    for xi in xi_k:\n",
    "        dot_product = 0.0\n",
    "        for i in range(len(xi)):\n",
    "            dot_product += xi[i] * features_augmented[i]\n",
    "        f_values.append(math.atan(dot_product))\n",
    "\n",
    "    # Calculate the linear combination\n",
    "    linear_combination = phi_0\n",
    "    for i in range(len(phi_k)):\n",
    "        linear_combination += phi_k[i] * f_values[i]\n",
    "\n",
    "    # Calculate the probability using the sigmoid function\n",
    "    probability = sigmoid(linear_combination)\n",
    "\n",
    "    return probability\n",
    "\n",
    "# Example Usage (Illustrative)\n",
    "# Assuming D = 1064, K = 300\n",
    "D = 1064\n",
    "K = 300\n",
    "\n",
    "# Generate some example features (replace with actual feature extraction)\n",
    "example_features = [0.1 * (i % 10) for i in range(D)] #example list of floats\n",
    "\n",
    "# Generate some random parameters (replace with learned parameters)\n",
    "phi_0_example = 0.5\n",
    "phi_k_example = [0.01 * (i % 10) for i in range(K)] #example list of floats\n",
    "xi_k_example = [[0.001 * (i + j) % 10 for i in range(D + 1)] for j in range(K)] #example list of lists of floats.\n",
    "\n",
    "# Perform classification\n",
    "probability_female = gender_classification(example_features, phi_0_example, phi_k_example, xi_k_example)\n",
    "\n",
    "print(f\"Probability of female face: {probability_female}\")\n",
    "\n",
    "# Example of how to determine the predicted gender.\n",
    "def predicted_gender(probability):\n",
    "  if probability >0.5:\n",
    "    return \"Female\"\n",
    "  else:\n",
    "    return \"Male\"\n",
    "\n",
    "predicted_gender_result = predicted_gender(probability_female)\n",
    "print(f\"Predicted gender: {predicted_gender_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed1cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
