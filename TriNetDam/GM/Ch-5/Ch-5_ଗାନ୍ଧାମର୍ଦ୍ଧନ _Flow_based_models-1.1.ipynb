{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2004 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAATcAAABlCAIAAACncTMtAAAgAElEQVR4Ae2dd1hTybv475+/5+69d/e7fne/u67uuqvbXPu69t6wgQgq0sVCCxBqCqEjCAJ2EFBBQUAQEMXQJFKlQwKEFkggdISEnpCckt9zOGwWUSE0iXjy8OjknHfaO+8nM2fmnTn/JcE+mAYwDci3Bv5LvouHlQ7TAKYBCUYpZgSYBuRdAxil8t5CWPkwDWCUYjaAaUDeNYBRKu8thJUP0wBGKWYD/2gAhmH0y98BGIbhxuae0LAyAICQL2MFJDAMZ71qys5peDMich2GJTze4P0HZWIx+E8eWGjyGsAonbzO5m+MNyGEYRgSCod8ruXVsrvQSr8pgFyDYTg1rSEto14iQQh/UwCGYTAxhVVY0jZ/dfYhaoZR+iG0/FHkMdz7jf4HgmAgr4B7w79ALBaPvjEmPExpw+iLw90uBMMQBIO9fYPhUVUfhQbktpAYpXLbNB+2YLBkcFDY2dUvBkR8voDPGwCRD3DVr6CM2QFBoFAENDb1NTX3Nzf3icWi9vb+pub+1rZ+AARoadz0jAYYAnn8fg6nu57Tw+F0szn8rq5BCAIhCE7LHBkPf9gqzZ/cMErnT1tOpyYwDIeEVzi6ZQY/KH0QWnrZO6e0ok0kAkiO6Xz+IAxDnZ2Drpeyjp6MOmNA5fEG3S5na517evXmK4FwCKUUBKHQ8FLNs89u3Co2s36xWzE8NIyBMArD1SzedMqGxcUoxWwA0QAIQrFPatx9cu7cLxENiZ4+r3Fzz+7uEVpR0oRCAHlChWGRCAi6Tz+gFHEvlE5xSmfVdgIACMMwLY2bltEAgsDtoOK07PoSRpviqShD82QefwBC4sHNLX2YlqejAYzS6Whv/sSFYZjfLTDAJ3Ibe0AQ8AsodHHP5vEGrGzTRCIERfQjHBJ6XcnZsDfkYQQTRBhFbqWmcdMyGyAI7O8frK7uVFSLUtN9Ulv7mtvQCQ33pR0dA/NHU3NRE4zSEa23t7fHx8fPRRPIS57cph4D06TBQeGQSGxm8yIpub6vX2hDSRMIkL4UhiUwLGlq6jG2SDKxSlZWi65ld6EQpqY1vsxsgCFkQtjWibb7aHhmTj29tN3zah4EIn1pU3PvOJUsLi7OyMgYRwC7hVE6YgN4PH7jpo2fsEHAtPQGfdPEgUFhQVGzFTmlr29IJBaTHdO7OgdhGBaJxXWcbrJj2pPnVe3tPSfPxBrjk2rZPJEIGKaUC4DiZ9SabQqhPtfzmpr5Hldy/AKKQRCAYaiiqnMcxWpqaWpqao4jgN3CKB2xgR9/+nHpsqWDg4Ofpk3AEonX9TxXj1ePo2tCwpiNzd0QBEEgEBhEzytogiGwo6PXz7/Q60p2SUmzQDh0N6jI68orv4CCrs6+4REvVyQCIiJK3S9n3bidd+N2nrt3Rl4+F4IAEASTU9nv0yoAAAv+veCHJT8AAPA+Gew6RumIDXAbudHR0Z+sQUAwfNYooaS0DQCQ3m/4D4aQbvD15et5IpF4eAkUnUVC7/79LwSnpjcgI953fiDwdWdfeCRzHMVyG7ncRu44AtgtjNIRG/jEKe3vFymqRVET6wBAjDyBDnsCwjA8JBLd8qeXVXRIr6D6GvExGhZNTW+QroiOXB9xQoIhCHoSX13O7BiHNIzScZSD3sIoHVHRJ06pWAzVsrsbm/rQCaHR/WJ3tyD+OUvqxzv6FhoupreVMFrfvg7DcFfXIDWpDgShcQwRo3Qc5WCUvqGcT5zSN3TxYb9glE6ob6wvHVERRumEtjJLAtHR0dhz6fi6xSjFKB3fQmb9LkbphCrGKMUondBIZlcAo3RC/WKUYpROaCSzK4BROqF+MUo/Vkr5PUIQhLPym+nMDhCESO6ZJPdMiUQSEVdFckMc7pCAewavWygN0JkdJPcMOrMDDUTEVfG6hf6hjAQa4nVAcs8MCGVIJJIEGoc+vHYiEH4IT4Po6OjCkhoWhw+CEJ3ZkUBjC4QAWma0qAk0dktbv0AIIIH2fhCEW9r7J7Ts+SSAUfoRUMrvEQqEQEtbv6dvPp3ZweLwSW4IbAKBuKWtn9ctnFmLbGnrp5cjK5wIzG4jnHv65guEAFKMYU6mk6MUM5J7Bskt09vbOySyIDO/CQAhXrfwndURCMQACKGVFQjEVBo7Ig7ZWU5yz/D0zZdIJCwOn98zw3qYTh1nNi5G6Yg+5Wc9AARhEITpzA5P3/yW9n46syMirqq5rR+11JltftlTA0AIACEWh59A47A4fLQ3Rrs4Gbtcfo8wK78ZRYs63HujufsH+HO50/U9ysxvioirRBJ3y4iIqxIIARAcOcNJ9jrKrSRG6UjTzC2lAiGA9I3oSM8tQyAQ87qFAoFYbu0GLZhAIG5u6/cPZVCHh6kJNM7bHZpACGTlN4Eg5B/KYHH4b9doRigdnSzaGyfQ2AbEFH6PsKUdGS2PFvjowhilI002J5SyOPyAUMbwExcna3jI99EZkLTAaE9LZ3bwuoXoyBwl1tO3AB0/SyXHBGac0jHpszh8T98CfreQzux4+0dkjLB8fsUoHWmXD0lpVn4zyS0DAGF6OWLT8mkZ0ykVAELnrJKuBBaes0zMK2odP6nZplSae8twt8/vFg7PVH1M42GM0pFG/ACURsRVGRBSAACZIwHGdW2VGtZHF2Bx+AaEZIHwn7E6r1vYyRtUvfC0ijVyXOiYSn0wSqX5ItNv7pkf0bMrRulI280epVn5zQaEFIEQedSUGsr8C6DjAhaH/84fIHT+tqKmK4ZaM0bgw1MqVT7JLcM/tFT6VW4D85zSrq4uGTd2V1RWzKw36fDjELJ6Mb/hRC17eIq1agx+7zT6AkZrTlEzOjGGys8hpRKJBJ2lQ6e15HZaeJ5Tml3IKKziJianvNNiRl+cKQ8YEIQTaBze8MOP/E/SjtbAFMIA4k2RkZnfNNm4d8NK3W/khsUiaydzS6lEIgFAyO167uP46vTcSVdkshWfmvw8pzQuOYPO7aWzOyY8sGP6lAqEAL9biDjuDLsETK09PpZYAOIn1D4oQHwtplBmAIQUdWNP6j+VB0pRULcph6O/GlOozmxHmeeU0llNdG5vEZsXeD98fFVOk1Kpm874ucybuwaE5Gn+GAEgpGaIHNoYEBjQ0DD3h9+/7hqMS6qVzwb6JChFQX2emDxOG0yNUoEQCBhe0x8n5fl0a2QKd0ruFuhhDiAIFNW0OEUziI+Y5Mhyn6dl0dnVXT39bfy+voHBxAK2UzTTKWa8c5Kmo88TBpvxzspeAbhrD8z8omzuJ9rHpjs9f3UxJuly4isvas7F56+cafneJYyIkrzwjBfXk9KcU/JIT9OIUamEvLKI6WQ9nbjznNKRES+3l87tLaxtF4nf64MyWUpBEEZ8R7uFUxvyTafN5iQu6mFLZ7bLMkX0zhKilHb3DT5Kr7aLLHeOYTpEMy/dp5pakmNeFkVmMItYrUnFDW5xFY+yZqtPuxtr+YBq/TCJ+CzbMTnvUmLOpahUOx8/a5tzxlHePrSYWwXZ0RUpScXBwfn3guMcnJ9d8UqJvxxDI8W8pOSWP3pnvT7AxXlOKTriRR5Nh8e9t+6FvU+nk6IUBGEDQsoUZk3el7ucX6cz20lumVOeDJMeiSQSA7SSusBEpnM00yGmgnQtfM/GLUd37HCNzL3zgnUntTqYVvUkrz48o2aWFBKWZB2Tav88zTU+0+V59sWn6Rdd3M3UdhwiHzjmoqwRZGyWczsg3dMr2Z6S4n7JS0uHfORYsJ1zYrRLVCoxt2yCh6ZZKrNEIpnnlHpe80URlf4bERP3Tm3KSCkIwsPO3P+s2r8ztflxEQAhKo3tP7ydbTo1Ql6RCIFiMSASiZnstrsvqh1jmG7RJSeOKP2xcMnpwwc8nhT7v2B5hSTde/CwoLo1u3y25lpDn1pTs1ypmRefZbtQX7kFRZCV9xww3rgTv/4vooKSncLBIAP9ECPjEGNchKVVqKUFYe8O+5Pqd10Mol4SC6oip6OE6cSd55S29QxJ+UQDz7PLunvfMS0pI6XojpDpaPyjiItM4ZYj3v/TnCJCKzs0JBKJgcbWrtLa1qDUKofoMvuYSpewV7vWbli3eMl5hV1eUa88ghNOHjru5Whbym5JoSNbZ2bjk/LK80Wed3Kez9Osi2HxdidOHj/08wrDVas0ly0127HXbu9u291bKAoKjopK3qdP++npuisr4Hdt89BXinlhW1L9ZDaKJEua85zS677+YyhNY3Ai4l8C0Fg3zgkppTM7pt+ryNIkcy4DgJABIYXObJ+pkoAg0pEy65pTC+rup1V7PmP6UKs978UdXbPqyG/LNP5aa29mrq58etPSFbevelKLGwJe1s1U1mPSSaf7JOa6vcj3pr7ysnPVX/vzGuUflyn+8OPehYs0V63Bb1xt/NcvWquW665dY7Jjm82ujQ6Ht1/YtNZDXznplWtRVdSY1D7Y13lOafPrniI2bzSoOdVtdG7vnYinQtEbo9bxKRUIgfAn8/+F1gk0jgFhvJnwqdklAIJtnfymjs7uvoEBobC1q7u2tuqKtcG5Db9aHt5traGmvXPr0RXLFTdspCYlZ1S1BGdzppbRhLHCqKYhz82iX1o/TaWcOKW0bvFvCouXbl/4/baFi5R/WmKwaoneiu8Uf/pGceki9ZW/GP71q8GfS48tW+JpeirxlUdx1buflSbMdPoC85zSOk4DiqUU1NCnNDScU90WG58g1eA4lPqHMiY1cSIWizNzCph13BRamjR9eQ6g+1oFAvE7939Ov+RDIlFjWyen5TWD1dzV3dvS3n7N1VZl7coz63+1VFO56X3F25Zkf3xD2J1bxezG1q4eGnO2RrwJWc5Jry4lZF98GEvesnnn1kU/7174/Y7vvl/97y93fvPlyZ++Ov7jl3u++2Lfon8pLfv2xIrvtn7/+cav/s8Od+hFkVtpbez0VTG1FOY5pf0DA4m5FVJE6dzeMdDeuPuwobWzvgF5Scw7/XiRo3dk9iUaGBho5w86ely/E/mczu1NY3Bqm7omdHuaWsvNSCx0h3QCjT1LfKKFhGAIhMAuXg+b21rf3FpRXUsx0j6ydrXG2uVntm10I5A8zqsF2yi3Nte2dvdVcDsY9eO9sWI6FU/Iu0SjX0mj+3heN1n121/bvv1u96JFG779z29ffrb26//d+c1n2//z3xu//mzHN/97YMmXvyxaoG9wYPdPX11106DmuDJYMdPJejpx5zmlAACMwdLx8o3R0KLhmNT8hMyi6KeJdZyG0VAl0CYx9Orp7fO7/yinuq2IzZNmml3RXN3QMp0WmqW4IAhFxFVNdpgwtcKAf38EQkFPbx89O8Xm0PozG/7QWPuHzpZNHk4Xb9laXdU+QM9MAQDxoEjcJ5itzUM0hs/L0uspeZ7qmqrLFy7b8u03Kht+X7Xw85Vf/r9VX/63wu/fbPvl6/3rvldc/e2Gbz7fu39VRALh6KYldwL1U0s8KhqeTa360481zymVSCS3g8PexpJRWs+gs9HrhewuqQDKmLPH1fwyFsX1jk9AHquWPTAwMBrdt5XOZDIfPU0MiXuBppNT3fY8u0yaZnB0Ultb29ux5uoK6j/0IZ0xQBAEAACCINHQYGttaYidrtGWX/U3rtBdv8JE6eg1n+v3r3je0lN4+TRCJBaBEPJ+8VlSTkqB990wi1v3zNev3fjHgq/3/Lz42s2zasqr137z2eqv/ptifvBxEvlZmhPB6MDen7+9EXiBmuNySnGNh4d2cvFFBhub452lZpFIOvtEUmDo3F7HyzdK0wtKGnrKqbRqUyN67evRd9FwEZuXVdGSx+KhvSI1uyynus3jRmBBdQvB3rWxS+Dg6l5ey415lpjwMieNXpeYW/GiqFaazui+FL1Ywx3vNbuzVvU3Em5p69cnpNDLO6bsPPRGcpP5gq6WtrKZ8deJ/rprHQ4s1d/4u8nWP4y3rrLV1fO9dTs6KCDxulkzl9PVxRsaGpo9Sp9nOvvfMVLYsfuXhT+sXbDgrNL6mDS7wHDDvau/27D4i+v+Z14wvKl5Dtqndu5ZsSgi3iY++6LaiY0EikpyoWdp7Zy9Kn7+96XpWTmjp3nTGBx6dVtJQ09JQw+jsJqlr1ccGScFDA2kMTgaprF5rDcmh+nc3oLaTulQdnSUnOq2e6Ex5RExLA3VajNcWcC9vILK0QIPYlP6+9+xSDsZU5+ibEtbv/RY0A/PJ1ro9sa65GCv6+cVbHb86LDnP6abf9Jb/6vVjhUWO9bYamj6Xb8WF36XHn+ttpbT1NjM5/EFg4Ip1naiaEnFDtcCjVb+unLZgm8Ulv3oefFUfIFzfL692qmN65cvDqPik+muCYUu14J0D+/7NSzBKqn4EtlF1dFDnVbqUc7F+tKJ9Dvl+xAMj0YrJjW/PDahpKGn2sG+7uieKs/LNVbmZdSXo6HKYL72CqKPvoKGM0obsphNJQ09Y26VxafWHj9YRqXROTx6TXtBSnYezpClfaq0sEoqGRb1QeceWtr7DYgp6LmE47+YcMqKlT1iSUo0fvNis01Lzq37Ab/pa9zGHw03/EHatdJi21o7Pb3b169ERz5gFqbW1TU0Nja/fs3jdXXLnvikJONznSwtj/3+9bdbvl2osnypl8fpp/n2zwtdrJ2Orfvz90ia5bM8SlwuKSrdSkNzW3iSzZM8O5+7Os7epxML7Mo42BzvpJQ9GeHBwUFqRqGUlsTcioLkrNJsBnvvJnpNe6XnZZa+XpWbe5X7Jfrf+EW9oN+PSZZGkQaKOPzgmOQxlJZRaSVEG6SLHvYWpnN7i0vqXpXU0Wvaqyi2LO1TjLKG4bll5A2fkyn45GRBEBIIxPTyjlFwzmJ2kypcbkL0ufU/6KxZorFike6qb4w3LDq77hfL7b8Rjuz2caDc9LoYFRnaze+CQHDk7alv+ZxMKrtxhGNzbW8Fa61fuui3r7/a+9N31iaHHtOc4rI8fMMNd+1b84hm8SSX9CyPEpZgflprX9RLq5gcc5/7qng7xWfZxKIazI93HNVO+1Z2IUOKEDo/xLwTzDI8X+l5+XFKbkXwQ5a+XjmVxtJQYZTW57F4TjfzpfKjAyUNPYm5FaMpLU3Lr3J0QNOkc3hVtmT2ng1VJEL07i3VJkb02g5GQSXr9HF6eSOd20txcJqwKg1cbmv76wnFUAF0hbO5DTlZGzlie0obsmXMazpi2dRYnTWLlX/9XvXXb1V/WWC8/mvdtUtsdi52OKPq5UC6TDSLenBHKByUOuXP3s/Zs2yL0PgLm5cvWvrl53uWL755Vy8m0zEqnewXeX7d+j+8gnRjc6yf5tqEPDNRUt3z+KVlTLqZh5+qqtb2mDSzggqM0ulYwURxW9v/mSLKqW5DHRsqAoM4a5fe27GJUdlcOTzuZdDraqzMg0y8Ypy8xqyySln1uHXvH0o5vFrlg3QOj5pdlvcyv+acdnnoIzqHjwqXFlZVXvaqvOzFKGuoO36QUdZQxOaVlb975yQAAKw6zsNYqtPl67f8br+vQugB8/TyDk/fAhaH39LWn5XfJP9HQmc9jzn+2yKFpd8pLfvPuZWfW2z+wmrXItO9S/SP7nIy1vUhGAf7+jS3tPB7Bto7u/ndfd3dfe/TwDSvx2WYxaTg969a/OfXn5vpbYl7ZROf7/Q018b7zvHvv19iSDj6ONPsEc3I+fpJDf3dgU8uBDzRv3j9pIWtclSKVT62v3Sa2p8w+kWfW1LSpAFmSMQjxYMsbbXKm35VTk415qZ5udXBz6qr3NxLGCPrNFJhNJBcUI3OPCGzxNHPmYHBdG5vSXxqmZoy8lD696A34l544dNkOodX4RdYg8cxyhpYZzTo3F5afuXr1290lRVV1XUtPB//kJCnqamF1bmFxdK6oJM99PIO5OR4gTgirkr6sha5PUdLWvjRAdrT6P1L/rN3ydd7l3x1ZuX/Oe//l9bWnw5tXGWhddJZX8PT8sItV3JqctLLTPqL9KJiRnU1q3509BkM+z85fe2B4pHV3x38Y5G79+HQZIOoNKtImokZ6dCqNcvxdod97p+8EaJ+I1zl8oPjV8NPXg1Ru3hb2cP/xM2H59IKgmewJJNKav7P8aLqGBgCpTO93v4hUpzot24zKpuZoZF1Kofrju6J37DXxjM7Lz6VftPvH5m/2aNze+PSi59lIhNLJQ09NXgcndtbmllUaUvOoHOyqzrpHF4NHsfes7Ha3q5211/IEymHV6esQK9qYQbcLc0upXN7H1HTuF2Dt+7cz2OyHydn342ippXUx7ysdPT0R3eKoa9Ok76nCH2HwqQaVd6Ek2Oj9vywYOeiL3cu/pfOui9tDizcvGzhzjW/krSVyFrHyLoqlyzPx0UGV9fUcZtaBwYGxeI3XKxnsDpeoarXH2ocP7byyOF1l/20AqJNAx8b+UfqOV9Xdrx27HLwSe8QFe8HKl4PTl6LUPeN1LkZfuZaqM61ML3bkUbJuXdmsCSTSupTobSzs/PZy4K3wSusfV174ii9pr2koSc7rdRYL0hBK9o/ModhYvy2MApnbjUiTK9przE8R+f2IqzWde5Qebh63/04r5D0izcrrt3IOmv0PKG4oI4Xlcrx935WGJ+WmsIIJAW+KG6NSuUYUFKjUjkRiUVnbRLsrtLSy5qtHELQlxF+pK9IGN/mkmMfb134xeZvv9jx/b9Pr/1aa8N//vxx4b4/V1L0TlG0Ve20lN1NNDKSHolEQyOzR7M5zTZ+UeXz7qdCqUQiqarloDOxb/Sl3F567WtkgpfbezWEsWb/gzX7H+Bd02u11d5JKZ3b6+KNdLNltNxKn6sIq8M96lG92B2qj64F5gY6PCh7kvCioOlFcav7jaCXEYlZmmeLajuLgiJSn+Wgzr2FdV02jpeK2LzQp7SAhzGDQ7PVdciJzSXFRK5c8NnGb/9vz/f/Uvp9wcmVC3b8tkRjz1aShpK9nrqj7klXY60cWhz0t9fR7M0eyYlCJlsM+aUUbSppg6EBEATAwUGJRPL2XbFAAAHjmTsAAHXtfahjkHT0i3aP9PruKvdLCRm1G48iXaK/2+N4C4v3UfqqsiW1iFVGy61yckLHvWVJGUVs/o37sWOilCVlVNlRAh7GZkU8KVNTDotPe1FUezcqoYjNc7x8I4/VcdP/rryslkzWcCYjnxQTueqrz7Ys/N8t33y2+8cvTq3+8sRfS3EHVpsf2Wypso+srkA20mioZUo7UmmjTyaT+Sz7kVE6yGJ2DU+Bvk1pf1V1z8MJnu+ZzIoX+ZWJuRWj/RxG0KrvrnRzqwh+iCzJ6OvRK5vHICf9WsjuQtdj2Arb6Q09JRweM/QR64wGM/TRHQvLkpd5ZffDa/C4Gjyuwi+Qzu0tj6WyzmjkVCBnjvqHxSXmVqQxOJeu+L69E32+GtqrF0/MTq7R2bd8w7f/s33J51o7lxof+t1oz8+mCqvNFP90MT1RUpguEiOOgWOadb4qZLL1+mgohSAIAIDXzraiIcR9bExzwsNH63QEevfXlY+vAl5PX/jzjNELLdkVo4Bkd5XmltMrm0Of0kY7KqCIlhZWVfgFVl728g9/mlrEQv2WpJ7ApYVVpZlF5bFUakzCiyJWQPiz+37B5YbnX3pdKWJ1oMs/OdVthbXtcc8Txy/kPLtbU/LiBmG3q8Gm/b98sfenL5Q2/II7/Dv+4C84hd9t1LdRo4P7+/pEoqGhISEIAlJWRysBTz5mRT5FpJw0Jx/DEQ7hiAoGVnsMrPYYWe01Ix4wJx+2JCrirBXw5MPWtscsiEdMiYeMSQpGxD361nvOW+40Jh4MCr80OsGPKyyPlMIwAuGYDwRBPSlUfuR9AED2TIx8IPR/EEZ2MEKC9pYOswvjNwAAAM2dyM5Pad/4vsBoGbQ/rPALREGl55anMepLGnoqAoNqDM9V+AYgiBZW0Tk8NFDhF8g6o1F52Yte046mX8RGfPd9btz+FIa44zfBmLtGxkZjrrz9FUdUwltpmhO0DCwUDW0OGRMOGhIOGZMO44gH8LYKpuSj+jZHjMhHDAgKhoQjRsRD+jb7jQhHTEiH8RQlE+JhE+LRe2Eebyf7sVyRR0ohGAYAkWhocAgQDQ0JQFCMrOZDYKOBFtTKRe5C4FB3l4DX0c9v7+e1CzvbALEI5bUdZwAD7z10F20VAAAy8/9x043P+sczaTSxaO+HLnUyQx8x8pg1OIPak4p1xxFPhqDoJFS4pKGnNL2gPJbKDH1U4RfIDH1UHksd7cFL5/bGpOYXMWvrG6b7XvqPxaomVc4L+hP8sEokkvMW+x0cbS+6XvEP9Lsd5GHpoK5ntkfbZLOe+RZ96z1GxMNnLPdpmW/Xtdysa7lZy/xPTbP1OuZbdfE7DWyO4kjHTMnHAx+6TapUciUsp5R23rn+2ty0++G9nkD/ViNTAacOEglYirshCIAhWAxBTQbadedOdHi5NO1cX7/lt75yBtqttgbehIUy7aggOblJMfvHnWjU0mhibkVeQSUyhVtaX020qTbWr7xxq8L9EtJDDouFxadFJmZLnRxGEy4Nx6TmN3cNYHyOY/SyUGpoftDe3s0UZ3v54o3A28HRjx/dCbpkd1EHb3vUjKyob73/jOUubfxmHfNN2uZb9Ky26pju0MHv1DPfd97yoCFBCUdSuhfmPk4Z5PyWPFIKi0RtDwK5Pg680FsABHYH3Wt2cwTauI1nVUcGuKCowQwnGuh/HRnSuHF5q+81MfI8g3Da8zQKknmP2N2QiJzqtpL67uL6bilX0kBxSV21mXHZo9iLCuYPLj5k0OtYasosXXWpjxHKdmRi9shE8SjCi9i87LL66KcJ/QMDcm4Bc148WSi1ICpTKA5n9cysLexwOGsbK7uo8Cd52TmZGcmPon0tKKrGhAMXLPdaO5+8HuhATXkYn/zQ+7btBevDOqbbDa0VzEiKIZFec17TKRdAHilFjskRA62aSqJevhgEWyhWnRawnz4AAAulSURBVK6EofrKZlN1dNIIhGFADPSlpbC2LeUH+At4vKGebrQvFbxMAvtl9QIdHBys5LSkMThpdM7b3Wm1vV2kgQH+kOPqffdX77v/SvVUNcG6NLNIijEKZxqDE5mYHZdejKaQxuAwm7pv+gVgz58yGqUslFqRVSgk4vkz5030dXBGlmcvWJma2lKfpTBLa3idvPp6VmUVncUqa2trqq1hU5/TiouZtbX1eUWZePtT2rhtRub7gkOwvlTGBpFNDIbhoT4+V3M3AEEi4UDt4S09mYlARytXR2mEUhAWvm5t3LejVee0SCTquu/bnZ6K9qWDcVHQwCT2WwMA0NaFPDeOZg8J17RX29uxNE8YkmNW77t/XOFqlYtLWRLynkUDSqoBJZXO7Y1K5fhFMvNYPK+gEn3blIs3qTfuPMfbpzS29PB7hAk0Np3ZAYJQS3v/vPQokq0xJ5aShVIbwvGzKvtxhsdINqeNz+teMLDUO2fp4HDF7+YDWkpORTm7pppbweRkZTNiYlNMLRxMzZ3tHXweRcQHBHnpmW03tz7wMMxz4qLIq4Q89qUwDPdlpjZf0BEDUE/K8xazcyAgAoAhjuIuGJnghQAQbHe0qd30Ux+joL+lsVn1cG9JMdqXdvq6yfhcOrpFsnJy70cn5P49H4t45xZWIfNAoY9SFXYVWxFYuuooomNhRg8lbODfDAgeEkNDQ0NosgKBuKWtH33PNJXGRk8hJLlnSn10I+KQ033ngY/uaDVOLSwLpSSyCt70iJXVMTJZ1dxYTf8C7pyBrQHO0RDnYGBMJhDdHZ2vURyuWtp4GBiTjYytcaa2OFMy3pziftEJZ6OIszr0MMxnasWTh1hySulrH8d2N9LrmAe80CDR4CA8fFZkB9FwkFMFQbB4SMi54s318Ki/caXe06Pe23mgow2RgaAm/eMwBE5Bs8H379c1jmxqQ1FkndEozSyq8AvM01Ibc0IK+m6onOq2uOSMqlrOwADiDjWpD68bOSZvZL+LEIiIqyK5Z6BvcGtp7/+4trxMquJvC8tCqQPltLODppOdpouDliNF29jQyMiEom9MOXuBaIizMTUlmJjZmlnYm1k4mpkRLPB4PN4aCZhbW5gYmNgoqxts9guaeHPv22WTkytySmn96YP9zHL0OLm/l0bBAUZeR7AfCIIwjC6ZIt2nBB3pIl4NQG9tRbuj2dQ0e+cOsuOhs7OzrrEtIv4l4pzE4ZXHUv8+aaHNPywOXfOMiH/Z8Lr/YUTkbDx5trT1U2nsllEbu+V/++jUFC6NJQulTnZaTnYajrYaznYajnaapsaGOBMrHM5a38jKzNTcCm9lY2NLJFKIBJIl/oKJ/nG8kS7e2Mjc2Oj8iYMUO00Tm4NBodhKjFTlMxEYamA3bFrJS6YC0DCHw2nCMAiCUJe73VBf7zt9jwAI6rjpJmyZ4uG3Y2yFU99Q19jmc+N2Q6fA85pvbTPvRXp2fVN7e8fr8U/9nAkFjKQhEAICIdDSPnK8GL9bOKtnW89gySeV1BjNvzOus52Os52Ws72OA0Xdwe60uam64XldU2OcibGxiaEOHnfWwtyQYKlvSzhPJpwmElWszDTMDM+Z6mmdP7zVkaBiTNgbEonNHr1TtVO9CA/0gS2NYFvzSC866j9RR1NHTOSoC/8Eu1nMvmwaNNVNT7LYylQrNDPxBEIggcbOym9qaevPzG9Cx8wzk/ScpiKL5p1stZ0oOo52Wo4UTQeyOpl4wsZCzURfD4eztLHStSWcJBNPUGxPOVDU7OxO2pCUcPijpjgj3HntsyqHiOcO4fAHgx5glM5pM89I5rLYyoxkNP1E0NeQszh8FocfEVcpt8cdyVhTWTRPsjllbalsZankZKvpaqvtaqdtTz51Tuek/gV9gvVZB7tTtmQVou1xsq2yLfmYpfVBfeM9Jka6VjgNfQ1VnMZhe+KpyPBrMpZHDsXk8bl0TtQki63MScHGz5TfgwyDWRy+fyjjI8VVFs07krWcbLUdiRouFE0XO00XioYDWe2cjrKutoapiZ6D7WkyUdWaoGRDVCKRjpFJRy2tjxrqaxKM1Kx1j5hoHXcma0Y/8h1fk/J8F6N0pHVksRV5bkgprsirygXj7bOVt1rIonknkpYLWcvD6TyFpOZAVne103F3OGNudOKcroreGTVHOw1ne01HOzUHWzVnew1XB01nWw3chVPOVur2BkfOn1ZypejFPLolbxWXvTwYpSO6ksVWZFfrHEqiXSsySyzzq+LmsLQSiUQWzTvbarnYadkST9hYH7MjqV100L7kfIZgcQpncNrYUMfV6byTvbodWdnFXuOio46H81lHgg7O4LS7vbY7UQ135pgL8XxMJEbp3LbzTOQui63MRD4fKA0QhLPym+nMjpa2fjnvWmXZueZM0XCwVbO3Pelir+5qp+lkr+5sr0a0OW1qqGlmqkO01nN30broqOlqr+mEDIl1zumdMsepO5BO2VqfPK951MJILRYb8X4g05vNbOYZpVJV8XuEJPcMFoc/Vy+JkZbkfQEVVZX33ZJedyZp2pNOu9jpuFJ0XShaFMIpopWqjtZR3HkVQwN1QwMNg/NHdLT3a2nu1dTYd1x519q/1h5U2KCssl1NfRfeWIlseepx2A1pah9dABvxjjSZvFGak5Mzs8aUQGMbEJLlsF+VhVJHgrq1mbKRvtJZ3aNHj+7ctHnl8lXLlv324+p1v61YsXzdX6t+W77s1z+WrVr388ZtK3bsW3dYaZPumX0WeGU8XtmBrOlA0ooO95NFn4ODg+XlExz3IUs6MyuDUYros6ura9nPyy7oXxj/L/qtz507d8aPMuW7y35etmjxIgqFMoPtDYIwCEL+oQz5eWTt7OxUOKigoqoyzh/eHK94ZNP+vX+pqm49rb5T6fjW3fv/2n1gg8LhLYcVN546vf284UEz/DGiuSrBWtXaRsmGcIxAUiWRVaysFUkEFQdbdQpBjUw4K0tbaGppLvj3gkWLF/n6ytGcMEYpguj2Hds7u+b+FaOjgdy7b29MTMxs+Dmhj6wgCGXmN83tMLizs/OC/oVp1pHXLdxwKDQstnK09qYc5jZyDx06lJGRMc1STbkA74z4qVMqn4i+s6lm/CKd2UFyy5jxZGVMcEYQlUgkTt6vPH3zn79gy5jvxyj2SVP6KSMqNVaBENAnpGTmN0mvfIBAZ2fn+r/WD0zvIAtkY+Cwn7NEIpnfexI+XUoxREfTiO50RV8bNfr6bIQ7OzvXrF3T2TmtR4zM/CZkr18PsgFw3n8+UUoxRN9p2XRmR1Z+E79bOHtTwdNElNct9A9hZOU3f1JbcD9FSjFE34mo9CK/R+jpm4+8GXWmPQ2njKhAIKbS2FQah98t/ET6T2lzSCSST45SDNHRzT9+mM7sMCCmzNSm1ikgir61FYVzpooxfpXl8+6nRSmG6BSsEARh1CNiOntuZEcUPTKK5J6RQONg50Kh7fUJUYohOgVEpVFQjwgEV2JK87BvsOzj4fER5XULM4e3tiMrQ+4ZiOOxEPikHjulSn5f4FOhFACA4yrH5c114X2tIv/X6cwOT998OrODzuxISEUOapIemzim8Cii5ZVctCseOZBNIB59IBuLw5/fSyljdDLZr58EpQAAXLhwAUN0ssYhozy/Z3jdsq0fPYIY9e9HjzK1dqZtO2TPZrMTaMgfdripjCodIzb/KcUQHdPkH+xrV1fXjh07urq6PliO8zWjeU4phuhcGS6G6Axqfj5TiiE6g4YyqaQwRCelrgmF5y2lGKITtv0sCWCIzrhi5yelO3bu0NLWwqaLZtxcJkxw1epVmzZvwp5FJ1TUpATmIaXl5eUL/r1g+R/L5WqL4KRa5SMVzsjIQDX/kZZfbos9Dyk1tzD3D/DHEP3wNqehqREdE41pfsY1Pw8pnXEdYQliGphbDWCUzq3+sdwxDUysAYzSiXWESWAamFsNYJTOrf6x3DENTKyB/w/BSBVi/4LARAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "5ea180c3",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.1 A diagram presenting a latent variable model and a generative process. Notice the low- dimensional manifold (here 2D) embedded in the high-dimensional space (here 3D).\n",
    "\n",
    "\n",
    "## Latent Variable Models\n",
    "\n",
    "##  Introduction\n",
    "\n",
    "In the previous sections, we discussed two approaches to learning $ p(x) $:\n",
    "- **Autoregressive models (ARMs)** (Chapter 3)\n",
    "- **Flow-based models (Flows)** (Chapter 4)\n",
    "\n",
    "Both ARMs and Flows model the likelihood function directly:\n",
    "1. **ARMs**: Factorize the distribution and parameterize conditional distributions $ p(x_d \\mid x_{<d}) $.\n",
    "2. **Flows**: Utilize invertible transformations (neural networks) and the change of variables formula.\n",
    "\n",
    "Now, we will discuss a third approach that introduces **latent variables**.\n",
    "\n",
    "---\n",
    "\n",
    "### Generative Modeling Scenario\n",
    "\n",
    "Consider a collection of horse images. To learn $ p(x) $, e.g., for generating new images, we can imagine the generative process:\n",
    "1. Sketch the silhouette of the horse, its size, and shape.\n",
    "2. Add details like hooves, head, and color.\n",
    "3. Finally, consider the background.\n",
    "\n",
    "This step-by-step process highlights **factors of variation** (e.g., silhouette, color, background) crucial for generating an object. Using mathematics, this generative process is expressed as:\n",
    "\n",
    "1. Sample a **low-dimensional latent variable** $ \\mathbf{z} \\in \\mathcal{Z}^M $ (hidden factors in the data).\n",
    "2. Generate a high-dimensional object $ \\mathbf{x} \\in \\mathcal{X}^D $ by sampling from the conditional distribution $ p(\\mathbf{x} \\mid \\mathbf{z}) $.\n",
    "\n",
    "---\n",
    "\n",
    "### Generative Process\n",
    "\n",
    "$$\n",
    "\\mathbf{z} \\sim p(\\mathbf{z})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\sim p(\\mathbf{x} \\mid \\mathbf{z})\n",
    "$$\n",
    "\n",
    "The joint distribution is factorized as:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}, \\mathbf{z}) = p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}).\n",
    "$$\n",
    "\n",
    "However, for training, we only have access to $ \\mathbf{x} $. Using probabilistic inference, we marginalize over $ \\mathbf{z} $:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}) = \\int p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) \\, d\\mathbf{z}. \\tag{5.1}\n",
    "$$\n",
    "\n",
    "Calculating this integral is generally challenging, with two possible approaches:\n",
    "1. **Tractable Integral** (discussed briefly).\n",
    "2. **Approximate Inference** using **Variational Inference** (primary focus).\n",
    "\n",
    "---\n",
    "\n",
    "##  Probabilistic Principal Component Analysis (PPCA)\n",
    "\n",
    "Let us discuss the following scenario:\n",
    "- $ \\mathbf{z} \\in \\mathbb{R}^M $ and $ \\mathbf{x} \\in \\mathbb{R}^D $ (continuous random variables).\n",
    "- Latent variables $ \\mathbf{z} $ follow a standard Gaussian distribution:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{z} \\mid \\mathbf{0}, \\mathbf{I}).\n",
    "$$\n",
    "\n",
    "- The dependency between $ \\mathbf{z} $ and $ \\mathbf{x} $ is **linear**, with **Gaussian additive noise**:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{W}\\mathbf{z} + \\mathbf{\\mu} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}),\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\mathbf{W} \\in \\mathbb{R}^{D \\times M} $ is a linear transformation matrix.\n",
    "- $ \\mathbf{\\mu} \\in \\mathbb{R}^D $ is the mean vector.\n",
    "- $ \\boldsymbol{\\epsilon} $ is Gaussian noise with variance $ \\sigma^2 $.\n",
    "\n",
    "---\n",
    "\n",
    "### Likelihood Function\n",
    "\n",
    "The marginal likelihood of $ \\mathbf{x} $ is given by:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}) = \\int p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) \\, d\\mathbf{z}.\n",
    "$$\n",
    "\n",
    "Using the linear dependency, $ p(\\mathbf{x} \\mid \\mathbf{z}) $ is Gaussian:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mathbf{z}) = \\mathcal{N}(\\mathbf{x} \\mid \\mathbf{W}\\mathbf{z} + \\mathbf{\\mu}, \\sigma^2 \\mathbf{I}).\n",
    "$$\n",
    "\n",
    "The prior $ p(\\mathbf{z}) $ is also Gaussian:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{z} \\mid \\mathbf{0}, \\mathbf{I}).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Marginal Distribution\n",
    "\n",
    "The marginal $ p(\\mathbf{x}) $ becomes a Gaussian distribution:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}) = \\mathcal{N}(\\mathbf{x} \\mid \\mathbf{\\mu}, \\mathbf{C}),\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\mathbf{W}\\mathbf{W}^\\top + \\sigma^2 \\mathbf{I}.\n",
    "$$\n",
    "\n",
    "This concludes the description of PPCA in the context of latent variable models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4512571b",
   "metadata": {},
   "source": [
    "## Probabilistic Principal Component Analysis (pPCA)\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "We consider the following setup:\n",
    "- $ \\mathbf{z} \\in \\mathbb{R}^M $ and $ \\mathbf{x} \\in \\mathbb{R}^D $ (continuous random variables).\n",
    "- Latent variables $ \\mathbf{z} $ follow a standard Gaussian distribution:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{z} \\mid \\mathbf{0}, \\mathbf{I}).\n",
    "$$\n",
    "\n",
    "- The dependency between $ \\mathbf{z} $ and $ \\mathbf{x} $ is **linear**, with Gaussian additive noise:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\mathbf{W}\\mathbf{z} + \\mathbf{b} + \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\boldsymbol{\\epsilon} \\mid \\mathbf{0}, \\sigma^2 \\mathbf{I}). \\tag{5.2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Conditional Distribution\n",
    "\n",
    "Using the properties of Gaussian distributions, the conditional probability $ p(\\mathbf{x} \\mid \\mathbf{z}) $ is:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid \\mathbf{z}) = \\mathcal{N}(\\mathbf{x} \\mid \\mathbf{W}\\mathbf{z} + \\mathbf{b}, \\sigma^2 \\mathbf{I}). \\tag{5.3}\n",
    "$$\n",
    "\n",
    "This model is known as the **probabilistic Principal Component Analysis (pPCA)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Marginal Likelihood\n",
    "\n",
    "The marginal likelihood $ p(\\mathbf{x}) $ is calculated by integrating over $ \\mathbf{z} $:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}) = \\int p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) \\, d\\mathbf{z}. \\tag{5.4}\n",
    "$$\n",
    "\n",
    "Substituting the Gaussian distributions:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}) = \\int \\mathcal{N}(\\mathbf{x} \\mid \\mathbf{W}\\mathbf{z} + \\mathbf{b}, \\sigma^2 \\mathbf{I}) \\mathcal{N}(\\mathbf{z} \\mid \\mathbf{0}, \\mathbf{I}) \\, d\\mathbf{z}. \\tag{5.5}\n",
    "$$\n",
    "\n",
    "The result of this integration is another Gaussian distribution:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x}) = \\mathcal{N}(\\mathbf{x} \\mid \\mathbf{b}, \\mathbf{W}\\mathbf{W}^\\top + \\sigma^2 \\mathbf{I}). \\tag{5.6}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Posterior Distribution\n",
    "\n",
    "Due to the properties of Gaussian distributions, the posterior $ p(\\mathbf{z} \\mid \\mathbf{x}) $ can also be computed analytically:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{z} \\mid \\mathbf{x}) = \\mathcal{N}(\\mathbf{z} \\mid \\mathbf{M}^{-1} \\mathbf{W}^\\top (\\mathbf{x} - \\mathbf{b}), \\sigma^2 \\mathbf{M}^{-1}), \\tag{5.7}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\mathbf{M} = \\mathbf{W}^\\top \\mathbf{W} + \\sigma^2 \\mathbf{I}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. Once $ \\mathbf{W} $ is found by maximizing the log-likelihood, and its dimensionality is computationally tractable, we can calculate $ p(\\mathbf{z} \\mid \\mathbf{x}) $ for any observation $ \\mathbf{x} $. \n",
    "2. This is significant because it allows us to compute the distribution over latent factors for given data points.\n",
    "\n",
    "---\n",
    "\n",
    "### A Side Note\n",
    "\n",
    "Probabilistic PCA is an essential latent variable model for two reasons:\n",
    "1. **Analytical tractability**: All computations can be done by hand, making it an excellent exercise for building intuition about latent variable models.\n",
    "2. **Linearity**: As a linear model, it raises important questions:\n",
    "   - What happens with **non-linear dependencies**?\n",
    "   - What happens if we use distributions other than Gaussians?\n",
    "\n",
    "In both cases, the integral in $ p(\\mathbf{x}) $ becomes intractable, requiring approximations such as **variational inference**.\n",
    "\n",
    "Thus, studying pPCA in depth helps develop a solid understanding of probabilistic modeling concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc94de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000], Log-Likelihood: -355.7412\n",
      "Epoch [100/1000], Log-Likelihood: -381.8489\n",
      "Epoch [200/1000], Log-Likelihood: -406.8539\n",
      "Epoch [300/1000], Log-Likelihood: -430.4676\n",
      "Epoch [400/1000], Log-Likelihood: -452.6530\n",
      "Epoch [500/1000], Log-Likelihood: -473.5280\n",
      "Epoch [600/1000], Log-Likelihood: -493.2508\n",
      "Epoch [700/1000], Log-Likelihood: -511.9764\n",
      "Epoch [800/1000], Log-Likelihood: -529.8442\n",
      "Epoch [900/1000], Log-Likelihood: -546.9756\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkcAAAHFCAYAAAD40125AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkIklEQVR4nO3dd1hTZ/8G8PuEEXZkyFTAvVBxi4u696y1bqmrDupAu7R14Kt2Ulut0tdWravurXVV60RBRcWJGxERFSWIMvP8/vBHXlLQIgZOAvfnunJpTp6cfHOybs45z/NIQggBIiIiIgIAKOQugIiIiMiQMBwRERER5cBwRERERJQDwxERERFRDgxHRERERDkwHBERERHlwHBERERElAPDEREREVEODEdEREREOTAc0VtZtmwZJEnCqVOn5C4FABAQEAAbG5vXtsmu+fbt29pl77zzDnx8fPRSw99//w1JkvD3339rl82YMQOSJOm08/b2RpcuXfTymPpw+/ZtSJKEZcuW5av9zZs3ERgYiMqVK8PS0hJWVlaoUaMGvvjiC9y7d69wi6VCldf71ZDX+zrZ7+v8XHJ+JxREQEAAvL29C3TfvL6XSD6mchdAVNQ6d+6MsLAwuLm5FdljDh8+HB06dCiyxytsO3bsQN++feHk5ITAwEDUqVMHkiQhKioKS5Yswc6dOxEZGSl3mWRg5PgcuLm5ISwsTGfZmDFjkJSUhFWrVuVq+za+/PJLjB8/vkD3leN7iV6N4YhKnNKlS6N06dJF+phlypRBmTJlivQxC8utW7fQt29fVK5cGQcPHoRKpdLe1qpVK4wbNw6bN2+WscK3J4RAamoqLC0t5S6lWHj+/DmsrKxk+RwolUo0btxYZ5mdnR3S09NzLf+nFy9evNF7oEKFCgWqEZDne4lejYfVqEgcPXoUrVu3hq2tLaysrNCkSRPs3Lkzz3Z+fn6wsLCAh4cHvvzyS/z666963d2c393XmzdvhpWVFYYPH47MzEwAwKlTp9CtWzc4ODjAwsICderUwbp16/71MV93OGH37t2oW7cuLC0tUbVqVSxZsiRXmwsXLqB79+6wt7eHhYUFfH198fvvv+dqFxMTg4EDB8LZ2RlKpRLVqlXD999/D41Go9MuLi4Offr0ga2tLVQqFd5//33Ex8f/6/MAgJCQEKSkpGDhwoU6wSibJEno1auXzrIlS5agdu3asLCwgIODA3r27InLly/rtMk+JHr9+nV06tQJNjY2KFu2LCZNmoS0tDQAQEZGBpydnTFo0KBcj/v06VNYWloiKChIu0ytVmPy5MkoV64czM3N4eHhgQkTJiAlJSVXzYGBgQgNDUW1atWgVCq12/dN3pNr166Fn58frK2tYWNjg/bt2+fag5af55ktLS0NwcHBqFatGiwsLODo6IiWLVvi+PHj2jZCCCxcuBC+vr6wtLSEvb09evfujZs3b+baRnnZuXMnfH19oVQqUa5cOXz33Xe52rzukKskSZgxY4b2evZ7/cyZM+jduzfs7e21oeF1h5fz8zkozO+H7Do2bdqEOnXqwMLCAjNnzgQA/Pzzz2jRogWcnZ1hbW2NmjVr4ptvvkFGRobOOvI6rJb93lqxYgWqVasGKysr1K5dGzt27NBp97rD/REREWjevDmsrKxQvnx5fPXVV7k+0xcvXkS7du1gZWWF0qVLY+zYsdi5c2euQ/yUT4LoLSxdulQAEBEREa9s8/fffwszMzNRr149sXbtWrFlyxbRrl07IUmSWLNmjbbduXPnhIWFhahVq5ZYs2aN2LZtm+jUqZPw9vYWAMStW7f+tZ4hQ4YIa2vrfNWcc33+/v6iRo0a2ushISHCxMREzJo1S7vswIEDwtzcXDRv3lysXbtW7N69WwQEBAgAYunSpdp2Bw8eFADEwYMHtcumT58u/vlx8/LyEmXKlBHVq1cXy5cvF3v27BHvvfeeACAOHTqkbXflyhVha2srKlSoIJYvXy527twp+vXrJwCIr7/+WtsuISFBeHh4iNKlS4vQ0FCxe/duERgYKACI0aNHa9s9f/5cVKtWTahUKjF//nyxZ88eMW7cOOHp6ZnrueSlcuXKwsXF5bVtcpozZ44AIPr16yd27twpli9fLsqXLy9UKpWIjo7WthsyZIgwNzcX1apVE999953Yv3+/mDZtmpAkScycOVPbbuLEicLS0lIkJSXpPM7ChQsFAHH+/HkhhBApKSnC19dXODk5iZCQELF//37x448/CpVKJVq1aiU0Go32vgCEh4eHqFWrlli9erU4cOCAuHDhwhu9J2fPni0kSRJDhw4VO3bsEJs2bRJ+fn7C2tpaXLx48Y2fZ0ZGhmjZsqUwNTUVkydPFrt27RLbtm0TU6ZMEX/88Ye23YgRI4SZmZmYNGmS2L17t1i9erWoWrWqcHFxEfHx8a99bfbv3y9MTExEs2bNxKZNm8T69etFgwYNtO+FbLdu3XrlewOAmD59uvZ69nvdy8tLfPrpp2Lfvn1iy5YtOrfllN/PgT6+H7L98/OeXYebm5soX768WLJkiTh48KAIDw8XQrx8zy1atEjs3r1bHDhwQPzwww/CyclJfPDBBzrrGDJkiPDy8sq1fby9vUXDhg3FunXrxK5du8Q777wjTE1NxY0bN7TtXvW95OjoKCpVqiRCQ0PFvn37xJgxYwQA8fvvv2vbxcXFCUdHR+Hp6SmWLVsmdu3aJQYNGqTdNjm/iyh/GI7oreQnHDVu3Fg4OzuL5ORk7bLMzEzh4+MjypQpo/2Reu+994S1tbV4+PChtl1WVpaoXr16kYWjrKwsERgYKMzNzcXKlSt17le1alVRp04dkZGRobO8S5cuws3NTWRlZQkh3iwcWVhYiDt37miXvXjxQjg4OIgPP/xQu6xv375CqVSKmJgYnft37NhRWFlZiadPnwohhPjss88EAHHy5EmddqNHjxaSJImrV68KIYRYtGiRACC2bt2q027EiBH5CkcWFhaicePGr22T7cmTJ8LS0lJ06tRJZ3lMTIxQKpWif//+2mVDhgwRAMS6det02nbq1ElUqVJFe/38+fMCgPjvf/+r065hw4aiXr162utz584VCoUi13tzw4YNAoDYtWuXdhkAoVKpRGJiok7b/L4nY2JihKmpqfjoo4907p+cnCxcXV1Fnz593vh5Ll++XAAQixcvFq8SFhYmAIjvv/9eZ/ndu3eFpaWl+OSTT155XyGEaNSokXB3dxcvXrzQLlOr1cLBweGtw9G0adNytX2bz4E+vh+yvSocmZiYaD8nr5KVlSUyMjLE8uXLhYmJic575lXhyMXFRajVau2y+Ph4oVAoxNy5c7XLXvW9lNdnunr16qJ9+/ba6x9//LGQJEknhAshRPv27RmOCoiH1ahQpaSk4OTJk+jdu7dOLzITExMMGjQIsbGxuHr1KgDg0KFDaNWqFZycnLTtFAoF+vTpo7NOjUaDzMxM7SUrK0svtaampqJHjx5YtWoV9u7diwEDBmhvu379Oq5cuaJdlvPxO3XqhPv372ufx5vw9fWFp6en9rqFhQUqV66MO3fuaJcdOHAArVu3RtmyZXXuGxAQgOfPn2tPNj1w4ACqV6+Ohg0b5monhMCBAwcAAAcPHoStrS26deum065///5vXP+/CQsLw4sXLxAQEKCzvGzZsmjVqhX++usvneWSJKFr1646y2rVqqWzPWrWrIl69eph6dKl2mWXL19GeHg4hg4dql22Y8cO+Pj4wNfXV+f1at++fZ6HGlq1agV7e3udZfl9T+7ZsweZmZkYPHiwzmNZWFjA398/12Pl53n++eefsLCw0HlO/7Rjxw5IkoSBAwfqPK6rqytq16792sMpKSkpiIiIQK9evWBhYaFdbmtrm6u2gnj33Xfz3TY/n4P8vhZvo1atWqhcuXKu5ZGRkejWrRscHR1hYmICMzMzDB48GFlZWYiOjv7X9bZs2RK2trba6y4uLnB2dtZ5fq/i6uqa6zP9z/fKoUOH4OPjg+rVq+u069ev37+un/LGcESF6smTJxBC5NkDw93dHQDw+PFj7b8uLi652v1zWXBwMMzMzLSXtzkJMqeEhATs2bMHfn5+aNKkic5tDx48AABMnjxZ57HNzMwwZswYAMCjR4/e+DEdHR1zLVMqlXjx4oX2+uPHj/O9/d5mO7u6uuarZk9PT9y6dStfbbMf81V1Zd+ezcrKSueHGni5PVJTU3WWDR06FGFhYbhy5QoAYOnSpVAqlTo/Bg8ePMD58+dzvV62trYQQuR6vfKqMb/vyez3R4MGDXI93tq1a3M9Vn6e58OHD+Hu7g6F4tVf0w8ePIAQAi4uLrke98SJE699Tz558gQajSbP1z2/74XXeZNeV/n9HOTntXgbedUcExOD5s2b4969e/jxxx9x5MgRRERE4OeffwYAnRpfJT/P723uWxTbpqRhbzUqVPb29lAoFLh//36u2+Li4gBA+5ego6Oj9kcmp3+eKDxy5Eid8YGUSqVeavX09ERISAh69uyJXr16Yf369dofsOwaP//881wnG2erUqWKXur4J0dHx3xvv/y2Cw8Pz9Uuvydkt2/fHvPnz8eJEyf+tbdP9hf7q+rKuRfgTfTr1w9BQUFYtmwZZs+ejRUrVqBHjx46e36cnJxgaWmZ54m92bfnlNcJ8/l9T2ava8OGDfDy8nrj55OX0qVL4+jRo9BoNK8MSE5OTpAkCUeOHMnzc/C6z4a9vT0kScrzdf/nsuzPwT9PGP9nuM1J3+MZ5fe1eBt51bxlyxakpKRg06ZNOq/t2bNn9fa4b6sotk1Jwz1HVKisra3RqFEjbNq0SecvHY1Gg5UrV6JMmTLa3dj+/v44cOCAzl+7Go0G69ev11mnu7s76tevr73UrFlTb/W2a9cOe/bsweHDh9GlSxdtr6YqVaqgUqVKOHfunM5j57zk3G2uT61bt8aBAwe0ISfb8uXLYWVlpQ0orVu3xqVLl3DmzJlc7SRJQsuWLQG83MWfnJyMbdu26bRbvXp1vuqZOHEirK2ttWPF/JMQQtuV38/PD5aWlli5cqVOm9jYWO3hwoKwt7dHjx49sHz5cuzYsQPx8fG5Dj916dIFN27cgKOjY56vV34G68vve7J9+/YwNTXFjRs3Xvn+eFMdO3ZEamrqawfl7NKlC4QQuHfvXp6P+brPhrW1NRo2bIhNmzbp7LFKTk7G9u3bddq6uLjAwsIC58+f11m+devWN35eBZXf10LfsgNTzqAphMDixYsL9XHfhL+/Py5cuIBLly7pLF+zZo1MFRk/7jkivThw4ECeXWk7deqEuXPnom3btmjZsiUmT54Mc3NzLFy4EBcuXMAff/yh/fKZOnUqtm/fjtatW2Pq1KmwtLREaGioNqC87vBCTllZWdiwYUOu5dbW1ujYseO/3r9Zs2b466+/0KFDB7Rr1w67du2CSqXCL7/8go4dO6J9+/YICAiAh4cHEhMTcfnyZZw5c6bQvqSnT5+OHTt2oGXLlpg2bRocHBywatUq7Ny5E9988422O/3EiROxfPlydO7cGcHBwfDy8sLOnTuxcOFCjB49WhtCBw8ejB9++AGDBw/G7NmzUalSJezatQt79uzJVz3lypXDmjVr8P7778PX11c7CCQAXLp0CUuWLIEQAj179kSpUqXw5ZdfYsqUKRg8eDD69euHx48fY+bMmbCwsMD06dMLvF2GDh2KtWvXIjAwEGXKlEGbNm10bp8wYQI2btyIFi1aYOLEiahVqxY0Gg1iYmKwd+9eTJo0CY0aNXrtY+T3Pent7Y3g4GBMnToVN2/eRIcOHWBvb48HDx4gPDwc1tbW2m7h+dWvXz8sXboUo0aNwtWrV9GyZUtoNBqcPHkS1apVQ9++fdG0aVOMHDkSH3zwAU6dOoUWLVrA2toa9+/fx9GjR1GzZk2MHj36lY8xa9YsdOjQAW3btsWkSZOQlZWFr7/+GtbW1khMTNS2yz6vacmSJahQoQJq166N8PDwfAdqfdDX98Obatu2LczNzdGvXz988sknSE1NxaJFi/DkyZNCebyCmDBhApYsWYKOHTsiODgYLi4uWL16tfawc2Ftm2JNvnPBqTjI7mHxqkt2z4sjR46IVq1aCWtra2FpaSkaN24stm/fnmt9R44cEY0aNRJKpVK4urqKjz/+WHz99dcCgLZX1utk9wTK65LdiyQ/XfmFEOLChQvC1dVV1K1bV9tD5ty5c6JPnz7C2dlZmJmZCVdXV9GqVSsRGhqqvd+b9Fbr3Llzrufg7+8v/P39dZZFRUWJrl27CpVKJczNzUXt2rXz7Dl0584d0b9/f+Ho6CjMzMxElSpVxLfffqvtSZctNjZWvPvuu8LGxkbY2tqKd999Vxw/fjxfvdWy3bhxQ4wZM0ZUrFhRKJVKYWlpKapXry6CgoJy9Rz69ddfRa1atYS5ublQqVSie/fuuXrWvKqnYV7bToiXvYbKli0rAIipU6fmWeOzZ8/EF198IapUqaJ97Jo1a4qJEyfqdHMHIMaOHZvnOt7kPbllyxbRsmVLYWdnJ5RKpfDy8hK9e/cW+/fvL9DzfPHihZg2bZqoVKmSMDc3F46OjqJVq1bi+PHjOu2WLFkiGjVqpP18VahQQQwePFicOnUqz+eU07Zt27Svjaenp/jqq6/yrCUpKUkMHz5cuLi4CGtra9G1a1dx+/btV/ZWy9mr7HXP8U0+B2/7/ZBz3Xn1VsurDiGE2L59u6hdu7awsLAQHh4e4uOPPxZ//vlnrs/5q3qr5fXe8vLyEkOGDNFez+/30qse58KFC6JNmzbCwsJCODg4iGHDhonff/9dABDnzp3Le0PQK0lCCFH4EYyo4Nq1a4fbt2/nq1cIUVHge9Jw8LV4tZEjR+KPP/7A48ePYW5uLnc5RoWH1cigBAUFoU6dOihbtiwSExOxatUq7Nu3D7/99pvcpVEJxfek4eBr8WrBwcFwd3dH+fLl8ezZM+zYsQO//vorvvjiCwajAmA4IoOSlZWFadOmIT4+HpIkoXr16lixYgUGDhwod2lUQvE9aTj4WryamZkZvv32W8TGxiIzMxOVKlVCSEhIgSfCLel4WI2IiIgoB57CTkRERJQDwxERERFRDgxHRERERDnwhOwC0Gg0iIuLg62trd6HyCciIqLCIYRAcnLyv85byHBUAHFxcblmSCciIiLjcPfuXZQpU+aVtzMcFUD2HFp3796FnZ2dzNUQERFRfqjVapQtW/Zf58JkOCqA7ENpdnZ2DEdERERG5t9OiTGaE7K7desGT09PWFhYwM3NDYMGDco1S7kkSbkuoaGhOm2ioqLg7+8PS0tLeHh4IDg4GBzqiYiIiLIZzZ6jli1bYsqUKXBzc8O9e/cwefJk9O7dG8ePH9dpt3TpUnTo0EF7PXvGcuDl7rTs2eEjIiIQHR2NgIAAWFtbY9KkSUX2XIiIiMhwGU04mjhxovb/Xl5e+Oyzz9CjRw9kZGTAzMxMe1upUqXg6uqa5zpWrVqF1NRULFu2DEqlEj4+PoiOjkZISAiCgoLY84yIiIiM57BaTtkTDjZp0kQnGAFAYGAgnJyc0KBBA4SGhkKj0WhvCwsLg7+/P5RKpXZZ+/btERcXh9u3bxdV+URERGTAjCocffrpp7C2toajoyNiYmKwdetWndtnzZqF9evXY//+/ejbty8mTZqEOXPmaG+Pj4+Hi4uLzn2yr8fHx7/ycdPS0qBWq3UuREREVDzJGo5mzJiR50nUOS+nTp3Stv/4448RGRmJvXv3wsTEBIMHD9Y5mfqLL76An58ffH19MWnSJAQHB+Pbb7/Vecx/HjrLvv/rDqnNnTsXKpVKe+EYR0RERMWXJGTsqvXo0SM8evTotW28vb1hYWGRa3lsbCzKli2L48ePw8/PL8/7Hjt2DM2aNdPuMRo8eDCSkpJ09jhFRkaibt26uHnzJsqVK5fnetLS0pCWlqa9nj1OQlJSErvyExERGQm1Wg2VSvWvv9+ynpDt5OQEJyenAt03O9PlDC3/FBkZCQsLC5QqVQoA4OfnhylTpiA9PR3m5uYAgL1798Ld3R3e3t6vXI9SqdQ5T4mIiIiKL6PorRYeHo7w8HA0a9YM9vb2uHnzJqZNm4YKFSpo9xpt374d8fHx8PPzg6WlJQ4ePIipU6di5MiR2mDTv39/zJw5EwEBAZgyZQquXbuGOXPmYNq0aeypRkRERACMJBxZWlpi06ZNmD59OlJSUuDm5oYOHTpgzZo12uBjZmaGhQsXIigoCBqNBuXLl0dwcDDGjh2rXY9KpcK+ffswduxY1K9fH/b29ggKCkJQUJBcT42IiIgMjKznHBmr/B6zJCIiIsOR399vo+rKT0RERFTYGI4MyN3E57h8n2MoERERyYnhyEA8UKdiwK8n8f4vYYiMeSJ3OURERCUWw5GBsDAzgZONOdSpmRj460mE3Xgsd0lEREQlEsORgVBZmmHFsEZoWtERKelZCFgajoNXEuQui4iIqMRhODIg1kpT/DakAdpUc0ZapgYjV5zCrqj7cpdFRERUojAcGRgLMxMsGlgPXWq5ISNLIHD1GWw4HSt3WURERCUGw5EBMjNR4Me+dfB+/bLQCGDy+nNYHnZb7rKIiIhKBIYjA2WikPDVuzUxtOnLyXCnbb2IhX9fl7kqIiKi4o/hyIBJkoQvu1TDuFYVAQDf7L6Kb/dcAQc1JyIiKjwMRwZOkiQEtauCzzpWBQD8fPAGZm6/BI2GAYmIiKgwMBwZiVH+FTCrhw8AYNnx2/h043lkMSARERHpHcORERnU2AshfWpDIQHrT8di3B+RSM/UyF0WERFRscJwZGR61S2DhQPqwsxEws6o+xi18jRSM7LkLouIiKjYYDgyQh183LB4cH0oTRU4cCUBHyyNQEpaptxlERERFQsMR0bqnSrOWD60IWyUpgi7+RgDfzuJpOcZcpdFRERk9BiOjFij8o5YNbwRVJZmiIx5ir6LT+DRszS5yyIiIjJqDEdGrnbZUlj7YWM42Shx+b4afX4Jw/2kF3KXRUREZLQYjoqBqq52WD/KD+4qC9x8mIL3QsNw+1GK3GUREREZJYajYqKckzXWjfKDt6MVYp+8wHu/hOHyfbXcZRERERkdhqNipIy9FdaN8kNVV1s8TE7D+7+E4fSdJ3KXRUREZFQYjooZZ1sLrB3ph3pe9lCnZmLgrydxOPqh3GUREREZDYajYkhlZYYVwxqiReXSeJGRhWG/R2BX1H25yyIiIjIKDEfFlJW5KX4dXB+da7ohI0sgcPUZrI2IkbssIiIig8dwVIyZmyrwU7866NewLDQC+HRjFP57+IbcZRERERk0hqNizkQhYU7PmvjQvzwAYM6uK/h2zxUIIWSujIiIyDAxHJUAkiTh847V8EmHKgCAnw/ewJdbL0CjYUAiIiL6J4ajEmTMOxUxu6cPJAlYeSIGE9aeRUaWRu6yiIiIDArDUQkzoJEXfupbB6YKCdvOxWHk8lN4kZ4ld1lEREQGg+GoBOpa2x2Lh9SHhZkCB68+xJAl4VCnZshdFhERkUFgOCqhWlZxxophjWBrYYrw24no+8sJPHqWJndZREREsmM4KsEaeDtgzcjGcLIxx6X7avQJDcO9py/kLouIiEhWDEclXA13FdZ96AePUpa4+SgFvRcdx/WEZ3KXRUREJBuGI0L50jbYMNoPFUpb435SKvr8EoYL95LkLouIiEgWDEcEAHBTWWLdh36o6aFCYko6+v73BE7efCx3WUREREWO4Yi0HG2UWD2iERqVc8CztEwMXhKOA1ceyF0WERFRkWI4Ih22Fmb4fWhDtKnmjLRMDUYuP42tZ+/JXRYREVGRYTiiXCzMTLBoYD30rOOBTI3AhLVnsTzsttxlERERFQmGI8qTmYkC379XG0P8vCAEMG3rRfywL5oT1hIRUbHHcESvpFBImNGtBia0qQQA+PGva5i29SKyOGEtEREVYwxH9FqSJGFCm8qY1b0GJAlYceIOxq2JRFom52MjIqLiieGI8mWQnzd+6lsHZiYSdp6/j2HLTiElLVPusoiIiPSO4YjyrWttd/w2pAGszE1w9Poj9F98Aokp6XKXRUREpFcMR/RGWlQujdUjGsPeygznYpPQO/Q452MjIqJiheGI3phv2VJYP8oP7ioL3HyYPR9bstxlERER6QXDERVIRWdbbBjdBBWdbXA/KRW9Q8MQGfNE7rKIiIjeGsMRFZh7KUus/9APtcuWwtPnGei/+CQORT+UuywiIqK3wnBEb8Xe2hyrhzdC80pOeJGRheG/R2DbuTi5yyIiIiowhiN6a9ZKU/w2pAG61nZHRpbA+DWRnG6EiIiMFsMR6YW5qQI/vu+rM91ICKcbISIiI8RwRHqTPd3IxDaVAQA//XUNX269wOlGiIjIqDAckV5JkoTxbSphVg8fSBKw8kQMpxshIiKjwnBEhWJQYy/M76c73cgzTjdCRERGgOGICk2XWu5YGtBQO93IAE43QkRERoDhiApVs0pO+IPTjRARkRFhOKJCV7tsKawf1UQ73ci7C48j+gGnGyEiIsPEcERFoqKzDTaOaYJKzjaIV6ei96LjCL+VKHdZREREuTAcUZFxU1li/Sg/1Peyhzo1EwN/O4ndF+LlLouIiEgHwxEVqVJW5lg5vBHaVHNBeqYGY1adxsoTd+Qui4iISIvhiIqchZkJQgfWRb+GntAI4IstFxCy9ypH0yYiIoPAcESyMDVRYE5PH0xoUwkA8NOB6/h8UxQyszQyV0ZERCUdwxHJRpIkTGhTGbN7+kAhAWsi7mLUytN4kc7RtImISD4MRyS7AY28sGhgPShNFdh/OQEDfj2BJxwskoiIZMJwRAahfQ1XrBzeCHYWpjgT8xTv/RLGwSKJiEgWDEdkMBp4O2DD6CZwU1ngesIz9Fp4DFfi1XKXRUREJQzDERmUyi622Dj65WCRD9RpeC80DCdvPpa7LCIiKkEYjsjguJeyxIZRTdDA2x7JqZkYtCQcf0bdl7ssIiIqIRiOyCCprMywYlgjtKv+/4NFrj6DFWG35S6LiIhKAIYjMlgWZiZYNLAe+jfyhBDAl1sv4rs9HCySiIgKF8MRGTQThYTZPXwQ1LYyAGDBwev4dON5DhZJRESFxujCUVpaGnx9fSFJEs6ePatzW0xMDLp27Qpra2s4OTlh3LhxSE/XHS8nKioK/v7+sLS0hIeHB4KDg7knwsBJkoRxrSthbq+aUEjAulOx+HAFB4skIqLCYXTh6JNPPoG7u3uu5VlZWejcuTNSUlJw9OhRrFmzBhs3bsSkSZO0bdRqNdq2bQt3d3dERERg/vz5+O677xASElKUT4EKqF9DT/wyqD6Upgr8dSUB/RafwONnaXKXRURExYxRhaM///wTe/fuxXfffZfrtr179+LSpUtYuXIl6tSpgzZt2uD777/H4sWLoVa/HCtn1apVSE1NxbJly+Dj44NevXphypQpCAkJ4d4jI9G2ugtWj2iEUlZmOHv3Kd5ddBy3H6XIXRYRERUjRhOOHjx4gBEjRmDFihWwsrLKdXtYWBh8fHx09iq1b98eaWlpOH36tLaNv78/lEqlTpu4uDjcvn270J8D6Uc9LwdsHN0EZewtcfvxc/RadByRMU/kLouIiIoJowhHQggEBARg1KhRqF+/fp5t4uPj4eLiorPM3t4e5ubmiI+Pf2Wb7OvZbfKSlpYGtVqtcyF5VShtg01jmqCmhwqJKenot/gE9l589WtIRESUX7KGoxkzZkCSpNdeTp06hfnz50OtVuPzzz9/7fokScq1TAihs/yfbbIPp+V132xz586FSqXSXsqWLfsmT5MKibOtBdaMbIyWVUojNUODUStPcywkIiJ6a7KGo8DAQFy+fPm1Fx8fHxw4cAAnTpyAUqmEqakpKlasCACoX78+hgwZAgBwdXXNtffnyZMnyMjI0O4dyqtNQkICAOTao5TT559/jqSkJO3l7t27etsG9HaslaZYPLg++jUsC83/j4X01Z9XoNHwHDIiIioYUzkf3MnJCU5OTv/a7qeffsJ//vMf7fW4uDi0b98ea9euRaNGjQAAfn5+mD17Nu7fvw83NzcAL0/SViqVqFevnrbNlClTkJ6eDnNzc20bd3d3eHt7v/LxlUqlznlKZFhMTRSY07Mm3FWW+H5fNEIP3cD9pBf4pnctKE1N5C6PiIiMjCSMsJvW7du3Ua5cOURGRsLX1xfAy678vr6+cHFxwbfffovExEQEBASgR48emD9/PgAgKSkJVapUQatWrTBlyhRcu3YNAQEBmDZtmk6X/3+jVquhUqmQlJQEOzu7wniKVEAbTsfis43nkakR8CvviNBB9aCyNJO7LCIiMgD5/f02ihOy88PExAQ7d+6EhYUFmjZtij59+qBHjx463f5VKhX27duH2NhY1K9fH2PGjEFQUBCCgoJkrJz0qXe9Mlj6QQPYKE0RdvMx+oSGIe7pC7nLIiIiI2KUe47kxj1Hhu9iXBI+WBqBhOQ0uNpZYOkHDVDNja8VEVFJVuL2HBHlVMNdhc1jm6KSsw3i1al4LzQMx64/krssIiIyAgxHVGx5lLLEhlFN0KicA56lZWLIknBsOhMrd1lERGTgGI6oWFNZmWH5sIboWtsdmRqBoHXn8PPB65wuhoiIXonhiIo9pakJfnzfFx/6lwcAfLvnKqZuuYDMLI3MlRERkSFiOKISQaGQ8HnHagjuXgOSBKw+GYORK04jJS1T7tKIiMjAMBxRiTLYzxuhA+tBaarAgSsJ6PNLGB6oU+Uui4iIDAjDEZU47Wu4Ys3IxnCyMcfFODV6/HwMl+I4mTAREb3EcEQlUh1Pe2we0xQVSlvjflIq3gs9jr+vJshdFhERGQCGIyqxyjpYYdPopvAr74iU9CwM+/0UVp28I3dZREQkM4YjKtFUVmb4fWhDvFu3DLI0AlM3X8DcXZeh0bCrPxFRScVwRCWeuakC371XC0FtKwMAfjl8E4F/nEFqRpbMlRERkRwYjogASJKEca0rYd77vjA3UWBXVDz6LT6BR8/S5C6NiIiKGMMRUQ496nhgxbCGUFmaITLmKXouPIbrCc/kLouIiIoQwxHRPzQq74hNY5rA08EKdxNfoNfCYzhx87HcZRERURFhOCLKQ4XSNtg8pgnqepaCOjUTg347yUlriYhKCIYjoldwtFFi9YjG6FzTDRlZLyet/WFfNCetJSIq5hiOiF7DwswE8/vVweh3KgAAfvzrGiatO4f0TE5aS0RUXDEcEf0LhULCpx2qYm6vmjBRSNgUeQ+Dl5xE0vMMuUsjIqJCwHBElE/9GnpiaUAD2ChNceJmInouOoY7j1PkLouIiPSM4YjoDbSoXBobRvvBXWWBmw9T0OPnYzjJnmxERMUKwxHRG6rqaoctY5uidhkVnjzPwMDfTmL9qbtyl0VERHrCcERUAM52Flj7oZ+2J9vHG87j691XOCcbEVExwHBEVEDZPdk+alURALDo7xsYs+oMnqdnylwZERG9DYYjoregUEiY1K4Kfni/NsxNFNh9MR7v/3ICD9SpcpdGREQFxHBEpAc965TB6hGN4GBtjqh7Sei+4Bgu3EuSuywiIioAhiMiPanv7YAtY5qikrMN4tWpeC80DHsuxstdFhERvSGGIyI98nS0wsYxTdC8khNeZGRh1MrTCD10g1OOEBEZEYYjIj2zszDD0oAGGNTYC0IAX/15BZ9sOM8pR4iIjATDEVEhMDVRYFYPH8zoWh0KCVh/OhaDfjuJJynpcpdGRET/guGIqBAFNC2H3/5/ypGTtxLRc+Ex3Hj4TO6yiIjoNRiOiApZyyrO2Di6CTxKWeL24+fo+fMxHL/+SO6yiIjoFRiOiIpAFVdbbBnbFHU8S0GdmonBS8Kx+mSM3GUREVEeGI6IikhpWyX+GNEY3Wq7I1MjMGVzFGZsu4jMLJ6oTURkSBiOiIqQhZkJfuzri6C2lQEAy47fxgfLIpD0PEPmyoiIKBvDEVERkyQJ41pXQujAurA0M8GRa4/QgydqExEZDIYjIpl08HHDhtF+cFdZ4NajFPT4+RgORT+UuywiohKP4YhIRjXcVdga2Az1vOyRnJqJD5aGY8nRWxxRm4hIRgxHRDIrbavE6hGN8F69MtAIIHjHJXy2MYojahMRyYThiMgAKE1N8E3vWviiczUoJGDtqbsY8OsJPHqWJndpREQlDsMRkYGQJAnDm5fHbwENYKs0RcTtJ+i+4Bgu31fLXRoRUYnCcERkYFpWccbmsU3g7WiFe09f4N1Fx7HnYrzcZRERlRgMR0QGqKLzyxG1m1Z0xPP0LHy44jR+PnidJ2oTERUBhiMiA1XKyhzLPmiIwX5eAIBv91zF+DVnkZqRJXNlRETFG8MRkQEzM1EguLsPZvf0galCwrZzcejzSxjik1LlLo2IqNiSRD730wcFBeV7pSEhIQUuyBio1WqoVCokJSXBzs5O7nKohAi78RijV53G0+cZcLZV4r+D68O3bCm5yyIiMhr5/f02ze8KIyMjda6fPn0aWVlZqFKlCgAgOjoaJiYmqFevXgFLJqLX8avgiG1jm2H48ghEP3iGPr+EYU7Pmuhdr4zcpRERFSv5DkcHDx7U/j8kJAS2trb4/fffYW9vDwB48uQJPvjgAzRv3lz/VRIRAMDT0QobRzfBxLVnsf9yAiavP4eLcUmY2qkaTE14lJyISB/yfVgtJw8PD+zduxc1atTQWX7hwgW0a9cOcXFxeivQEPGwGslNoxGYtz8aPx24DgBoUsERP/evC3trc5krIyIyXPn9/S7Qn5pqtRoPHjzItTwhIQHJyckFWSURvQGFQkJQuyoIHVgXVuYmOH7jMbouOMoBI4mI9KBA4ahnz5744IMPsGHDBsTGxiI2NhYbNmzAsGHD0KtXL33XSESv0MHHDZvHNIWngxVin7xAr4XHsfP8fbnLIiIyagU6rPb8+XNMnjwZS5YsQUZGBgDA1NQUw4YNw7fffgtra2u9F2pIeFiNDM3T5+n46I9IHLn2CAAwtmUFBLWtAhOFJHNlRESGI7+/3wUKR9lSUlJw48YNCCFQsWLFYh+KsjEckSHKzNLg691XsPjILQBAq6rOmNfXF3YWZjJXRkRkGAr1nKNs1tbWcHBwgJOTU4kJRkSGytREgamdq2Pe+75Qmipw4EoCeiw4husJz+QujYjIqBQoHGk0GgQHB0OlUsHLywuenp4oVaoUZs2aBY1Go+8aiegN9KjjgQ2jmsBNZYGbj1LQ8+dj+Oty7g4URESUtwKFo6lTp2LBggX46quvEBkZiTNnzmDOnDmYP38+vvzyS33XSERvqGYZFbYFNkMDb3skp2Vi+PJTWHDgGieuJSLKhwKdc+Tu7o7Q0FB069ZNZ/nWrVsxZswY3Lt3T28FGiKec0TGIj1Tg+AdF7HyRAwAoFNNV3zbuzaslfke/5WIqNgo1HOOEhMTUbVq1VzLq1atisTExIKskogKgbmpAv/pURNze9WEmYmEXVHxeHfRccQ8fi53aUREBqtA4ah27dpYsGBBruULFixA7dq137ooItKvfg098ceIxnCyUeJKfDK6/XwUR/+/2z8REekq0GG1Q4cOoXPnzvD09ISfnx8kScLx48dx9+5d7Nq1q9jPr8bDamSs7ie9wKgVp3EuNgkKCfi0Q1WMbFEeksTxkIio+CvUw2r+/v6Ijo5Gz5498fTpUyQmJqJXr164evVqsQ9GRMbMTWWJtR/64d26ZaARwNw/ryBwdSRS0jLlLo2IyGC81SCQJRX3HJGxE0Jg5Yk7mLn9EjI1ApWcbfDLoHooX9pG7tKIiApNoY+Q/fTpU/z222+4fPkyJElC9erVMXToUKhUqgIXbSwYjqi4OH0nEaNXnkFCchpslaYIed8Xbau7yF0WEVGhKNTDaqdOnUKFChXwww8/IDExEY8ePUJISAgqVKiAM2fOFLhoIipa9bwcsOOj/42HNGL5KYTsi4ZGwx3KRFRyFWjPUfPmzVGxYkUsXrwYpqYvx0vJzMzE8OHDcfPmTRw+fFjvhRoS7jmi4iY9U4M5uy5j2fHbAICWVUpj3vt1oLLivGxEVHwU6mE1S0tLREZG5hrr6NKlS6hfvz6ePy/eY6gwHFFxtelMLD7fFIW0TA08Hazwy6B6qObG9zgRFQ+FeljNzs4OMTExuZbfvXsXtra2BVklERmAXnXLYOPoJihjb4mYxOfotfA4tp4t3iPeExH9U4HC0fvvv49hw4Zh7dq1uHv3LmJjY7FmzRoMHz4c/fr103eNRFSEfDxU2B7YDM0rOeFFRhbGrzmLWTsuISOLk0oTUclQoMNq6enp+PjjjxEaGorMzJfjo5iZmWH06NH46quvoFQq9V6oIeFhNSoJsjQCIfuu4ueDNwAAjco5YEH/uihtW7w/30RUfBV6V34AeP78OW7cuAEhBCpWrAgrK6uCrsqoMBxRSbL7Qjwmrz+HZ2mZcLWzwKKBdVHH017usoiI3liRhKOSiuGISprrCc/w4YpTuPEwBeYmCszsXgP9GnrKXRYR0Rsp1BOyU1JS8OWXX6JJkyaoWLEiypcvr3MpTGlpafD19YUkSTh79qzObZIk5bqEhobqtImKioK/vz8sLS3h4eGB4OBgMB8SvV5FZxtsGdsU7Wu4ID1Lg883ReHTDeeRmpEld2lERHpnWpA7DR8+HIcOHcKgQYPg5uZWpJNWfvLJJ3B3d8e5c+fyvH3p0qXo0KGD9nrOEbvVajXatm2Lli1bIiIiAtHR0QgICIC1tTUmTZpU6LUTGTNbCzOEDqyHhX/fwHd7r2Ltqbu4eD8JiwbUQ1mHknFInYhKhgKFoz///BM7d+5E06ZN9V3Pvz7u3r17sXHjRvz55595tilVqhRcXV3zvG3VqlVITU3FsmXLoFQq4ePjg+joaISEhCAoKIgzkxP9C0mSMLZlRdT0UGH8mkhcuKdGl/lHMe99X7Ss6ix3eUREelGgw2r29vZwcHDQdy2v9eDBA4wYMQIrVqx47YnfgYGBcHJyQoMGDRAaGgqN5n/dj8PCwuDv76/Tm659+/aIi4vD7du3C7N8omKlReXS2DGuOWqXLYWkFxn4YFkEQvZeRRanHSGiYqBA4WjWrFmYNm1akY2ELYRAQEAARo0ahfr167+2rvXr12P//v3o27cvJk2ahDlz5mhvj4+Ph4uL7qSa2dfj4+Nfud60tDSo1WqdC1FJ51HKEus+bIzBfl4AgJ8OXEfA0nA8fpYmc2VERG8n34fV6tSpo3PY6fr163BxcYG3tzfMzHTnX8rv5LMzZszAzJkzX9smIiICx48fh1qtxueff/7atl988YX2/76+vgCA4OBgneX/PHSWfTL26w6pzZ0791/rJCqJlKYmCO7ug7qe9vh8UxSOXHuELvOP4ucBdVGX3f2JyEjluyv/m4SD6dOn56vdo0eP8OjRo9e28fb2Rt++fbF9+3adAJOVlQUTExMMGDAAv//+e573PXbsGJo1a6bdYzR48GAkJSVh69at2jaRkZGoW7cubt68iXLlyuW5nrS0NKSl/e+vYbVajbJly7IrP1EOV+OTMXrladx8lAIzEwlfdqmOQY29eC4fERmMYjXOUUxMjM6hrLi4OLRv3x4bNmxAo0aNUKZMmTzvt2DBAnz88cd4+vQplEolFi1ahClTpuDBgwcwNzcHAHz99df46aefEBsbm+8vcY5zRJS35NQMfLrxPHZFvTxM3a22O+b2qglrZYH6fhAR6VV+f7+N4hvL01N3sDkbGxsAQIUKFbTBaPv27YiPj4efnx8sLS1x8OBBTJ06FSNHjtSegN2/f3/MnDkTAQEBmDJlCq5du4Y5c+Zg2rRp/OuWSA9sLczwc/+6+O3oLcz98wq2nYvD5ftqLBpYDxWdbeQuj4goX/IdjhwcHBAdHQ0nJyfY29u/NkwkJibqpbg3YWZmhoULFyIoKAgajQbly5dHcHAwxo4dq22jUqmwb98+jB07FvXr14e9vT2CgoIQFBRU5PUSFVeSJGF48/KoVaYUAlefwbWEZ+i+4Ci+6V0bnWu5yV0eEdG/yvdhtd9//x19+/aFUql85Tk+2YYMGaKX4gwVD6sR5U9CcirG/RGJEzdf/sE0tGk5fN6pKsxMCtRRlojorRSrc44MDcMRUf5lZmnw3d5ohB66AQCo72WPBf3rwlVlIXNlRFTS6D0cvcnYPsU9MDAcEb25PRfjMXndOSSnZcLJxhw/9auDJhWc5C6LiEoQvYcjhULxryctCyEgSRKysor3ZJQMR0QFc+tRCkavPI0r8clQSMCkdlUw2r8CFAp2iCCiwqf33moHDx7US2FEVHKVc7LG5jFN8cWWC9h4Jhbf7rmK8FuJ+OF9XzhYm8tdHhERAJ5zVCDcc0T0doQQWHfqLqZtvYi0TA3cVBZY0L8O6nkV7ZyNRFSy5Pf3u8BdRo4cOYKBAweiSZMmuHfvHgBgxYoVOHr0aEFXSUQlhCRJeL+BJ7aMbYpyTta4n5SK9385gcWHb4J/rxGR3AoUjjZu3Ij27dvD0tISZ86c0U6tkZycrDPRKxHR61Rzs8P2j5qha213ZGoEZu+6jBHLTyPpeYbcpRFRCVagcPSf//wHoaGhWLx4sc6ks02aNMn3pLNERABgozTFT319MauHD8xNFNh/+QE6zz+Cc3efyl0aEZVQBQpHV69eRYsWLXItt7Ozw9OnT9+2JiIqYSRJwqDGXtg0pgk8HawQ++QFeocex7Jjt3iYjYiKXIHCkZubG65fv55r+dGjR1G+fPm3LoqISiYfDxW2f9QM7Wu4ICNLYMb2Sxi7+gzUqTzMRkRFp0Dh6MMPP8T48eNx8uRJSJKEuLg4rFq1CpMnT8aYMWP0XSMRlSAqSzOEDqyHaV2qw1QhYVdUPLrNP4qLcUlyl0ZEJUSBu/JPnToVP/zwA1JTUwEASqUSkydPxqxZs/RaoCFiV36iohEZ8wSBqyNx7+kLmJsqML1rdfRv6PmvA9ISEeWlUOdWS09Ph7m5OZ4/f45Lly5Bo9GgevXqsLGxwaNHj+DkVLynBGA4Iio6T5+nY9K6c/jrSgIAoLuvO+b0rAlrZb7HsCUiAlDI4xz16dMHGo0GVlZWqF+/Pho2bAgbGxs8ePAA77zzTkFrJiLKpZSVORYPro/POlaFiULC1rNx6LbgKK7GJ8tdGhEVUwUKR/fv38ewYcNyLXvnnXdQtWpVvRRGRJRNoZAwyr8C1oxsDFc7C9x4mILuPx/FulN32ZuNiPSuQOFo165dCA8Px8SJEwEA9+7dwzvvvIOaNWti3bp1ei2QiChbA28H7BzXDM0rOSE1Q4NPNpzHxLVn8SwtU+7SiKgYKfAJ2bGxsWjWrBl69uyJnTt3om7duli1ahVMTEz0XaPB4TlHRPLSaAQWHbqBkH3RyNIIlHOyxoL+dVDDXSV3aURkwAr1hOxs165dQ7NmzdC2bVusWLGixPQgYTgiMgwRtxMx7o9I3E9KhbmJAl90qYZBjb1KzHcREb0ZvYcje3v7PL9wnj9/DqVSqbPHKDExsQAlGw+GIyLD8SQlHR9vOIf9l1/2ZmtfwwXfvFsbKiuzf7knEZU0+f39zndf2Hnz5umjLiIivbK3ftmbbcmx2/jqz8vYc/EBLtw7gvn966Cup73c5RGREXqrw2olFfccERmm87FPEbg6EjGJz2GqkPBx+yoY0bw8FAoeZiOiQjisplartStSq9WvbVvcAwPDEZHhUqdmYMqmKOw4fx8A8E6V0vj+vdpwtFHKXBkRyU3v4cjExAT379+Hs7MzFApFnucfCSEgSRKysrIKXrkRYDgiMmxCCKyJuIsZ2y4iLVMDFzsl5r1fB34VHOUujYhkpPdzjg4cOAAHBwcAwMGDB9++QiKiQiJJEvo19EQdz1IIXB2J6wnPMODXExjXuhI+alUJJjzMRkSvoddzjp48eYLt27dj8ODB+lqlQeKeIyLj8Tw9EzO2XcS6U7EAgMblHfBj3zpwsbOQuTIiKmqFOrfaq8TExOCDDz7Q5yqJiN6KlbkpvuldG/Pe94W1uQlO3ExExx+P4O+rCXKXRkQGSq/hiIjIUPWo44HtHzVDdTc7JKakI2BpBObuuoz0TI3cpRGRgWE4IqISo3xpG2wa0wRD/LwAAL8cvoneocdx+1GKzJURkSFhOCKiEsXCzAQzu/vgl0H1oLI0w/nYJHT+6Qg2nYmVuzQiMhD57q0GAD/99NNrb793795bFUNEVFTa13BFTQ8VJqw9i/BbiQhadw6Hox9iVg8f2Fpw6hGikuyNequVK1cuX+1u3bpV4IKMAXurERUfWRqBhQevY95f15ClEfB0sMJP/erAt2wpuUsjIj3T+yCQ9D8MR0TFz+k7iRj3x1nce/oCpgoJk9pVwYctOPUIUXFSZF35Y2NjodGwtwcRGbd6Xg7YNb45OtdyQ6ZG4OvdVzBoyUk8UKfKXRoRFbG3DkfVq1fH7du39VAKEZG8VJZmWNCvDr55txYszUxw7PpjdPzxCP66/EDu0oioCL11OOJROSIqTiRJQp8GZXXGRBr2+ynM2HYRqRnFe95IInqJXfmJiPJQ0dkGm8c2wdCmLzuiLDt+Gz0XHsf1hGSZKyOiwvbW4WjKlCnaCWmJiIoTpakJpnWtjqUBDeBobY7L99XoMv8o/giP4V5zomKMvdUKgL3ViEqeBHUqJq0/hyPXHgEAOtV0xdyetaCy4phIRMaiULvyBwUF5b0ySYKFhQUqVqyI7t27F9s9SgxHRCWTRiPw69Gb+Gb3VWRqBDxKWWJeX1808C6e33VExU2hhqOWLVvizJkzyMrKQpUqVSCEwLVr12BiYoKqVavi6tWrkCQJR48eRfXq1d/qiRgihiOiku3c3acYtyYSdx4/h0ICAltWxEetK8HMhKdxEhmyQh3nqHv37mjTpg3i4uJw+vRpnDlzBvfu3UPbtm3Rr18/3Lt3Dy1atMDEiRML/ASIiAxV7bKlsHNcc/Sq6wGNAH46cB3vhYZxAluiYqJAe448PDywb9++XHuFLl68iHbt2uHevXs4c+YM2rVrh0ePHumtWEPBPUdElG37uThM3RwFdWomrMxNMKNbDbxXrwwkiSNrExmaQt1zlJSUhISEhFzLHz58CLVaDQAoVaoU0tPTC7J6IiKj0bW2O3ZPaIFG5RzwPD0Ln2w4jzGrzuDpc37/ERmrAh9WGzp0KDZv3ozY2Fjcu3cPmzdvxrBhw9CjRw8AQHh4OCpXrqzPWomIDJJ7KUusHtEYn3aoClOFhD8vxKPDvCM4fr347TknKgkKdFjt2bNnmDhxIpYvX47MzEwAgKmpKYYMGYIffvgB1tbWOHv2LADA19dXn/UaBB5WI6JXiYpNwvi1kbj58OX5RyNblMekdpWhNDWRuTIiKtTeatmePXuGmzdvQgiBChUqwMbGpqCrMioMR0T0Os/TMzF752WsOhkDAKjuZoef+vmiorOtzJURlWyFes5RNhsbGzg4OMDJyanEBCMion9jZW6K2T1rYvHg+nCwNsel+2p0/ukoVoTd5sjaREagQOFIo9EgODgYKpUKXl5e8PT0RKlSpTBr1ixoNBp910hEZJTaVnfB7vHN0aJyaaRlavDl1osY9vspPExOk7s0InqNAoWjqVOnYsGCBfjqq68QGRmJM2fOYM6cOZg/fz6+/PJLfddIRGS0nO0ssCygAaZ3rQ5zUwUOXElAxx8P4+CV3D1+icgwFOicI3d3d4SGhqJbt246y7du3YoxY8bg3r17eivQEPGcIyIqiCvxakxYcxZX4pMBAIP9vDClUzVYmPFkbaKiUKjnHCUmJqJq1aq5lletWhWJiYkFWSURUbFX1dUOW8Y2xdCm5QAAy8PuoMv8o7gYlyRzZUSUU4HCUe3atbFgwYJcyxcsWIBatWq9dVFERMWVhZkJpnWtjuVDG6K0rRLXE56hx8/H8MuhG8jS8GRtIkNQoMNqhw4dQufOneHp6Qk/Pz9IkoTjx4/j7t272LVrF5o3b14YtRoMHlYjIn1ITEnHpxvPY9+lBwCAhuUc8P17tVHWwUrmyoiKp0I9rObv74/o6Gj07NkTT58+RWJiInr16oWLFy9i6dKlBS6aiKgkcbA2x38H1cNXvWrCytwE4bcS0fHHI1h/6i67/BPJ6K0Ggfync+fOoW7dusjKytLXKg0S9xwRkb7deZyCoHXncPrOEwBA+xoumNOzJhxtlDJXRlR8FMkgkEREpB9ejtZY96EfPulQBWYmEvZcfID2847gwJUHcpdGVOIwHBERGQgThYQx71TE5jFNUcnZBo+epWHoslP4fFMUUtIy5S6PqMRgOCIiMjA+Hips/6gZhjV72eX/j/AYdPrpiPaQGxEVLtM3adyrV6/X3v706dO3qYWIiP6fhZkJvuxSHa2rOmPS+nO48/g53gs9jrEtK2Jc60owM+HftkSF5Y1OyP7ggw/y1a6491jjCdlEVJSSXmRgxraL2Bz5cvYBHw87zHvfFxWdbWWujMi45Pf3W6+91UoKhiMiksOO83GYuvkCkl5kQGmqwGcdq2KInzcUCknu0oiMAnurEREVM11quWPvxBZoXskJaZkazNx+CYOXhON+0gu5SyMqVhiOiIiMiIudBZYPbYjg7jVgYabA0euP0P6Hw9h6tnhP+E1UlBiOiIiMjCRJGOznjZ3jmqN2GRXUqZkYv+YsPvojEk+fp8tdHpHRYzgiIjJSFUrbYMPoJhjfuhJMFBK2n4tD+3mH8ffVBLlLIzJqDEdEREbMzESBiW0rY+PoJijvZI0H6jQELI3A55ui8IwDRxIVCMMREVEx4Fu2FHaOa44PmnoDeDlwZId5h3Hi5mN5CyMyQgxHRETFhKW5CaZ3rYHVIxrBo5QlYp+8QN//nkDw9ktIzSjeE4IT6RPDERFRMdOkghP2TGyBfg3LAgCWHLuFTj8dQWQMpx8hyg+GIyKiYshGaYq5vWph6QcN4GyrxM2HKXh30XF8u+cK0jM1cpdHZNCMJhx5e3tDkiSdy2effabTJiYmBl27doW1tTWcnJwwbtw4pKfrdmuNioqCv78/LC0t4eHhgeDgYHCQcCIqrlpWccbeiS3Qw9cdGgH8fPAGui04iktxarlLIzJYbzTxrNyCg4MxYsQI7XUbGxvt/7OystC5c2eULl0aR48exePHjzFkyBAIITB//nwAL4cNb9u2LVq2bImIiAhER0cjICAA1tbWmDRpUpE/HyKiolDKyhzz+tZBuxqu+GLLBVyJT0b3n49iQpvK+LBFeZhyElsiHUYVjmxtbeHq6prnbXv37sWlS5dw9+5duLu7AwC+//57BAQEYPbs2bCzs8OqVauQmpqKZcuWQalUwsfHB9HR0QgJCUFQUBAkifMTEVHx1ammGxp4O2Dq5ijsvfQA3+65ir2XHuD792qjorPNv6+AqIQwqj8Xvv76azg6OsLX1xezZ8/WOWQWFhYGHx8fbTACgPbt2yMtLQ2nT5/WtvH394dSqdRpExcXh9u3b7/ycdPS0qBWq3UuRETGqLStEr8MqoeQPrVha2GKc3efovNPR/Db0VvQaHiKARFgROFo/PjxWLNmDQ4ePIjAwEDMmzcPY8aM0d4eHx8PFxcXnfvY29vD3Nwc8fHxr2yTfT27TV7mzp0LlUqlvZQtW1ZfT4uIqMhJkoRedcvoTGI7a8cl9Ft8AncTn8tdHpHsZA1HM2bMyHWS9T8vp06dAgBMnDgR/v7+qFWrFoYPH47Q0FD89ttvePz4fwOc5XVYTAihs/yfbbJPxn7dIbXPP/8cSUlJ2svdu3ff6nkTERkCN5Ullg9tiNk9fWBlboKTtxLRYd5h/BEew44qVKLJes5RYGAg+vbt+9o23t7eeS5v3LgxAOD69etwdHSEq6srTp48qdPmyZMnyMjI0O4dcnV1zbWHKCHh5RxE/9yjlJNSqdQ5FEdEVFxIkoQBjbzQvGJpTF5/DuG3E/H5pijsvhCPub1qwr2UpdwlEhU5WcORk5MTnJycCnTfyMhIAICbmxsAwM/PD7Nnz8b9+/e1y/bu3QulUol69epp20yZMgXp6ekwNzfXtnF3d39lCCMiKgk8Ha3wx8jGWHrsFr7ZcxWHoh+i/Q+H8UWXauhTvyw7rFCJIgkj2HcaFhaGEydOoGXLllCpVIiIiMDEiRNRv359bN26FcDLrvy+vr5wcXHBt99+i8TERAQEBKBHjx7arvxJSUmoUqUKWrVqhSlTpuDatWsICAjAtGnT3qgrv1qthkqlQlJSEuzs7ArlORMRyeV6wjN8vOEcImOeAgD8K5fmXiQqFvL7+20U4ejMmTMYM2YMrly5grS0NHh5eaFv37745JNPYGVlpW0XExODMWPG4MCBA7C0tET//v3x3Xff6RwSi4qKwtixYxEeHg57e3uMGjUK06ZNe6O/ihiOiKi4y9II/Hb0Jr7bG430TA1slabci0RGr1iFI0PDcEREJQX3IlFxkt/fb6Ppyk9EREWvorMNNoxqgimdqsLcVKE9F2ltBHu0UfHFcERERK9lopAwskUF7BrXHHU8SyE5LROfboxCwNIIxD19IXd5RHrHcERERPnCvUhUUjAcERFRvr1qL9IQ7kWiYoThiIiI3tg/9yId5l4kKkYYjoiIqEC4F4mKK4YjIiJ6K9yLRMUNwxEREb017kWi4oThiIiI9CavvUjtfjiMlSfuQKPhXiQyDgxHRESkVzn3ItX1LIVnaZn4YssF9Ft8ArcfpchdHtG/YjgiIqJCUdHZButHNcG0LtVhaWaCk7cS0eHHw1h8+CayuBeJDBjDERERFRoThYShzcphz4QWaFrREakZGszedRnvLjqO6AfJcpdHlCeGIyIiKnSejlZYOawRvupVE7ZKU5y9+xSdfzqCn/66howsjdzlEelgOCIioiIhSRL6NvTEviB/tKnmjIwsgZB90eg6/yiiYpPkLo9Ii+GIiIiKlKvKAosH18ePfX1hb2WGK/HJ6LHwGL7efQWpGVlyl0fEcEREREVPkiR09/XAviB/dKnlhiyNwKK/b6DTj0cQcTtR7vKohGM4IiIi2TjZKLGgf138d1A9ONsqcfNRCvr8EobpWy8gJS1T7vKohGI4IiIi2bWr4Yp9E/3Rp34ZCAH8HnYH7ecdxpFrD+UujUoghiMiIjIIKiszfNO7NlYMawiPUpaIffICg34LxycbziHpRYbc5VEJwnBEREQGpXml0tg7sQUCmnhDkoB1p2LRNuQQ9l6Ml7s0KiEYjoiIyOBYK00xo1sNrPvQD+WdrJGQnIaRK07joz8i8fhZmtzlUTHHcERERAargbcDdo1vjlH+FWCikLD9XBzahBzC5shYCMEpSKhwMBwREZFBszAzwWcdq2LLmKao6mqLJ88zMHHtOQxZGoG7ic/lLo+KIYYjIiIyCjXLqLD9o2b4uH0VmJsqcDj6Idr9cBi/HuFEtqRfDEdERGQ0zEwUGNuyInaPb45G5RzwIiML/9l5Gb0WHsPl+2q5y6NiguGIiIiMTvnSNvhjRGPM7VUTthamOBebhK7zj+IbTkFCesBwRERERkmhkNCvoSf+CvJHRx9XZGoEFv59Ax1/PIITNx/LXR4ZMYYjIiIyas52Flg0sB5+GVQPLnZK3HqUgr7/PYHPN53n4JFUIAxHRERULLSv4Yp9Qf4Y0MgTAPBH+F20CTmE3Rfuy1wZGRuGIyIiKjbsLMwwu2fNl4NHlrbGw+Q0jFp5BiOXn0J8Uqrc5ZGRYDgiIqJip2E5B+wa1xzjWlWEqULC3ksP0DbkEFaeuAMNu/3Tv2A4IiKiYsnCzARB7apgx7hm8C1bCslpmfhiywW8/98wXE94Jnd5ZMAYjoiIqFir6mqHjaObYHrX6rAyN0HE7Sfo9OMRzP/rGtIzNXKXRwaI4YiIiIo9E4WED5qWw96JLdCySmmkZ2nw/b5odJ1/FJExT+QujwwMwxEREZUYZeytsCSgAX7s6wtHa3NcfZCMXouOY/rWC0hOZbd/eonhiIiIShRJktDd1wP7g/zxbt0yEAL4PeyOttu/EDxhu6RjOCIiohLJ3toc3/epjVXDG8Hb0QoP1C+7/Y9Yfgr3nr6QuzySEcMRERGVaE0rOmH3hBb4qFVFmJlI2H85AW1DDuG3o7eQmcUTtksihiMiIirxLMxMMKldFewa1xz1vezxPD0Ls3ZcQo+FxxAVmyR3eVTEGI6IiIj+XyUXW6z70A9ze9WEnYUpLtxTo/vPRxG8/RJS0jLlLo+KCMMRERFRDgqFhH4NPfHXpHfQ3dcdGgEsOXYLbUMOYd+lB3KXR0WA4YiIiCgPpW2V+LFvHfw+tCHKOlgiLikVI5afwqgVpzlPWzHHcERERPQa/pVLY+8Ef4x+pwJMFRJ2X4xHm5BD+P34bWRxnrZiieGIiIjoX1iam+DTDlWxY1wz1PEshWdpmZi+7SJ6LTqOi3E8Ybu4YTgiIiLKp6qudtg4qglm9fCBrdIU5+4+RbcFxzBn12U8T+cJ28UFwxEREdEbUCgkDGrshf2T/NG5phuyNAL/PXwTbUMO4+CVBLnLIz1gOCIiIioAFzsL/DygLn4bUh8epSxx7+kLfLAsAmNXn0GCmidsGzOGIyIiorfQupoL9gW1wIjm5WCikLDz/H20/v4QVpy4wxO2jRTDERER0VuyMjfF1M7VsXVsU9Qqo0JyWia+3HIBvRYew4V7PGHb2DAcERER6YmPhwqbxzTFzG41Xp6wHZuEbguOYsa2i0hOzZC7PMonhiMiIiI9MlFIGNLEG39N8kfX2i9H2F52/DZaf38IO87HQQgeajN0DEdERESFwNnOAvP71cGKYQ3h7WiFhOQ0BK6OxOAl4bj9KEXu8ug1GI6IiIgKUfNKpbF7QgtMaFMJ5iYKHLn2CO3mHcaP+68hLTNL7vIoDwxHREREhczCzAQT2lTGnokt0LySE9IzNfhhfzQ6zjuCY9cfyV0e/QPDERERUREp52SN5UMbYn6/Oihtq8TNRykY8OtJjPsjEgnJHBvJUDAcERERFSFJktC1tjv+muSPgCbeUEjAtnNxaP39ISwP42S2hkASPG3+janVaqhUKiQlJcHOzk7ucoiIyIhFxSZh6pYonI99OR5SrTIqzO5REzXLqGSurPjJ7+839xwRERHJqGaZl2Mjzer+cmyk87FJ6P7zy7GR1BwbSRYMR0RERDIzUUgY5OeNvyb7o7vv/8ZGavP9IWw/x7GRihrDERERkYFwtrXAj33rYOWwRijvZI2E5DR89MfLsZFucWykIsNwREREZGCaVXLCnxOaI6htZZibvhwbqf28w5i3PxqpGRwbqbAxHBERERkgpakJxrWuhL0T/jc20rz919B+3mEcvJogd3nFGsMRERGRAfP+/7GRFvSvAxc7Je48fo4PlkZg5PJTiH3yXO7yiiWGIyIiIgMnSRK61HLHX5PewcgW5WGqkLD30gO0CTmEnw9e5zQkesZxjgqA4xwREZGcoh8k48stF3DyViIAoLyTNWZ2r4HmlUrLXJlh4zhHRERExVRlF1usGdkY8973hZPNy2lIBv0WjrGrzuB+0gu5yzN6DEdERERGSJIk9KjjgQOT/fFB05fTkOyMuo/W3x/CL4duID1TI3eJRouH1QqAh9WIiMjQXIpTY9rWCzh15wkAoKKzDYK710CTCk4yV2Y4eFiNiIioBKnubod1H/rhu/dqw9HaHNcTnqH/4pMY90ckHqhT5S7PqDAcERERFRMKhYTe9crgwKR3MNjPCwoJ2HYuDq2/P4Rfj9xERhYPteWH0YQjb29vSJKkc/nss8902vzzdkmSEBoaqtMmKioK/v7+sLS0hIeHB4KDgzlnDRERFSsqKzMEd/fBtsBm8C1bCs/SMvGfnZfRdf5RhP9/Dzd6NVO5C3gTwcHBGDFihPa6jY1NrjZLly5Fhw4dtNdVKpX2/2q1Gm3btkXLli0RERGB6OhoBAQEwNraGpMmTSrc4omIiIqYj4cKm0Y3wbpTd/H17iu4Ep+MPr+EoVddD3zesRpK2yrlLtEgGVU4srW1haur62vblCpV6pVtVq1ahdTUVCxbtgxKpRI+Pj6Ijo5GSEgIgoKCIElSYZRNREQkG4VCQt+GnmhfwxXf7LmKNREx2HTmHvZdeoDJ7apgQCNPmJoYzYGkImFUW+Prr7+Go6MjfH19MXv2bKSnp+dqExgYCCcnJzRo0AChoaHQaP53fDUsLAz+/v5QKv+XlNu3b4+4uDjcvn37lY+blpYGtVqtcyEiIjIm9tbmmNurJjaPaYqaHiokp2Zi+raL6LbgGE7f4aG2nIwmHI0fPx5r1qzBwYMHERgYiHnz5mHMmDE6bWbNmoX169dj//796Nu3LyZNmoQ5c+Zob4+Pj4eLi4vOfbKvx8fHv/Kx586dC5VKpb2ULVtWj8+MiIio6PiWLYUtY5tiVg8f2FmY4tJ9Nd5dFIZJ684hIZm92gCZxzmaMWMGZs6c+do2ERERqF+/fq7lGzduRO/evfHo0SM4Ojrmed/vv/8ewcHBSEpKAgC0a9cO5cqVwy+//KJtc+/ePZQpUwZhYWFo3LhxnutJS0tDWlqa9rparUbZsmU5zhERERm1x8/S8NWfV7D+dCwAwFZpigltK2OwnxfMiuGhtvyOcyTrOUeBgYHo27fva9t4e3vnuTw7yFy/fv2V4ahx48ZQq9V48OABXFxc4OrqmmsPUUJCAgDk2qOUk1Kp1DkUR0REVBw42ijx7Xu10b+RJ6Zvu4jzsUmYteMS1kbEYEa3kjuApKzhyMnJCU5OBdvwkZGRAAA3N7fXtrGwsECpUqUAAH5+fpgyZQrS09Nhbm4OANi7dy/c3d1fGcKIiIiKuzqe9tgypqm2V1v0g5cDSHau5YapnarBvZSl3CUWKaOYPiQsLAwnTpxAy5YtoVKpEBERgYkTJ6J+/frYunUrAGD79u2Ij4+Hn58fLC0tcfDgQUyaNAkBAQH48ccfAQBJSUmoUqUKWrVqhSlTpuDatWsICAjAtGnT3qgrP6cPISKi4urp83SE7IvGyhN3oBGApZkJAltVxPDm5aA0NZG7vLeS399vowhHZ86cwZgxY3DlyhWkpaXBy8sLffv2xSeffAIrKysAwO7du/H555/j+vXr0Gg0KF++PIYPH46xY8fC1PR/O8iioqIwduxYhIeHw97eHqNGjcK0adPeqBs/wxERERV3l+LUmL7tAiJuv5yrzdvRCtO71kDLqs4yV1ZwxSocGRqGIyIiKgmEENhy9h7m7LqCh8kvOya1qeaML7tUh5ejtczVvTmGo0LEcERERCVJcmoG5h+4jiVHbyFTI2BuqsCoFuUx+p2KsDQ3nkNtDEeFiOGIiIhKousJyZix7RKOXn8EAPAoZYkvOldDBx9Xo5hlguGoEDEcERFRSSWEwJ6L8Zi14zLuPX0BAGhW0QkzulVHRWdbmat7PYajQsRwREREJd2L9CwsOnQDoYduID1TA1OFhKHNyuGjVhVha2Emd3l5YjgqRAxHREREL8U8fo7gHZew//IDAEBpWyWmdKqKHr4eBneojeGoEDEcERER6Tp4JQEzt1/E7cfPAQANvO0xo1sN1HBXyVzZ/zAcFSKGIyIiotzSMrPw65FbWHDgOl5kZEEhAQMaeSGobWXYW5vLXR7DUWFiOCIiInq1uKcvMGfXZew4fx8AUMrKDJPaVUH/hp4wUch3qI3hqBAxHBEREf27sBuPMXP7RVyJTwYAVHW1xYxuNdC4fN4Txhc2hqNCxHBERESUP5lZGqwOj8H3e6OR9CIDANC5lhumdKoGjyKe0JbhqBAxHBEREb2ZJynp+H7fVaw+GQONACzMFBjtXxEf+peHhVnRjLLNcFSIGI6IiIgK5lKcGjO2X0T4rUQARTvKNsNRIWI4IiIiKjghBHacv485uy7jflIqAKBJBUdM71oDVVwLb5RthqNCxHBERET09p6nZyL07xsIPXwT6ZkamCgkDGrshYltKkNlpf9RtvP7+63Q+yMTERER5YOVuSmC2lXBX0H+aF/DBVkagWXHb+Od7w7iSrxatroYjoiIiEhWZR2s8Mug+lg5rBEqOdvAyUaJCqVtZKvHVLZHJiIiIsqhWSUn7BrfHPFJqTAzkW//DfccERERkcEwM1GgrIOVrDUwHBERERHlwHBERERElAPDEREREVEODEdEREREOTAcEREREeXAcERERESUA8MRERERUQ4MR0REREQ5MBwRERER5cBwRERERJQDwxERERFRDgxHRERERDkwHBERERHlYCp3AcZICAEAUKvVMldCRERE+ZX9u539O/4qDEcFkJycDAAoW7aszJUQERHRm0pOToZKpXrl7ZL4t/hEuWg0GsTFxcHW1haSJOltvWq1GmXLlsXdu3dhZ2ent/WSLm7nosNtXTS4nYsGt3PRKMztLIRAcnIy3N3doVC8+swi7jkqAIVCgTJlyhTa+u3s7PjBKwLczkWH27pocDsXDW7nolFY2/l1e4yy8YRsIiIiohwYjoiIiIhyYDgyIEqlEtOnT4dSqZS7lGKN27nocFsXDW7nosHtXDQMYTvzhGwiIiKiHLjniIiIiCgHhiMiIiKiHBiOiIiIiHJgOCIiIiLKgeHIgCxcuBDlypWDhYUF6tWrhyNHjshdktGYO3cuGjRoAFtbWzg7O6NHjx64evWqThshBGbMmAF3d3dYWlrinXfewcWLF3XapKWl4aOPPoKTkxOsra3RrVs3xMbGFuVTMSpz586FJEmYMGGCdhm3s/7cu3cPAwcOhKOjI6ysrODr64vTp09rb+e2fnuZmZn44osvUK5cOVhaWqJ8+fIIDg6GRqPRtuF2fnOHDx9G165d4e7uDkmSsGXLFp3b9bVNnzx5gkGDBkGlUkGlUmHQoEF4+vTp2z8BQQZhzZo1wszMTCxevFhcunRJjB8/XlhbW4s7d+7IXZpRaN++vVi6dKm4cOGCOHv2rOjcubPw9PQUz54907b56quvhK2trdi4caOIiooS77//vnBzcxNqtVrbZtSoUcLDw0Ps27dPnDlzRrRs2VLUrl1bZGZmyvG0DFp4eLjw9vYWtWrVEuPHj9cu53bWj8TEROHl5SUCAgLEyZMnxa1bt8T+/fvF9evXtW24rd/ef/7zH+Ho6Ch27Nghbt26JdavXy9sbGzEvHnztG24nd/crl27xNSpU8XGjRsFALF582ad2/W1TTt06CB8fHzE8ePHxfHjx4WPj4/o0qXLW9fPcGQgGjZsKEaNGqWzrGrVquKzzz6TqSLjlpCQIACIQ4cOCSGE0Gg0wtXVVXz11VfaNqmpqUKlUonQ0FAhhBBPnz4VZmZmYs2aNdo29+7dEwqFQuzevbton4CBS05OFpUqVRL79u0T/v7+2nDE7aw/n376qWjWrNkrb+e21o/OnTuLoUOH6izr1auXGDhwoBCC21kf/hmO9LVNL126JACIEydOaNuEhYUJAOLKlStvVTMPqxmA9PR0nD59Gu3atdNZ3q5dOxw/flymqoxbUlISAMDBwQEAcOvWLcTHx+tsY6VSCX9/f+02Pn36NDIyMnTauLu7w8fHh6/DP4wdOxadO3dGmzZtdJZzO+vPtm3bUL9+fbz33ntwdnZGnTp1sHjxYu3t3Nb60axZM/z111+Ijo4GAJw7dw5Hjx5Fp06dAHA7FwZ9bdOwsDCoVCo0atRI26Zx48ZQqVRvvd058awBePToEbKysuDi4qKz3MXFBfHx8TJVZbyEEAgKCkKzZs3g4+MDANrtmNc2vnPnjraNubk57O3tc7Xh6/A/a9aswZkzZxAREZHrNm5n/bl58yYWLVqEoKAgTJkyBeHh4Rg3bhyUSiUGDx7Mba0nn376KZKSklC1alWYmJggKysLs2fPRr9+/QDwPV0Y9LVN4+Pj4ezsnGv9zs7Ob73dGY4MiCRJOteFELmW0b8LDAzE+fPncfTo0Vy3FWQb83X4n7t372L8+PHYu3cvLCwsXtmO2/ntaTQa1K9fH3PmzAEA1KlTBxcvXsSiRYswePBgbTtu67ezdu1arFy5EqtXr0aNGjVw9uxZTJgwAe7u7hgyZIi2Hbez/uljm+bVXh/bnYfVDICTkxNMTExyJd2EhIRcyZpe76OPPsK2bdtw8OBBlClTRrvc1dUVAF67jV1dXZGeno4nT568sk1Jd/r0aSQkJKBevXowNTWFqakpDh06hJ9++gmmpqba7cTt/Pbc3NxQvXp1nWXVqlVDTEwMAL6n9eXjjz/GZ599hr59+6JmzZoYNGgQJk6ciLlz5wLgdi4M+tqmrq6uePDgQa71P3z48K23O8ORATA3N0e9evWwb98+neX79u1DkyZNZKrKuAghEBgYiE2bNuHAgQMoV66czu3lypWDq6urzjZOT0/HoUOHtNu4Xr16MDMz02lz//59XLhwga/D/2vdujWioqJw9uxZ7aV+/foYMGAAzp49i/Lly3M760nTpk1zDUcRHR0NLy8vAHxP68vz58+hUOj+FJqYmGi78nM765++tqmfnx+SkpIQHh6ubXPy5EkkJSW9/XZ/q9O5SW+yu/L/9ttv4tKlS2LChAnC2tpa3L59W+7SjMLo0aOFSqUSf//9t7h//7728vz5c22br776SqhUKrFp0yYRFRUl+vXrl2fX0TJlyoj9+/eLM2fOiFatWpXo7rj5kbO3mhDczvoSHh4uTE1NxezZs8W1a9fEqlWrhJWVlVi5cqW2Dbf12xsyZIjw8PDQduXftGmTcHJyEp988om2Dbfzm0tOThaRkZEiMjJSABAhISEiMjJSOzyNvrZphw4dRK1atURYWJgICwsTNWvWZFf+4ubnn38WXl5ewtzcXNStW1fbDZ3+HYA8L0uXLtW20Wg0Yvr06cLV1VUolUrRokULERUVpbOeFy9eiMDAQOHg4CAsLS1Fly5dRExMTBE/G+Pyz3DE7aw/27dvFz4+PkKpVIqqVauK//73vzq3c1u/PbVaLcaPHy88PT2FhYWFKF++vJg6dapIS0vTtuF2fnMHDx7M8zt5yJAhQgj9bdPHjx+LAQMGCFtbW2FraysGDBggnjx58tb1S0II8Xb7noiIiIiKD55zRERERJQDwxERERFRDgxHRERERDkwHBERERHlwHBERERElAPDEREREVEODEdEREREOTAcERHpgSRJ2LJli9xlEJEeMBwRkdELCAiAJEm5Lh06dJC7NCIyQqZyF0BEpA8dOnTA0qVLdZYplUqZqiEiY8Y9R0RULCiVSri6uupc7O3tAbw85LVo0SJ07NgRlpaWKFeuHNavX69z/6ioKLRq1QqWlpZwdHTEyJEj8ezZM502S5YsQY0aNaBUKuHm5obAwECd2x89eoSePXvCysoKlSpVwrZt2wr3SRNRoWA4IqIS4csvv8S7776Lc+fOYeDAgejXrx8uX74MAHj+/Dk6dOgAe3t7REREYP369di/f79O+Fm0aBHGjh2LkSNHIioqCtu2bUPFihV1HmPmzJno06cPzp8/j06dOmHAgAFITEws0udJRHrw1lPXEhHJbMiQIcLExERYW1vrXIKDg4UQQgAQo0aN0rlPo0aNxOjRo4UQQvz3v/8V9vb24tmzZ9rbd+7cKRQKhYiPjxdCCOHu7i6mTp36yhoAiC+++EJ7/dmzZ0KSJPHnn3/q7XkSUdHgOUdEVCy0bNkSixYt0lnm4OCg/b+fn5/ObX5+fjh79iwA4PLly6hduzasra21tzdt2hQajQZXr16FJEmIi4tD69atX1tDrVq1tP+3traGra0tEhISCvqUiEgmDEdEVCxYW1vnOsz1byRJAgAIIbT/z6uNpaVlvtZnZmaW674ajeaNaiIi+fGcIyIqEU6cOJHretWqVQEA1atXx9mzZ5GSkqK9/dixY1AoFKhcuTJsbW3h7e2Nv/76q0hrJiJ5cM8RERULaWlpiI+P11lmamoKJycnAMD69etRv359NGvWDKtWrUJ4eDh+++03AMCAAQMwffp0DBkyBDNmzMDDhw/x0UcfYdCgQXBxcQEAzJgxA6NGjYKzszM6duyI5ORkHDt2DB999FHRPlEiKnQMR0RULOzevRtubm46y6pUqYIrV64AeNmTbM2aNRgzZgxcXV2xatUqVK9eHQBgZWWFPXv2YPz48WjQoAGsrKzw7rvvIiQkRLuuIUOGIDU1FT/88AMmT54MJycn9O7du+ieIBEVGUkIIeQugoioMEmShM2bN6NHjx5yl0JERoDnHBERERHlwHBERERElAPPOSKiYo9nDxDRm+CeIyIiIqIcGI6IiIiIcmA4IiIiIsqB4YiIiIgoB4YjIiIiohwYjoiIiIhyYDgiIiIiyoHhiIiIiCgHhiMiIiKiHP4PlQhFboftrI8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7721/2549660499.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# Posterior estimation for the first data point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mmean_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Posterior mean of latent variables:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Posterior covariance of latent variables:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7721/2549660499.py\u001b[0m in \u001b[0;36mposterior\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[1;32m     74\u001b[0m         \u001b[0mcovariance_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mmean_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mcovariance_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'linalg'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class pPCA(nn.Module):\n",
    "    def __init__(self, D, M, sigma=1.0):\n",
    "        \"\"\"\n",
    "        Probabilistic PCA model\n",
    "        \n",
    "        Args:\n",
    "            D (int): Dimensionality of the data.\n",
    "            M (int): Dimensionality of the latent variable.\n",
    "            sigma (float): Standard deviation of the Gaussian noise.\n",
    "        \"\"\"\n",
    "        super(pPCA, self).__init__()\n",
    "        self.D = D  # Dimensionality of input\n",
    "        self.M = M  # Dimensionality of latent space\n",
    "        self.sigma = sigma  # Standard deviation of noise\n",
    "        \n",
    "        # Weight matrix W and bias term b (initialization)\n",
    "        self.W = nn.Parameter(torch.randn(D, M))  # D x M matrix\n",
    "        self.b = nn.Parameter(torch.randn(D))     # D-dimensional bias\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass for pPCA model: x = Wz + b + noise\n",
    "        \n",
    "        Args:\n",
    "            z (Tensor): Latent variable of shape (batch_size, M)\n",
    "        \n",
    "        Returns:\n",
    "            x (Tensor): Data point reconstructed from latent variable, of shape (batch_size, D)\n",
    "        \"\"\"\n",
    "        # Reconstruct the data point\n",
    "        return torch.matmul(z, self.W.t()) + self.b\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood of the data under pPCA model\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Data, shape (batch_size, D)\n",
    "\n",
    "        Returns:\n",
    "            log_likelihood (Tensor): Log-likelihood of the data\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Compute the covariance matrix\n",
    "        covariance_matrix = torch.matmul(self.W, self.W.t()) + self.sigma ** 2 * torch.eye(self.D)\n",
    "\n",
    "        # Compute the log-likelihood of the Gaussian with mean b and covariance covariance_matrix\n",
    "        diff = x - self.b\n",
    "        inverse_covariance = torch.inverse(covariance_matrix)  # Compute the inverse of covariance matrix\n",
    "        log_prob = -0.5 * (torch.sum(torch.matmul(diff, inverse_covariance) * diff, dim=1)\n",
    "                          + batch_size * torch.log(torch.det(covariance_matrix)) + self.D * np.log(2 * np.pi))\n",
    "\n",
    "        return torch.mean(log_prob)\n",
    "\n",
    "\n",
    "    def posterior(self, x):\n",
    "        \"\"\"\n",
    "        Compute the posterior distribution p(z | x)\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Data, shape (batch_size, D)\n",
    "        \n",
    "        Returns:\n",
    "            mean_z (Tensor): Posterior mean for z, shape (batch_size, M)\n",
    "            covariance_z (Tensor): Posterior covariance for z, shape (batch_size, M, M)\n",
    "        \"\"\"\n",
    "        covariance_matrix = torch.matmul(self.W, self.W.t()) + self.sigma ** 2 * torch.eye(self.D)\n",
    "        mean_z = torch.matmul(torch.linalg.inv(covariance_matrix), x - self.b)\n",
    "        covariance_z = torch.linalg.inv(torch.matmul(self.W, self.W.t()) + self.sigma ** 2 * torch.eye(self.M))\n",
    "\n",
    "        return mean_z, covariance_z\n",
    "\n",
    "# Generate synthetic data\n",
    "D = 10  # Dimensionality of the data\n",
    "M = 3   # Latent dimensionality\n",
    "N = 100  # Number of samples\n",
    "\n",
    "# Generate latent variables z ~ N(0, I)\n",
    "z = np.random.randn(N, M)\n",
    "W_true = np.random.randn(D, M)\n",
    "b_true = np.random.randn(D)\n",
    "x_true = np.dot(z, W_true.T) + b_true + np.random.randn(N, D) * 0.1  # Adding noise\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_data = torch.tensor(x_true, dtype=torch.float32)\n",
    "\n",
    "# Initialize pPCA model\n",
    "model = pPCA(D, M)\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "log_likelihoods = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Sample from the latent variable z (random initial guess)\n",
    "    z_init = torch.randn(N, M)\n",
    "    \n",
    "    # Forward pass: Reconstruct data from z\n",
    "    x_reconstructed = model(z_init)\n",
    "\n",
    "    # Compute log-likelihood and backpropagate\n",
    "    log_likelihood = model.log_likelihood(x_data)\n",
    "    log_likelihoods.append(log_likelihood.item())\n",
    "    log_likelihood.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Log-Likelihood: {log_likelihood.item():.4f}')\n",
    "\n",
    "# Plot log-likelihood convergence\n",
    "plt.plot(log_likelihoods)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log-Likelihood')\n",
    "plt.title('Log-Likelihood Convergence during Training')\n",
    "plt.show()\n",
    "\n",
    "# Posterior estimation for the first data point\n",
    "mean_z, covariance_z = model.posterior(x_data[0].unsqueeze(0))\n",
    "print(\"Posterior mean of latent variables:\", mean_z)\n",
    "print(\"Posterior covariance of latent variables:\", covariance_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "class pPCA:\n",
    "    def __init__(self, D, M, sigma=1.0):\n",
    "        \"\"\"\n",
    "        Initializes the Probabilistic PCA model.\n",
    "        \n",
    "        Args:\n",
    "            D (int): Dimensionality of the data\n",
    "            M (int): Number of latent variables\n",
    "            sigma (float): Standard deviation for the Gaussian noise\n",
    "        \"\"\"\n",
    "        self.D = D  # Dimensionality of the data\n",
    "        self.M = M  # Dimensionality of the latent variables\n",
    "        self.sigma = sigma  # Standard deviation of Gaussian noise\n",
    "\n",
    "        # Initialize parameters randomly\n",
    "        self.W = [[random.gauss(0, 1) for _ in range(M)] for _ in range(D)]  # Transformation matrix\n",
    "        self.b = [random.gauss(0, 1) for _ in range(D)]  # Bias term\n",
    "\n",
    "    def matmul(self, A, B):\n",
    "        \"\"\"Performs matrix multiplication (A @ B)\"\"\"\n",
    "        result = []\n",
    "        for i in range(len(A)):\n",
    "            result.append([sum(A[i][k] * B[k][j] for k in range(len(B))) for j in range(len(B[0]))])\n",
    "        return result\n",
    "\n",
    "    def transpose(self, matrix):\n",
    "        \"\"\"Transposes a matrix\"\"\"\n",
    "        return [list(i) for i in zip(*matrix)]\n",
    "\n",
    "    def generate_data(self, batch_size):\n",
    "        \"\"\"\n",
    "        Generate data samples using the model parameters.\n",
    "        \n",
    "        Args:\n",
    "            batch_size (int): Number of data points to generate\n",
    "        \n",
    "        Returns:\n",
    "            List: Generated data points\n",
    "        \"\"\"\n",
    "        data_points = []\n",
    "        for _ in range(batch_size):\n",
    "            # Sample z from standard normal distribution\n",
    "            z = [random.gauss(0, 1) for _ in range(self.M)]\n",
    "            \n",
    "            # Reconstruct x from z\n",
    "            x_reconstructed = [sum(self.W[i][j] * z[j] for j in range(self.M)) + self.b[i] for i in range(self.D)]\n",
    "            \n",
    "            # Add Gaussian noise\n",
    "            noise = [random.gauss(0, self.sigma) for _ in range(self.D)]\n",
    "            x = [x_reconstructed[i] + noise[i] for i in range(self.D)]\n",
    "            \n",
    "            data_points.append(x)\n",
    "        \n",
    "        return data_points\n",
    "\n",
    "    def log_likelihood(self, x_data):\n",
    "        \"\"\"\n",
    "        Compute the log-likelihood of the data under the pPCA model.\n",
    "        \n",
    "        Args:\n",
    "            x_data (List): List of data points\n",
    "        \n",
    "        Returns:\n",
    "            float: Log-likelihood of the data\n",
    "        \"\"\"\n",
    "        log_likelihoods = []\n",
    "        for x in x_data:\n",
    "            # Compute covariance matrix: W * W.T + sigma^2 * I\n",
    "            W_T = self.transpose(self.W)\n",
    "            cov_matrix = self.matmul(self.W, W_T)\n",
    "            \n",
    "            # Add noise term (sigma^2 * I)\n",
    "            for i in range(self.D):\n",
    "                cov_matrix[i][i] += self.sigma ** 2\n",
    "            \n",
    "            # Compute the difference (x - b)\n",
    "            diff = [x[i] - self.b[i] for i in range(self.D)]\n",
    "            \n",
    "            # Compute the log-probability for the Gaussian distribution\n",
    "            det_cov = self.determinant(cov_matrix)\n",
    "            log_prob = -0.5 * (self.vector_dot(self.vector_dot(diff, cov_matrix), diff) + self.D * math.log(2 * math.pi) + math.log(det_cov))\n",
    "            log_likelihoods.append(log_prob)\n",
    "        \n",
    "        return sum(log_likelihoods) / len(log_likelihoods)\n",
    "\n",
    "    def vector_dot(self, A, B):\n",
    "        \"\"\"Computes dot product of two vectors A and B\"\"\"\n",
    "        return sum(A[i] * B[i] for i in range(len(A)))\n",
    "\n",
    "    def determinant(self, matrix):\n",
    "        \"\"\"Computes the determinant of a square matrix using recursion (Laplace expansion)\"\"\"\n",
    "        n = len(matrix)\n",
    "        if n == 1:\n",
    "            return matrix[0][0]\n",
    "        elif n == 2:\n",
    "            return matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "        \n",
    "        det = 0\n",
    "        for c in range(n):\n",
    "            # Minor matrix for element at matrix[0][c]\n",
    "            minor = [row[:c] + row[c+1:] for row in matrix[1:]]\n",
    "            det += ((-1) ** c) * matrix[0][c] * self.determinant(minor)\n",
    "        \n",
    "        return det\n",
    "\n",
    "# Initialize the model\n",
    "D = 20  # Data dimensionality\n",
    "M = 5   # Latent space dimensionality\n",
    "sigma = 1.0  # Gaussian noise standard deviation\n",
    "model = pPCA(D, M, sigma)\n",
    "\n",
    "# Example usage with synthetic data\n",
    "batch_size = 10\n",
    "x_data = model.generate_data(batch_size)\n",
    "\n",
    "# Compute log-likelihood of the generated data\n",
    "log_likelihood = model.log_likelihood(x_data)\n",
    "print(f\"Log-Likelihood of the data: {log_likelihood}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888a8af8",
   "metadata": {},
   "source": [
    "###  Variational Auto-encoders: Variational Inference for Nonlinear Latent Variable Models\n",
    "\n",
    "####  The Model and the Objective\n",
    "\n",
    "Let us take a look at the integral one more time and think of a general case where we cannot calculate it analytically. The simplest approach would be to use the Monte Carlo approximation:\n",
    "\n",
    "$$\n",
    "\\int p(x) = \\int p(x|z) p(z) \\, dz\n",
    "$$\n",
    "\n",
    "This can be approximated as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{z \\sim p(z)} [p(x|z)]\n",
    "$$\n",
    "\n",
    "or equivalently:\n",
    "\n",
    "$$\n",
    "\\frac{1}{K} \\sum_{k=1}^{K} p(x|z_k)\n",
    "$$\n",
    "\n",
    "where, in the last line, we use samples from the prior over latents, $ z_k \\sim p(z) $. Such an approach is relatively easy, and since our computational power grows rapidly, we can sample a lot of points in a reasonably short time. However, as we know from statistics, if $ z $ is multidimensional, and $ M $ is relatively large, we encounter the curse of dimensionality, and to cover the space properly, the number of samples grows exponentially with respect to $ M $. If we take too few samples, the approximation becomes poor.\n",
    "\n",
    "We can use more advanced Monte Carlo techniques, but they still suffer from issues associated with the curse of dimensionality. An alternative approach is an application of **variational inference**.\n",
    "\n",
    "Let us consider a family of variational distributions parameterized by $ \\phi $, $ \\{q_{\\phi}(z)\\}_{\\phi} $. For instance, we can consider Gaussians with means and variances, $ \\phi = \\{ \\mu, \\sigma^2 \\} $. We know the form of these distributions, and we assume that they assign nonzero probability mass to all $ z \\in \\mathbb{R}^M $.\n",
    "\n",
    "Then, the logarithm of the marginal distribution could be approximated as follows:\n",
    "\n",
    "$$\n",
    "\\ln p(x) = \\ln \\int p(x|z) p(z) \\, dz\n",
    "$$\n",
    "\n",
    "Using the variational distribution $ q_\\phi(z) $, we can rewrite it as:\n",
    "\n",
    "$$\n",
    "\\ln p(x) = \\int q_\\phi(z) \\frac{p(x|z) p(z)}{q_\\phi(z)} \\, dz\n",
    "$$\n",
    "\n",
    "By applying **Jensen's inequality**, we get the following lower bound:\n",
    "\n",
    "$$\n",
    "\\ln p(x) \\geq \\mathbb{E}_{z \\sim q_\\phi(z)} \\left[ \\ln \\frac{p(x|z) p(z)}{q_\\phi(z)} \\right]\n",
    "$$\n",
    "\n",
    "This can be expanded as:\n",
    "\n",
    "$$\n",
    "\\ln p(x) \\geq \\mathbb{E}_{z \\sim q_\\phi(z)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z)} \\left[ \\ln q_\\phi(z) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "This is the basis of variational inference, where the objective is to maximize the **ELBO (Evidence Lower Bound)**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\phi) = \\mathbb{E}_{z \\sim q_\\phi(z)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z)} \\left[ \\ln q_\\phi(z) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "This approach avoids the curse of dimensionality by approximating the intractable integral with a simpler variational distribution $ q_\\phi(z) $.\n",
    "\n",
    "###  Variational Auto-encoders: Variational Inference for Nonlinear Latent Variable Models\n",
    "\n",
    "####  The Amortized Variational Posterior\n",
    "\n",
    "If we consider an amortized variational posterior, namely, $ q_\\phi(z|x) $ instead of $ q_\\phi(z) $ for each $ x $, then we get:\n",
    "\n",
    "$$\n",
    "\\ln p(x) \\geq \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "Amortization could be extremely useful because we train a single model (e.g., a neural network with some weights), and it returns the parameters of the distribution for a given input. From now on, we will assume that we use amortized variational posteriors. However, please remember that we do not need to do that! Please refer to [5], where semi-amortized variational inference is considered.\n",
    "\n",
    "As a result, we obtain an auto-encoder-like model, with a **stochastic encoder**, $ q_\\phi(z|x) $, and a **stochastic decoder**, $ p(x|z) $. We use \"stochastic\" to highlight that the encoder and the decoder are probability distributions, in contrast to a deterministic auto-encoder. This model, with the amortized variational posterior, is called a **Variational Auto-Encoder (VAE)**.\n",
    "\n",
    "The lower bound of the log-likelihood function is called the **evidence lower bound (ELBO)**. The first part of the ELBO, $ \\mathbb{E}_{z \\sim q_\\phi(z|x)} [\\ln p(x|z)] $, is referred to as the **(negative) reconstruction error**, because $ x $ is encoded to $ z $ and then decoded back. The second part of the ELBO, $ \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) - \\ln p(z) \\right] $, could be seen as a **regularizer**, and it coincides with the **Kullback-Leibler divergence (KL)**. However, for more complex models (e.g., hierarchical models), the regularizer(s) may not be interpreted as the KL term, so we prefer to use the term **regularizer**, as it is more general.\n",
    "\n",
    "#### A Different Perspective on the ELBO\n",
    "\n",
    "For completeness, we provide a different derivation of the ELBO that will help us understand why the lower bound might be tricky sometimes:\n",
    "\n",
    "$$\n",
    "\\ln p(x) = \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x) \\right]\n",
    "$$\n",
    "\n",
    "We can expand this expression as:\n",
    "\n",
    "$$\n",
    "p(z|x)p(x) = \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\ln \\left( \\frac{p(z|x)p(x)}{q_\\phi(z|x)} \\right)\n",
    "$$\n",
    "\n",
    "Simplifying further:\n",
    "\n",
    "$$\n",
    "= \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\ln \\left( \\frac{p(x|z)p(z)}{q_\\phi(z|x)} \\right)\n",
    "$$\n",
    "\n",
    "Breaking it down into terms:\n",
    "\n",
    "$$\n",
    "= \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "This leads us to the final expression for the ELBO:\n",
    "\n",
    "$$\n",
    "\\ln p(x) \\geq \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "This formulation highlights the **Kullback-Leibler divergence** between the variational posterior $ q_\\phi(z|x) $ and the true posterior $ p(z|x) $, which measures the gap between the variational distribution and the true distribution. This KL divergence term is always greater than or equal to zero.\n",
    "\n",
    "Thus, the ELBO can be thought of as a lower bound on the true log-likelihood, with the KL term representing the gap between the ELBO and the true log-likelihood.\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "If the variational posterior $ q_\\phi(z|x) $ is a poor approximation of the true posterior $ p(z|x) $, then the KL term will be large, and even if the ELBO is optimized well, the gap between the ELBO and the true log-likelihood could be huge. This means that if we use too simplistic a posterior, we could end up with a bad VAE, even if the ELBO is optimized effectively.\n",
    "\n",
    "The problem arises when the ELBO is a loose lower bound of the log-likelihood, which means the optimal solution of the ELBO could be completely different from the solution of the log-likelihood.\n",
    "\n",
    "#### Final Considerations\n",
    "\n",
    "This insight emphasizes the importance of choosing a good approximation for the variational posterior $ q_\\phi(z|x) $. If we take a too simplistic posterior, the VAE might not perform well, and the ELBO might not adequately reflect the true log-likelihood.\n",
    "\n",
    "This is why carefully designing the variational posterior, such as using more complex models (e.g., hierarchical models), can improve the performance of the VAE and reduce the gap between the ELBO and the true log-likelihood.\n",
    "\n",
    "###  Variational Auto-encoders: Variational Inference for Nonlinear Latent Variable Models\n",
    "\n",
    "####  The Amortized Variational Posterior\n",
    "\n",
    "If we consider an amortized variational posterior, namely, $ q_\\phi(z|x) $ instead of $ q_\\phi(z) $ for each $ x $, then we get:\n",
    "\n",
    "$$\n",
    "\\ln p(x) \\geq \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "Amortization could be extremely useful because we train a single model (e.g., a neural network with some weights), and it returns the parameters of the distribution for a given input. From now on, we will assume that we use amortized variational posteriors. However, please remember that we do not need to do that! Please refer to [5], where semi-amortized variational inference is considered.\n",
    "\n",
    "As a result, we obtain an auto-encoder-like model, with a **stochastic encoder**, $ q_\\phi(z|x) $, and a **stochastic decoder**, $ p(x|z) $. We use \"stochastic\" to highlight that the encoder and the decoder are probability distributions, in contrast to a deterministic auto-encoder. This model, with the amortized variational posterior, is called a **Variational Auto-Encoder (VAE)**.\n",
    "\n",
    "The lower bound of the log-likelihood function is called the **evidence lower bound (ELBO)**. The first part of the ELBO, $ \\mathbb{E}_{z \\sim q_\\phi(z|x)} [\\ln p(x|z)] $, is referred to as the **(negative) reconstruction error**, because $ x $ is encoded to $ z $ and then decoded back. The second part of the ELBO, $ \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) - \\ln p(z) \\right] $, could be seen as a **regularizer**, and it coincides with the **Kullback-Leibler divergence (KL)**. However, for more complex models (e.g., hierarchical models), the regularizer(s) may not be interpreted as the KL term, so we prefer to use the term **regularizer**, as it is more general.\n",
    "\n",
    "####  A Different Perspective on the ELBO\n",
    "\n",
    "For completeness, we provide a different derivation of the ELBO that will help us understand why the lower bound might be tricky sometimes:\n",
    "\n",
    "$$\n",
    "\\ln p(x) = \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x) \\right]\n",
    "$$\n",
    "\n",
    "We can expand this expression as:\n",
    "\n",
    "$$\n",
    "p(z|x)p(x) = \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\ln \\left( \\frac{p(z|x)p(x)}{q_\\phi(z|x)} \\right)\n",
    "$$\n",
    "\n",
    "Simplifying further:\n",
    "\n",
    "$$\n",
    "= \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\ln \\left( \\frac{p(x|z)p(z)}{q_\\phi(z|x)} \\right)\n",
    "$$\n",
    "\n",
    "Breaking it down into terms:\n",
    "\n",
    "$$\n",
    "= \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "This leads us to the final expression for the ELBO:\n",
    "\n",
    "$$\n",
    "\\ln p(x) \\geq \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_\\phi(z|x)} \\left[ \\ln q_\\phi(z|x) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "This formulation highlights the **Kullback-Leibler divergence** between the variational posterior $ q_\\phi(z|x) $ and the true posterior $ p(z|x) $, which measures the gap between the variational distribution and the true distribution. This KL divergence term is always greater than or equal to zero.\n",
    "\n",
    "Thus, the ELBO can be thought of as a lower bound on the true log-likelihood, with the KL term representing the gap between the ELBO and the true log-likelihood.\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "If the variational posterior $ q_\\phi(z|x) $ is a poor approximation of the true posterior $ p(z|x) $, then the KL term will be large, and even if the ELBO is optimized well, the gap between the ELBO and the true log-likelihood could be huge. This means that if we use too simplistic a posterior, we could end up with a bad VAE, even if the ELBO is optimized effectively.\n",
    "\n",
    "The problem arises when the ELBO is a loose lower bound of the log-likelihood, which means the optimal solution of the ELBO could be completely different from the solution of the log-likelihood.\n",
    "\n",
    "#### Final Considerations\n",
    "\n",
    "This insight emphasizes the importance of choosing a good approximation for the variational posterior $ q_\\phi(z|x) $. If we take a too simplistic posterior, the VAE might not perform well, and the ELBO might not adequately reflect the true log-likelihood.\n",
    "\n",
    "This is why carefully designing the variational posterior, such as using more complex models (e.g., hierarchical models), can improve the performance of the VAE and reduce the gap between the ELBO and the true log-likelihood.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the encoder network (Q_phi)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mu = nn.Linear(hidden_dim, latent_dim)  # mean of z\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)  # log variance of z\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        mu = self.fc2_mu(h1)\n",
    "        logvar = self.fc2_logvar(h1)\n",
    "        return mu, logvar  # Return mean and log variance for the posterior distribution\n",
    "\n",
    "# Define the decoder network (P_theta)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h1 = F.relu(self.fc1(z))\n",
    "        x_recon = torch.sigmoid(self.fc2(h1))  # For binary data, use sigmoid\n",
    "        return x_recon\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    def loss_function(self, x, x_recon, mu, logvar):\n",
    "        # Compute the reconstruction loss (negative log-likelihood)\n",
    "        BCE = F.binary_cross_entropy(x_recon, x, reduction='sum')\n",
    "\n",
    "        # Compute the KL divergence\n",
    "        # Kullback-Leibler divergence between q(z|x) and p(z)\n",
    "        # q(z|x) = N(mu, exp(logvar)), p(z) = N(0, I)\n",
    "        # KL(q(z|x) || p(z)) = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        # where mu and logvar are the mean and log variance from the encoder output\n",
    "        # and the sigma^2 is exp(logvar).\n",
    "        # You can think of this as the regularizer term.\n",
    "        KL_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        # The ELBO (evidence lower bound) is the negative of this loss:\n",
    "        # ELBO = Reconstruction Loss + KL Divergence\n",
    "        return BCE + KL_div\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 784  # For MNIST dataset (28x28 images)\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Example input data\n",
    "# Let's assume x_data is a batch of images, shape: [batch_size, input_dim]\n",
    "x_data = torch.randn(batch_size, input_dim)  # Replace with real data\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "model = VAE(input_dim, hidden_dim, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    x_recon, mu, logvar = model(x_data)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = model.loss_function(x_data, x_recon, mu, logvar)\n",
    "\n",
    "    # Backpropagation and optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# After training, we can use the VAE to generate new samples or calculate the ELBO on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9fc223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the encoder network (Q_phi)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mu = nn.Linear(hidden_dim, latent_dim)  # mean of z\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)  # log variance of z\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        mu = self.fc2_mu(h1)\n",
    "        logvar = self.fc2_logvar(h1)\n",
    "        return mu, logvar  # Return mean and log variance for the posterior distribution\n",
    "\n",
    "# Define the decoder network (P_theta)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h1 = F.relu(self.fc1(z))\n",
    "        x_recon = torch.sigmoid(self.fc2(h1))  # For binary data, use sigmoid\n",
    "        return x_recon\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    def loss_function(self, x, x_recon, mu, logvar):\n",
    "        # Compute the reconstruction loss (negative log-likelihood)\n",
    "        BCE = F.binary_cross_entropy(x_recon, x, reduction='sum')\n",
    "\n",
    "        # Compute the KL divergence\n",
    "        # Kullback-Leibler divergence between q(z|x) and p(z)\n",
    "        # q(z|x) = N(mu, exp(logvar)), p(z) = N(0, I)\n",
    "        # KL(q(z|x) || p(z)) = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        # where mu and logvar are the mean and log variance from the encoder output\n",
    "        # and the sigma^2 is exp(logvar).\n",
    "        # You can think of this as the regularizer term.\n",
    "        KL_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        # The ELBO (evidence lower bound) is the negative of this loss:\n",
    "        # ELBO = Reconstruction Loss + KL Divergence\n",
    "        return BCE + KL_div\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 784  # For MNIST dataset (28x28 images)\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Example input data\n",
    "# Let's assume x_data is a batch of images, shape: [batch_size, input_dim]\n",
    "x_data = torch.randn(batch_size, input_dim)  # Replace with real data\n",
    "\n",
    "# Initialize the model, optimizer, and loss function\n",
    "model = VAE(input_dim, hidden_dim, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    x_recon, mu, logvar = model(x_data)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = model.loss_function(x_data, x_recon, mu, logvar)\n",
    "\n",
    "    # Backpropagation and optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# After training, we can use the VAE to generate new samples or calculate the ELBO on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd89dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Define a basic random normal distribution generator (for simplicity)\n",
    "def normal_sample(mu, logvar):\n",
    "    # Reparameterization trick: z = mu + eps * sigma\n",
    "    std = math.exp(0.5 * logvar)\n",
    "    eps = random.gauss(0, 1)  # Gaussian noise\n",
    "    return mu + eps * std\n",
    "\n",
    "# Encoder (Q_phi)\n",
    "def encoder(x, W1, b1, W2, b2):\n",
    "    # Linear transformation (layer 1)\n",
    "    h1 = [sum(xi * wi for xi, wi in zip(x, W1[j])) + b1[j] for j in range(len(W1))]\n",
    "    # ReLU activation\n",
    "    h1 = [max(0, h) for h in h1]\n",
    "    \n",
    "    # Output mean (mu) and log variance (logvar) from layer 2\n",
    "    mu = [sum(h1i * wi for h1i, wi in zip(h1, W2[j])) + b2[j] for j in range(len(W2))]\n",
    "    logvar = [random.uniform(-1, 1) for _ in range(len(mu))]  # Initialize logvar randomly\n",
    "    return mu, logvar\n",
    "\n",
    "# Decoder (P_theta)\n",
    "def decoder(z, W1, b1, W2, b2):\n",
    "    # Linear transformation (layer 1)\n",
    "    h1 = [sum(zi * wi for zi, wi in zip(z, W1[j])) + b1[j] for j in range(len(W1))]\n",
    "    # ReLU activation\n",
    "    h1 = [max(0, h) for h in h1]\n",
    "    \n",
    "    # Output (reconstructed x)\n",
    "    x_recon = [sum(h1i * wi for h1i, wi in zip(h1, W2[j])) + b2[j] for j in range(len(W2))]\n",
    "    return x_recon\n",
    "\n",
    "# Reconstruction loss (binary cross-entropy)\n",
    "def reconstruction_loss(x, x_recon):\n",
    "    return -sum(xi * math.log(x_recon[i] + 1e-10) + (1 - xi) * math.log(1 - x_recon[i] + 1e-10) for i, xi in enumerate(x))\n",
    "\n",
    "# KL Divergence\n",
    "def kl_divergence(mu, logvar):\n",
    "    return -0.5 * sum(1 + logvar[i] - mu[i]**2 - math.exp(logvar[i]) for i in range(len(mu)))\n",
    "\n",
    "# Variational Autoencoder (VAE)\n",
    "def vae(x, W1_enc, b1_enc, W2_enc, b2_enc, W1_dec, b1_dec, W2_dec, b2_dec):\n",
    "    # Encoder: Get the mean (mu) and log variance (logvar) for the latent variable z\n",
    "    mu, logvar = encoder(x, W1_enc, b1_enc, W2_enc, b2_enc)\n",
    "    \n",
    "    # Sample z from the approximate posterior q(z|x)\n",
    "    z = [normal_sample(mu[i], logvar[i]) for i in range(len(mu))]\n",
    "    \n",
    "    # Decoder: Reconstruct x from z\n",
    "    x_recon = decoder(z, W1_dec, b1_dec, W2_dec, b2_dec)\n",
    "    \n",
    "    # Compute the total loss (ELBO)\n",
    "    recon_loss = reconstruction_loss(x, x_recon)\n",
    "    kl_loss = kl_divergence(mu, logvar)\n",
    "    total_loss = recon_loss + kl_loss\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "# Example data (a simple vector x)\n",
    "x_data = [random.randint(0, 1) for _ in range(784)]  # Random binary data (e.g., a flattened image)\n",
    "\n",
    "# Initialize parameters (weights and biases)\n",
    "input_dim = 784  # For MNIST images (28x28)\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "\n",
    "W1_enc = [[random.random() for _ in range(input_dim)] for _ in range(hidden_dim)]\n",
    "b1_enc = [random.random() for _ in range(hidden_dim)]\n",
    "W2_enc = [[random.random() for _ in range(hidden_dim)] for _ in range(latent_dim)]\n",
    "b2_enc = [random.random() for _ in range(latent_dim)]\n",
    "\n",
    "W1_dec = [[random.random() for _ in range(latent_dim)] for _ in range(hidden_dim)]\n",
    "b1_dec = [random.random() for _ in range(hidden_dim)]\n",
    "W2_dec = [[random.random() for _ in range(hidden_dim)] for _ in range(input_dim)]\n",
    "b2_dec = [random.random() for _ in range(input_dim)]\n",
    "\n",
    "# Forward pass through VAE and compute loss\n",
    "total_loss, recon_loss, kl_loss = vae(x_data, W1_enc, b1_enc, W2_enc, b2_enc, W1_dec, b1_dec, W2_dec, b2_dec)\n",
    "\n",
    "print(f\"Total Loss: {total_loss}\")\n",
    "print(f\"Reconstruction Loss: {recon_loss}\")\n",
    "print(f\"KL Divergence: {kl_loss}\")\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ee7e6755",
   "metadata": {},
   "source": [
    "### Components of VAEs\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.2 The ELBO is a lower bound on the log-likelihood. As a result, . maximizing the ELBO does not necessarily coincides with .  that maximizes .ln p(x). The looser the ELBO is, the more this can bias maximum likelihood estimates of the model parameters.\n",
    "\n",
    "Let us wrap up what we know right now. First of all, we consider a class of amortized variational posteriors $ \\{ q_{\\phi}(z|x) \\}_{\\phi} $ that approximate the true posterior $ p(z|x) $. We can see them as stochastic encoders. Second, the conditional likelihood $ p(x|z) $ could be seen as a stochastic decoder. Third, the last component, $ p(z) $, is the marginal distribution, also referred to as a prior. Lastly, the objective is the ELBO, a lower bound to the log-likelihood function:\n",
    "\n",
    "$$\n",
    "\\ln p(x) \\geq \\mathbb{E}_{z \\sim q_{\\phi}(z | x)} \\left[ \\ln p(x|z) \\right] - \\mathbb{E}_{z \\sim q_{\\phi}(z | x)} \\left[ \\ln q_{\\phi}(z | x) \\right] - \\ln p(z)\n",
    "$$\n",
    "\n",
    "There are two questions left to get the full picture of the VAEs:\n",
    "\n",
    "1. How to parameterize the distributions?\n",
    "2. How to calculate the expected values?\n",
    "\n",
    "After all, these integrals have not disappeared!\n",
    "\n",
    "### Parameterization of Distributions\n",
    "\n",
    "As you can probably guess by now, we use neural networks to parameterize the encoders and the decoders. But before we use the neural networks, we should know what distributions we use! Fortunately, in the VAE framework, we are almost free to choose any distribution! However, we must remember that they should make sense for a considered problem.\n",
    "\n",
    "So far, we have explained everything through images, so let us continue that. If $ x \\in \\{ 0, 1, \\dots, 255 \\}^D $, then we cannot use a normal distribution, because its support is totally different than the support of discrete-valued images. A possible distribution we can use is the categorical distribution, that is:\n",
    "\n",
    "$$\n",
    "p_{\\theta}(x|z) = \\text{Categorical}(x | \\theta(z)),\n",
    "$$\n",
    "\n",
    "where the probabilities are given by a neural network $ \\text{NN} $, namely, $ \\theta(z) = \\text{softmax}(\\text{NN}(z)) $. The neural network $ \\text{NN} $ could be an MLP, a convolutional neural network, RNNs, etc.\n",
    "\n",
    "The choice of a distribution for the latent variables depends on how we want to express the latent factors in data. For convenience, typically $ z $ is taken as a vector of continuous random variables, $ z \\in \\mathbb{R}^M $. Then, we can use Gaussians for both the variational posterior and the prior:\n",
    "\n",
    "$$\n",
    "q_{\\phi}(z|x) = \\mathcal{N}\\left(z \\,|\\, \\mu_{\\phi}(x), \\text{diag}(\\sigma_{\\phi}^2(x))\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(z) = \\mathcal{N}(z | 0, I),\n",
    "$$\n",
    "\n",
    "where $ \\mu_{\\phi}(x) $ and $ \\sigma_{\\phi}^2(x) $ are outputs of a neural network, similarly to the case of the decoder. In practice, we can have a shared neural network $ \\text{NN}(x) $ that outputs $ 2M $ values that are further split into $ M $ values for the mean $ \\mu $ and $ M $ values for the variance $ \\sigma^2 $. For convenience, we consider a diagonal covariance matrix. We could use flexible posteriors (see Section 5.4.2). Moreover, here we take the standard Gaussian prior. We will comment on that later (see Section 5.4.1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db605296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set up the parameters\n",
    "latent_dim = 2  # Dimensionality of the latent space\n",
    "input_dim = 784  # Assuming input data is 28x28 (MNIST)\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "# Build the encoder network\n",
    "def build_encoder():\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(512, activation='relu')(inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    # The mean and log variance\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    \n",
    "    encoder = Model(inputs, [z_mean, z_log_var], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "# Sampling function to sample from the latent space using the reparameterization trick\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    z = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    return z\n",
    "\n",
    "# Build the decoder network\n",
    "def build_decoder():\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(256, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    outputs = layers.Dense(input_dim, activation='sigmoid')(x)\n",
    "    \n",
    "    decoder = Model(latent_inputs, outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "# VAE model class\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        z = sampling([z_mean, z_log_var])\n",
    "        reconstructed = self.decoder(z)\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
    "        )\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, input_dim)\n",
    "x_test = x_test.reshape(-1, input_dim)\n",
    "\n",
    "# Build the VAE\n",
    "encoder = build_encoder()\n",
    "decoder = build_decoder()\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "# Compile the VAE\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "# Train the VAE\n",
    "vae.fit(x_train, x_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, x_test))\n",
    "\n",
    "# Generate new data (sample from latent space)\n",
    "def generate_data(num_samples):\n",
    "    z = np.random.normal(size=(num_samples, latent_dim))\n",
    "    generated_data = vae.decoder(z)\n",
    "    return generated_data\n",
    "\n",
    "# Visualize the results\n",
    "def visualize_latent_space():\n",
    "    z_mean, z_log_var = encoder.predict(x_test, batch_size=batch_size)\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c='blue')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot new images\n",
    "def plot_generated_images():\n",
    "    generated_data = generate_data(16)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(generated_data[i].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the latent space\n",
    "visualize_latent_space()\n",
    "\n",
    "# Plot some generated images\n",
    "plot_generated_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
