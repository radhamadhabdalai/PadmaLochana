{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2004 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAB2CAIAAACGWfvLAAAgAElEQVR4Ae19eVRUR9r3e3LO98058887M3/NnG/mzGQmb2be1ySocUliNjUhMZPFRMcYzWIEZdG4G43LJDFuEZUkYiQogmwim4oGQRYBFUFxQUQEgabBphtoupve771VxXfqXvqm6Nt9b9MNl/btruPBulVPPc9T1c/vqeVW1f2PgWAItkCwBbxqgf/wqlSwULAFgi0wEARP0AiCLeBlCwTB42XDBYsFWyAInqANBFvAyxYIgsfLhgsWC7ZAEDxBGwi2gJctEASPlw0XLBZsgSB4gjYQbAEvWyAIHi8bLlgs2ALygQdCWF9fDyFECA0MDLj86zKRJJaBgBMngyBJEf6jCadqEC1OLSAreGbPnn3//n0UDA9hCzjZTfBxYEDGHQZqtfrXv/71li1bRDyuSJZsblg2QZKV9R9Ngj2PS2chX8+zc+fORx555NFHH7Xb7Q+h5w10lV1aT4Anygee5OTkadOm7dy5U6PRcD5V+FfSGctA4D/+3n80CfY8Lt2EfOCBEEZGRjIME+g+/OGsv0vrCfBE+cCDEFq6dCkAQKT3EMmSzQ3LJkiysv6jSbDncekmZAVPWFgYt1T9cDrfgNbapfUEeOLYgIfzqcK/ks5YBgL/8ff+o0mw53HpJmQFz+LFi4M9z0Paf7m0ngBPlBU84eHhPoIHIggRnjUNBggQwlsW2ACJuCPN5f+4BF/KJUUw0bkFAhwnLqsvK3iWLFni4/Ycm91O0xx4AMOgxPQ7San1CEIbTTfc0UDIIAwtGiEoGBMCiJGGAEDXb6pcEQzZNCTD+FBSRHDY5tJk/SdRVvAsXbrU2aEN8/n7+NqCoja24wAXKtqT0241NWshZFIz6zU9ZpqmTuQ15he03GnoJhlDCO429sR8V2WzMQjBwuK26zfVHJZIsmBcpAX8x2T9RxNZwRMREcH9PIJuYdDrSzrjTd9cXLGhBEEAIcw93cz2Y8BgtB9NvQ0hLL3UXlLextC2dVsryDVxCOl2Zd+8T04azRTufKB9Z0wNBx6vNZFU1XeCYM/jPzhxqYms4ImMjOR9G0SQoZmiC21JaXdNRis3nIMQ6A0WiqIhfmYghMzgIA1PUiACmblN78zN6+7ph4DJyb/PTV1Scxqqr6kghDv2V9+5040gXPVFqU5vHTqxgR8sPmW00KwCzN4D1f39wV1C/K8hHXFpPQGeKCt4oqKiuF+J9akwJfNWfGKt2cIhB8/gz51vWbG+dOPWMnWPESHU2KS7VfcADLCTewh0feaKyvav91zOy2/uN9lLylq5Wf+O/ZdaFHoI4ZYdlXcbexBEa7aUdmkMQyc2AIPHjMEzAODRjPq2dh10MTXytA/0vWOR5BDsefwcnHKDh+thOAgtX1+Wdepe5WWFw+8xp36+DyGt1Vm+3HXpUOLNz/99wWi0A3Z5DUDm9Nnmnl7L7cbujyPOnD57v729nyv4zbcXFcp+hJjd31Xfvt0NIIxee96gN7IDM35pDi4IO8UN2yCEadmNbQrd0K7JoUXwf1ct4Od2PCbqyQqe6Oho7nfBPhWCzdsqNT1mi5UbpEEEgdlCQQTwiA0wza06k8XGPkKrjWps7knNamDNHSxdUxi+rNhODY674o/erMOjNVB1teNMYSvDwHVbygDDxB64RtN4doQQoAH816Ks3n4Kd1aQ+f5QbU8PHtc5vDs+nPeLbmyMy3L3V7Lf8J3AoduQZUChPr4L8pDDmBioPwuVFTxRUVF8zwMh7NGafi5qO1/eBgC2b4f1uvi/Xan718enq652cHmNTT2FJa3sCx+MBVWXOT2rHq8EMLCwuLW4tKmlTQshnXjspkZthnh1gamsaMk52Xiu+C6N8QS2f1sFIMDTKAxHABADIMM9uhAfTGIP//qzHY+JbrKCZ0jPg62WXRdgX7/w9in0rAMI4QEYfgXKznEGsLk7XnLiHgMC5qcj12123GshTMnmApBzqp4BDFeWBQaGKISooan73Pn7ADIMw9TeVH+XULv5m8rN2yoOJd9qaOxlMfkLkl3ow54h99Bbi5CJZJFCJclkIxgTA/VnoWMDHh4qIxKBEKo0/dXXOvluDSMK0nr94CIeKQVAeOZMi81Gnzl3/91F+eNnHJsbdmbF5tLPvih95+PT42ce+yCi4MLFdgc4yaIBHfdnIx4r3WQFD7/aNjpmyPZLv7B2ehzMgAjp9P0R6wonv5b2fUKtpsfEZrBbeyBSKPXb91dNDk3Z/X0VTXPr2r9wDOTYWBmoP8sdG/CQwxIyLsMIRK+3vfvxqVfnZd9r6oF4soUxxunA9ld4BnSxumPia+kbv67kj+6RSvLEwkQyhWdLJpJxSQKOWJJMNgJ/tuMx0U1W8JAvScfEi9MMvXTN+Vfm5bS168UVqLjc8fRrabHxtRAG+x/cVGNinX4udGzAQzpgMj6aThT3MGlZd6bOSr3XokdQuHN0yIowgszJn5uemplccRkv8Q2wL2rlUnWoJo6OkZROxkez0X7pk/3cjsdEPVnBw+9tE/f6o5Tb1qGf9s/0zJy75LqCe1l4TPfvXRdfnH28C8+LXM+g3Bf/35YzJtbp50JlBQ8/bCMdJxkfHSeKFwMYwIR9dv79pfki05ihmmC09Oksz89O37bnCv9OideQj5ClyLjvBBw33/mMFAc/N2X51ZMVPGPU82AYFJcpQqYnXr46ZDlbsneAEPxc0jo5NLmpWedZfyXJ8mElkN80/V+irODhz/OQHpqMj5SPdOIDADM/Mn/5hlJuHwMp0V2c54Ag+GhZ4dLVBRBvQcCBK8JHJDl4TSCbIA/r4v/WLLOGYwMeOd0vRKisXDnp1dQWRa93cssqFU/NSL5+o8u74v87Sslslw+FOFnBExYWxlmS187YQx/JkyGEd63N+SR/7VcXEMDHSPksdzo4+Xs0gBgGvLvo5OdfVpLFJfn4TuCkiTuFvRCEN0bh04LsVib2J3HHnNThoTBoOZUcG/DI5owhQldqVE/NOFZTq+KOjnojGsLCkrbJr6V2qc3+uOzmmI15vrGVgdBUV9dXmG9TP+DGopLNIqdRPiyyZAXP4sWLJX+kkSWAkFmxqeyj6LNg6PbT4UoBgHlv0elvYq6wd4wMt/TI09Nmk6UXj0IhhMbr1aq1EXZTP2WxWOvrPBFG0bTm8EGqt7t72+fWnh5ruwLvaxcND4tBy6mnrOD59NNPuR/I3SDBixGIUxGnx+4e8/jQlNIKJXF0Z8grSH5YwlsOn0IqiRA8klo/aVaKXm9zSUASe0WAuw28yZzbZEd8/MupRhxzbWqCNnYn3l4OkTb3OGPSAYC6jx+m+vv5/ePcIUKywTHY8D/IQIaGsC83y9qEPzemz8rkVvCFtSDrIqddPhSyZAVPeHg4b6PyRA4lXw99P9dOSWyxAQAYDAbH8MeFahChTpVpwiupuWcbXWT7nAQhpE39tr5eu07HAP7AhVu+2iM/PlgdyQCa7jcYK0oAw9j6unWJBxl2KkPpdQxElMWMD2AQgWFoi7bH1KOxmIy9KWmauP09Z/IQQvqyYtP1K+Ij0ofCmmVWUlbwLFmyhPspxT2cS19LukBPCBBEFA1C52Z9e+Cq0+5PJ+llZWWfffbZvn37SN2cRHADpIh1xVHriniMOfERFvGcAALYdTBW++12/alcVg3cOehLi3WnsxmKYiBtVii4kSee6UOgL8hT7dxKKdssN6/T6g4GIXP1pb7SnwFkaAS6fohhEHqwYzvjOGyLIKD0fep/b+3csEIVsUhfVaFvbdG3Npn6+nDVejXdP37vpD+pPJcls2n6v7ixAQ/hDUctCsHV66px01Nv1EksMZtMpoSEhL1790qqcqFS8fRraVq8W+eX03KSpTwhgJCxanv7iwsYBneSDETG+jprRZml9X5fXKyptron6TAHWgZC2wOl5col47XL2p1f9RWcBAy+ZshUcMZcfQFCQBsN6gPfAQA0+79lHDM9BiBdyhGLutPU0a6K/w6fEHRk4RO4hr6e/YO+w522/m/K8msoK3giIyNJfyaMizg/jthzAgTB7gNXZ83LYcCQSY5LDocPH+bBIyKIosHLszOPnbjDLdwJ9SdTXApyR0Dp+tS7v7FrNYbyi9h8IbJougGDb5mjDYa+op+tWny3I4LIajQYzp2mrf2Uza6cM0ubnwnYO7qs16/0FuUDCLUVxbrMJEqh0B75TltXb6qtpq0WAJjuhDg7YLSZ6eb6Oqdrg+juzp74OH5aSCrJxbm6yG+dfi5RVvCM8mG4IU6TYZg3Fp48kHBVfCjPlSHBM4SL8wPcuqviX0tOA/zKaCSDTam0tDT3nEin+/GVQIPnxVkJeIoPcd+Czx5B2P7dvr5TOWwiMNfWmKou42QEKYNBeyQOQNi9Y3Pv2bOWm7V9F87bjXp9aaG54S5EyK5SGq5WWxtuMEMnQghBfcEp8/0m8fr4uR2PiXrygQcAEBUVJfRqZMqwvLVLYj6xoUk7fnpSmxKvPkmKIMFD+lqeG5cIESwuV4RMT1IoDU5ZpAgRDiSZJAeXfDgTd8lHl5Vu6X7QGf0pwwCewFh3nbGa+UcnoXhmCJi+vCx814Nj55GQmCs1Jgbqz0JlBQ9/AYi4kxuR3N0/1Mz59DTAV79LBw/nPBAifb9lyuupadl3WKZD1rKkxYwyBU3bLE3NVJeKfFsKKEp88c6q6aG6NfwqiDsd/dmIx0o3WcGzfPlyoVcjU5z8IpnFxT0hwKMcGr76r7x9P9ZypsCVxfeEqPCtvE5sMzMzP/zww4ULFyYmJpKmMzAwAADo6OjgDYsruHLzhaj1ZfiOHjY4ceM15CNeE3AFfeczUhzGykb9Vq584KFpevny5aR1jlYcwobGnnEzjlZfU3FLzE1NTbt37542bVpcXNxVN6GmpkaYU1NTs3fv3hkzZsTGxra2tnIKFxa3PfNGitni01XX7GVx+ONC3FtLLsLNagZv2Bqt1vGSr99a8BgqJh94KIpasWKFlz/dcIpBBA8m3nppdpodf1AE2e329PT0OXPm/O53v9u6deuhYYbNmzf//ve/X7BgQV5eHtcFWcz0c29mVFQpfRm0MbSdamm2lJcYs9KNx5P6M44as1ItF4ptzXdpu9UPz62OoY36rWj5wGO321euXOluDDOCQxQIwScrCrbuvAQQQ4rT6XSVlZUA/DKZFhnPcFk0TRcWFhoMeHmAJwaQXrGxdM+BWvLdKynIRV24FTG8ZAasN69pt6xTvjKl9ck/tYX8VTllXOfzEzqmTeh4Zlzb+McU4/6f8oUQ7ZooU0UxQ9nwbgNHEIpwIcjVpJ/X3EcOfmvEY6WYfOCxWq0rV650WMIo/q83UE+/fqziooI9O+2rIH7CwzOCEKYcr5+75LTzki9PMTSCzR8ihrb152V2zXut7enH1WHv9/90wHqtmtGoAGUBgIaQhrSV1qhsN64ZUhLUyxd1TBrXOesF3dGD0Gbh+PnS0Q3VyJunsTJQf5YrH3gsFsvq1avdOb8RdKKFJS1T3ki3WV1+XBHbjbgOkpogBO41a8fPTO7usfFmKOTJCYIIMQyyN9zqmh3aPuEx7dYNNmUL9+EtEU0QQHRPly52T8fUpx68PcN2+waF3+W4Vl6Ej2RdhkXgz3Y8JrrJBx6z2bx69Wre2kYngj/3u+GrSxGfn2f5/zLmGVFxgGbgy+8ezznVLN654c+gUpTu8I+KqeN6osKoew14pybeniCpGKbDmzsfdHSvjGqb+Jgubj9D2z3s60a0soPMxsQ6/VyofOAxmUxr1qwRemgyxWcnCq128MKbGYdTb5BsybikCI5Yigyu3loWubYEIrenU/HOGru9e31Ue8jfDKlHyc88eiZisIekGMqcm6mY9Hh35CeMccjsy0M+UnXB8CCbSBjnCPzclOVXTz7wGI3GtWvXjoZT5HlChG7e6npieurN2xKbQfki3kZgWnbDlFkZRqPN9VQEIlqn6wr/QDl9iqn6Ejtx8rLbAAgD1FJb0zHjma5PPwB6rdNBA2+rMLxy8pum/0uUDzz9/f1r164VejUyxUMX6J4MHj5WP+2tNJvN7ZKa+7JDvK8k2f1m3biXk69cHUQpWQv8dpWiusI/6Hx+gr3pLj6eA4cw54glRfBkeOIEIaPq7Aid1jX3LaZfR4qT5DNSBP5vzTJrKB949Hr9aPc8CKGIdaVrv6rw/roCj90xTTEz52b/cOSGUwm8pxMA7bfbO2ZOtTQ3cF8gcqLx7hEgZG9qUMycrFkejjfdeNmTeSccgz8YnFpAPvD09fWtW7fOy5/Os2JWG5g6K/V8aZv4PN4zZhJUEDE791YtWFbgtGsbQqg7uFf5TIj9bh3++NyImjiEyK5sV4Y+2702GlI2cg+bhLo+ZzvZTfBxYGBAPvBotdp169aR4w1h3JcBBkLwep160qsp/Ua8sUDInEsRySKLSJIhhC5Xqya+kmww8mvieH3MWFLU/tRfDdlpDHQ7dPRFEwih5UqlYvyf9fh43OBWBFJzYdyTughLkSkchyBgnFpAPvB0d3ePas8DIZ1w7NaHuCuQXAj22Q+zDCwWZsob6YUlLYPdC0SUpqtz5pTerRsgGLxedFiSurq6bLZf3h25LMsd9elPOqp4Zpzl9jXZNvI42U3wUdaeR61Wj2bPAyFkItcWx8Zf5WyOdJxkXNINc8SSZFgKRGFrCjd+c5E9rIYYQHeFz1O9O4uyWjj4knKFcVIEhDAuLi4/P/+dd97pY+8V4HP5CMmBAaBneVhn6AuMGR+eI7OE8ZEiCALGqQXk63m6urpGs+eBViv13JvHK6vaXTrs0UkEh5Kuv/Rejt1OAQCNx1NaJz5uvV7jxYwLQnj69GmTyRQWFqZQKDzQFtKd7R3Pj+/bs529+NODEr6RONlN8FHWnkelUq1fv17oF8kUX3xkda1qwswkQz8+9y/CRyRruJoghK5ef/Dky8ca7mkpXXfHCxN1sbuBox+QFEQScAO/3NzctLQ0p4+gkGROccvPpxUT/sveOniCmtSfjDuVIrO4uIcEQcA4tYB8Pc+DBw82btzom/sTKQ13xF6Zv+SsvF9BhEaz/dk30lIy67tXRz+Y8xpjNQ9rea23t/ceGzQaTX5+/sKFC1etWsUfHBKpLZfFAEazLKz7syX4DpBRnv042U3wUdaep7Ozc9OmTUK3R6Z46AKFZBCgWQtz9xy4xu4IGxAS8Cl8hJQrjEuSsVMeiACzfEPp5vdiFE/+2VxezL4OHTypKs4BQpiWljZ//vzp06d/+OGHFy5cUCqVDQ0NjY2N/Fe4Oa1E+CDI2Fqb2iY8bi4/TwPnE7J8QT4irKakCJIgCBinFpCv51EqlVu2bJH0pt4QQNDeYXhyempZBf5+qMwh73TT+fEvalaEM0DiXlJSMZqmo6OjGYYpKiravXs3mTWsOECo99+fPwh9jjZIfKJ4WGyFxE52E3yUtedRKBRffvmlO+dHejgRT+kyCyKQd6Z5wivJOh1e5/VRhOeaIDSAIDJkpNwe9497V1rBUN8vronZbI6Pj4cQbt68uaqqSoRYJAurChGlUrZMGWeIj2Ut3kX/I8GBLeZJowUB49QC8vU8CoVi27ZtQpfmewqEYNP2ikWf/XIRru88PeEAEKA1XR0vTIyZ+ul38deHNdthGCYmJiYrKysjI2NYBYWKAcj0H/5R+dIEm7Zn9PYlOdlN8FHWnuf+/fvbt28X/va+p9A0PWNO1om8ez5a4XA1AQB2b9vcGfrs3pjyWR9k86tk7viMnnqAotTz3+leE+HhVVvuNBRJD6JF2ALy9TxNTU27du3yZHggMsxwmXW7vvepmUldahO34uSjCK64S0EkZ4QQpWxte/pxY+GpykudT8xIam11vdmZvbkAXL16NSMjgzzVIykCQlhUVFRRUUGWInXgVWUgNJecUz71F1tttUsCYSKZIqkJRyC0ngBPkQ88jY2NvsyMRZzivoPV7y3Oh46vJopQjmAWDWhN1CfqT+ZCmjHoLZNeT8/I4W5CHCIEAHDw4MGQkJBf/epXS5cuXTfMsHr16t/85jd///vf9+zZI9GzAUbz8Rx11CcMAF68pR2itKuHAMeJy+rLB547d+7ExMSQDk8Y99AF8mTctWxvzM/59sA1fnezkC2ZwpclE4VxSTJb1cW2kD+bKy+wnxuAUZ+Xrtpcxlkdx43nYLPZcnJyQkNDk5KS9MMM5eXloaGhqamp/ewd1jxPUmE+0dZY3zbxUculi/yLWidNyFJknOdAJpJxjsClAQVyonzgqaur47+B48q1eZMGILjfqn1iemL5JfkWqfE9CQCow+Z3hy9gmMGrD/PONr/4drrVRrk+WMpWTq1WD2vaAyHUaKQvwuUbjmGAdsNnXbNfZRwX7vBZvkcCGSTu6i4feG7duhUbG0v6M2HcQxfIkwEEj2XWTw1NNZrtHDc+S8jcQwJJMgCRubaqfcLj9tZGCMEACxed3jLxlZTKyx38vfJOmrCfTBxElqQInoAEG5co/MsLwqd9mhvbJvzVnHucO0bE8xGWIlN4DmQiGecI3NlQwKbLB57a2trvv8efHxvRACPXF63cXDJ6S7RCbQEDNJEfazevJS0bQrBoZeGm7RWjvEtGqI5zSt/XX3S8PZO2mkf2aEbAIkSk4vKBp6amJi4ujvRnwriHLpAn6zdSk19LKSpTIMf17XyWkDmXIkkgQsbaKbRcKlWG/I1S3Of6kUF6CBJS6579Z5rFOnhNqaQgSQIRTbgsVwSQ0fd0TJuoTzpEfuCapBfGJTXhCETMKDCz5APPlStXfvzxR2c/6dtz/s9tz7153Gyx8asFvvGTKI0/Wmgxqd6e2fPFKuEnou41942bcaTyMr5dfqwCd1SuL/67zmefoNWdI6hGYMJDvNbygefixYvx8fFCt0emeOgCMRmGC1yy6ueVW1yvcZFsybikCI7YJRkAUJ+e1DbxMbrtPv8tA54eAPTPj/K276vih3OkXGHcpQgvyJz4IARBv0H5ckjPrm0M/pwcDkK2ZIqHBOKWFIC58oGnvLw8ISFhBH3hA7VxwsxjpwvujSBPcVbAoOt45Vnd3p3k/etkkSOpt179VzZFe/RFLbLgyMYhQpYzecqp/7C2No8U5wDEhmSV5QNPSUnJkSNHRuq3RAgeTat75s1Ug0Hi0P+ISMQ3p9F07+erVO++Qtst7q7E0Wotk15POV86+CWfERHtHRPA0N3LwlXzZjFY2xG41EHSkgKQQD7wFBUVHT16lBwtCOMejh+wPUEwP+LMlp2XERzyHRHPOQilkylOfCBC5qoKfGinuABBvJfZiYAti++hXraxJGxlETeoIxkK4644uBhfSZIJCdg3UYyt6U57yGOGE8nAsZoi1IFLEXJwSuEeAxAe4lWWDzwFBQXJycne+VFhqcZ7uvEzkxsae/EH1kc/AMqmmvd2b9Rimhb5IBwGz5nC+yEzkxVK4+grJSEBQqTbv7tjxhRGr5Mg9SBb3IwCM1c+8Jw9ezYlJcWd8/PcBbIrBWDT9sr5S8+SrwI95yCugxMfhBCAUH/oe+WzT9K9XeJr4gghk4l+7p8ZBxNvoNG5t02ovFMvwRNABIHd+uCdUO3eHQjir2TxWU5FnB6FZMGex6V3kA88eXl5aWlpHvg4aRK1xjRp8JPUg+/spcv4QGG9Uauc+F+G1KOe8YAxcTWvL8ijqGEcLPWMszdUlvLStsn/bblR41h484ZJEDxjDJ6cnJz09HShVyNTPHGBCKGfjt2c/Hpqn87KGcJwOZD07uKcJvi2XMqumvvPB5/OZ+jBt0lcERFVNd3mia+mXKxWumMuyYEsKCJIkg/Xbfasiuh49Tla3yfsqCU5kAQuDSiQE+XreU6cOJGRkeGl3yOK2e3Ma/Nz9x68OiKLSARjF1HAMLp/b+ycOYVSd7HXTnvU0UFIb9hWvmJzqQuOsifRENGqzvYZk7UbV9GA9qgCrpQMZJC4q7t84MnIyMjMzCR9qjAu6WUhZNKzG555I01vwBN3Lzi4LCXkg+9oB9CQldry1KPGkkLuvSdJJs7ndgM+n3evWcPPkciyXFycA5/LR4QcPOSDELLWVismPWZKS2bYDapOPJ0ehYI4Anc2FLDp8oEnPT09KyvLlVMbRlqv1vr828f3xtXwL/iHUXgYpPjzBuaayvZnntD9+AMY/sXTEMJFKws+XXmOpkfgHcswFHdDivdGJB1un/A3S/E52t1bKjdlueSARYhIxeUDT1paWk5OjtCrkSkiLhDvxoFg/8Grk99I1vRYuM1sZFkuLsLBQwK8SAWh7fbNtmf+p/cLPNRxydNlIqEPuHwVn80uLm33eqbhocJSmmDjx9/bAkD71fr2qU/Ybt/gv3wyLBEiZhSYWfKBJyUlJS8vT9S7iWVCBBTt+smvp2TnNbGDKK9H72JS2Lev0N7cqJwxtTtyETCbvP6GFIRg/ZcX3vowt7+fGu3rPCWqNJgNIW3XfL6sfdp4W/UldvFtGG0YmPAQr7V84ElOTs7Pz/fsZ3ZBZbHQH0T+vHprGcB3FYxKwH0OYEwl5zpenKj96nOGEnkf6pECRpPt7Y/yItaX2O1+sWyNF98ou273l61T/9GfcoSmaOTxzh1xMwrMXPnAk5SUdObMGWJg4+l0H9/rx4BN2y4891aGtndwp5Y7Ph6OYZzIEP7oJwIM1fdDTNtTj2q/3gAcez99EQQRqL2hCXnl2IGEWob9ahDJzUkHMouMS5INlwAiYEz8qT3kL90bVzEWE/4+iqulF6EOgYkQkVrLB57ExMSCggKPPPZQIoZmtu+9PPHVlPJL7cixWDSUxNcnCKH18oWu+W91vBDSn5NBM9SIHBBilQV5Z+9NCk05dPQGw/jF4gHufwAwVpR1vP5C56znTWdyECPdmYvYUMBmyQeen376qaioiPRnwjjvRCHC9ydByHR1m8NWnJv0WlrZ5Xbuxanf8WEAAAY2SURBVI6wFJnCcyATyTi78IAAAgBCGp9us1uvXNAsmtc6/i+aiA+pjsH5vTQfz7w1d79PWm59yMyUz78q7zdRWCz+ODyeb3CKsRgbnH6QqnJxnkyY5SMBpddpN69RjP9b18dzrOUXKMrKANwskPuU6tAJUcAiRKTi8oEnPj7+/PnznvQRDAPutxjKL3bu+qHm+Tcz3vwk59p1FfuL+uy5IQQdHVRjveVShSE1qXfzGlXoc21P/z37lZfO/XAAAIym0ZjcQwjLKtpD52e9PPvEvvjaKzWqdrxzdNA8b968mZ2dzR+h86SJRoQGOycIbfW3etdEtk16vGPm1J4vVvWnHbZerqDu1tNKBfkaWsSGAjZLPvAcPHiwtNSjl+4qtfG/X4p/akbKrPk5qSfq7RR+s+e5ufD+WFiEsdvan5vQ9j+PKp78c9u0EHXYAkNaol2tOpaSkpub60QvwseJ0t2jEweD0X4g8caM97LGvZT8wjsZvGlWVFQkJCSMVB3dKSOSDgECvd39x1M1SxYonx/f9uRf2p74c+sTf7lZWYo/rso2fsAiRKTi8oEnKytrwYIF0dHRkY6wbNmyKEcg4xFLl700/eO3Z38YFb0sellUVGRUZGRkVFQUWTYyMjKCDZGRkUuXLl3CBi4SzoYlS5aEh4eHsYFLwX/DwsOff27pqzMi5rwXGb4kOjo6etmy5cuiQ0ND33rrrRUrVqxkw+rVq9c4AnnF5wYibNq06Qs2bNq0aevWrVu2bOH+fkmEbdu2fc2Gbdu2fYPDtm+2ff3ll9siotfPX7hmx/btO9gQERExZ86cnTt37tq1a7cjfPvtt3vYEBMTs5cNMTEx+/fv/84RDhw4EBcXd/Dgwbi4uEOHDsU7QkJCwhFHSHKE5OTkVDakseH48eOZmZnH2ZCVlZWVfeJENv6bm5ubm3k8+2Bc5p5dCStW/Pr//p+QkJCvv/66tbVVxIYCNks+8JAjexEv6JTFlXL5FwgCwwbaERiGcUSH/E9RlN1u5/7abDaLxfLTTz+dOHHC7Agmk6nfEQwGA3/LZ19fn9YRent7u9mg0WjUanWXI6hUqs7Ozg42KJVKhSO0tra2OEJzczP3Qbh79+41NDQkJiZu3769vr6+rq7u5s2bt9hQW1t71RFqamqqHaGqquqyI1y6dKmysvLixYuVlZUXiFBSUlJcXMz9LXSEc+fOnSXCKUc4efJkjiNkZ2dnOsK+ffseeeSR3/72txEREXfu3AlYhIhUXD7wOKHCrx4TExNPnjw5VioVFxcnJSUNa9gmg6oajSY7O5u85lfEjAIzSz7wcBMA8b+jt7LEc+YjvCYQwoKCgsuXL/ODe840eQJhkZElqKmpKSoa/LiQUKhL6STZKBFw64Q8SgMTHuK1lg88/M8QjDyMLSBuRoGZGwQPtmSNRqPVah9Gm5ZN58CEh3it5QMPOdJwFx+lEQgpTigCLzdlZcXGxtbW1vK5fIQsS8ZHhABCyC1lcGMk7hWlE2enR1IHLi4bgbglBWCufOCRzUcOV1BUVBRN03fv3l28ePFwy/pOHxERcerUKQjhrVu3FixY4DvDUeIQgNiQrLJ84BG6TGGKbE6UF4QQmj9/PkKopaVl7ty5pOUJ1SNTeA5kIhn3hABCOG7cOJVKBSHctWvXhg0bOAWGy4ekF8Y90URYikzhOEgaU6ARyAce0i79Kv7RRx9BCJuamt5//32ZFVMoFOPHj+feYr344ounTp2SWQHPxQUaMDypr3zgIT2Zu/hI+UgRPk5ZCKGvvvpKrVaXlJTExsaSxuROSS7diY+Q2BOCxMREbqyo1+v/8z//s6Ghoby83Kmg06N3goSlyBQPRXhiTwFFIx94SLv0q3hPT09GRkZWVpbd7uvpt+HWa968eQsXLjSZTDt27PjTn/6UlJRUX18/XCby0AcUKjysrHzgIV2du7iHLlCETCSLE+qSgNw6JEJGqu2Sz7AIKIr6wx/+sIsNDQ0Nx48fT09PJ1/UyqaJh3Xx0KQCh0w+8MjjIB8iKXV1dX/84x9p2l9OaIs3XeBAwvOaBsEjbjOjmFtQULBp06ZRFDCirD03qcChlA88gdOmwZoGSAsEwRMgP3SwmiPfAv8faH4QC9pe2XgAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "41004f96",
   "metadata": {},
   "source": [
    "## Reparameterization Trick\n",
    "\n",
    "So far, we played around with the log-likelihood, and we ended up with the ELBO. However, there is still a problem with calculating the expected value, because it contains an integral! Therefore, the question is how we can calculate it and why it is better than the MC approximation of the log-likelihood without the variational posterior. In fact, we will use the MC approximation, but now, instead of sampling from the prior $ p(z) $, we will sample from the variational posterior $ q_\\phi(z|x) $.\n",
    "\n",
    "Is it better? Yes, because the variational posterior typically assigns more probability mass to a smaller region than the prior. If you examine the variance of the variational posterior, you will probably notice that the variational posteriors are almost deterministic (whether it is good or bad is an open question). As a result, we should get a better approximation!\n",
    "\n",
    "However, there is still an issue with the variance of the approximation. If we sample $ z $ from $ q_\\phi(z|x) $, plug them into the ELBO, and calculate gradients with respect to the parameters of a neural network $ \\phi $, the variance of the gradient may still be pretty large! A possible solution to that, first noticed by statisticians (e.g., see [8]), is the approach of reparameterizing the distribution.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.3 An example of reparameterizing a Gaussian distribution: We scale .ϵ distributed according to the standard Gaussian by .σ, and shift it by .μ.\n",
    "\n",
    "### Reparameterization Trick\n",
    "\n",
    "The idea is to express a random variable as a composition of primitive transformations (e.g., arithmetic operations, logarithm, etc.) of an independent random variable with a simple distribution. For example, if we consider a Gaussian random variable $ z $ with a mean $ \\mu $ and variance $ \\sigma^2 $, and an independent random variable $ \\epsilon \\sim N(\\epsilon | 0, 1) $, then the following holds:\n",
    "\n",
    "$$\n",
    "z = \\mu + \\sigma \\cdot \\epsilon\n",
    "$$\n",
    "\n",
    "Now, if we sample $ \\epsilon $ from the standard Gaussian, and apply the above transformation, then we get a sample from $ N(z | \\mu, \\sigma) $. This idea can be generalized to other distributions as well.\n",
    "\n",
    "The reparameterization trick can be used in the encoder $ q_\\phi(z|x) $. By using this trick, we can drastically reduce the variance of the gradient because the randomness comes from the independent source $ p(\\epsilon) $, and we calculate the gradient with respect to a deterministic function (i.e., a neural network), not random variables.\n",
    "\n",
    "### Application in VAEs\n",
    "\n",
    "In the VAE framework, we will apply the reparameterization trick to the latent variable $ z $. The encoder $ q_\\phi(z|x) $ outputs two values: the mean $ \\mu_\\phi(x) $ and log-variance $ \\log \\sigma^2_\\phi(x) $ for each input $ x $. Instead of sampling directly from $ q_\\phi(z|x) $, we sample an independent Gaussian $ \\epsilon \\sim N(\\epsilon | 0, 1) $ and apply the following transformation:\n",
    "\n",
    "$$\n",
    "z_\\phi = \\mu_\\phi(x) + \\sigma_\\phi(x) \\cdot \\epsilon\n",
    "$$\n",
    "\n",
    "Here, $ \\mu_\\phi(x) $ and $ \\sigma_\\phi(x) $ are outputs of the encoder neural network. This ensures that we can backpropagate through the reparameterization, reducing the variance of the gradient estimates.\n",
    "\n",
    "### Training the VAE\n",
    "\n",
    "The training objective for the VAE is to minimize the **negative ELBO**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\phi, \\theta; x) = - \\mathbb{E}_{q_\\phi(z|x)} \\left[\\ln p_\\theta(x|z)\\right] + \\text{KL}\\left(q_\\phi(z|x) || p(z)\\right)\n",
    "$$\n",
    "\n",
    "In practice, we approximate the expectation $ \\mathbb{E}_{q_\\phi(z|x)} $ by taking a single sample from the variational posterior:\n",
    "\n",
    "$$\n",
    "z_\\phi = \\mu_\\phi(x) + \\sigma_\\phi(x) \\cdot \\epsilon\n",
    "$$\n",
    "\n",
    "where $ \\epsilon \\sim N(0, I) $. This allows the model to be trained using stochastic gradient descent, where we only need a single sample of $ z $ during each training iteration.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- The reparameterization trick is used to express a random variable $ z $ as a deterministic transformation of an independent random variable $ \\epsilon $, making the gradient computation more stable.\n",
    "- For VAEs, we apply the reparameterization trick to sample $ z $ from the variational posterior $ q_\\phi(z|x) $.\n",
    "- The training objective is the negative ELBO, and the reparameterization trick allows us to sample $ z $ efficiently and compute gradients for optimization. \n",
    "\n",
    "##  VAE Code Implementation\n",
    "\n",
    "### Encoder Class\n",
    "\n",
    "The encoder class takes in an input $ x $, passes it through the encoder network, and generates the mean $ \\mu_\\phi(x) $ and log-variance $ \\log \\sigma_\\phi^2(x) $ of the variational posterior $ q_\\phi(z|x) $. We then use the **reparameterization trick** to sample from this posterior.\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_net):\n",
    "        super(Encoder, self).__init__()\n",
    "        # The init of the encoder network.\n",
    "        self.encoder = encoder_net\n",
    "\n",
    "    # Reparameterization trick for Gaussians.\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        # The formula is the following:\n",
    "        # z = mu + std * epsilon\n",
    "        # epsilon ~ Normal(0, 1)\n",
    "        \n",
    "        # Get the standard deviation from the log-variance.\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        \n",
    "        # Sample epsilon from Normal(0, 1).\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        # Final output\n",
    "        return mu + std * eps\n",
    "\n",
    "    # Output of the encoder network (mean and log-variance).\n",
    "    def encode(self, x):\n",
    "        # Calculate the output of the encoder network of size 2M.\n",
    "        h_e = self.encoder(x)\n",
    "        \n",
    "        # Split the output into the mean and log-variance.\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
    "        \n",
    "        return mu_e, log_var_e\n",
    "\n",
    "    # Sampling procedure using reparameterization.\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        if mu_e is None and log_var_e is None:\n",
    "            # Calculate mean and log-variance from the encoder.\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "        \n",
    "        # Apply the reparameterization trick.\n",
    "        return self.reparameterization(mu_e, log_var_e)\n",
    "\n",
    "    # Log-probability of the sample used for ELBO calculation.\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        if x is not None:\n",
    "            # Calculate corresponding sample if only x is provided.\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        \n",
    "        # Return the log-normal distribution.\n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "\n",
    "    # Forward pass: either log-probability or sampling.\n",
    "    def forward(self, x, type='log_prob'):\n",
    "        assert type in ['encode', 'log_prob'], 'Type could be either encode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)\n",
    "## 5.3.5 VAE Code Implementation\n",
    "\n",
    "### Encoder Class\n",
    "\n",
    "The encoder class takes in an input $ x $, passes it through the encoder network, and generates the mean $ \\mu_\\phi(x) $ and log-variance $ \\log \\sigma_\\phi^2(x) $ of the variational posterior $ q_\\phi(z|x) $. We then use the **reparameterization trick** to sample from this posterior.\n",
    "\n",
    "```python\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_net):\n",
    "        super(Encoder, self).__init__()\n",
    "        # The init of the encoder network.\n",
    "        self.encoder = encoder_net\n",
    "\n",
    "    # Reparameterization trick for Gaussians.\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        # The formula is the following:\n",
    "        # z = mu + std * epsilon\n",
    "        # epsilon ~ Normal(0, 1)\n",
    "        \n",
    "        # Get the standard deviation from the log-variance.\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        \n",
    "        # Sample epsilon from Normal(0, 1).\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        # Final output\n",
    "        return mu + std * eps\n",
    "\n",
    "    # Output of the encoder network (mean and log-variance).\n",
    "    def encode(self, x):\n",
    "        # Calculate the output of the encoder network of size 2M.\n",
    "        h_e = self.encoder(x)\n",
    "        \n",
    "        # Split the output into the mean and log-variance.\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
    "        \n",
    "        return mu_e, log_var_e\n",
    "\n",
    "    # Sampling procedure using reparameterization.\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        if mu_e is None and log_var_e is None:\n",
    "            # Calculate mean and log-variance from the encoder.\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "        \n",
    "        # Apply the reparameterization trick.\n",
    "        return self.reparameterization(mu_e, log_var_e)\n",
    "\n",
    "    # Log-probability of the sample used for ELBO calculation.\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        if x is not None:\n",
    "            # Calculate corresponding sample if only x is provided.\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        \n",
    "        # Return the log-normal distribution.\n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "\n",
    "    # Forward pass: either log-probability or sampling.\n",
    "    def forward(self, x, type='log_prob'):\n",
    "        assert type in ['encode', 'log_prob'], 'Type could be either encode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_net, distribution='categorical', num_vals=None):\n",
    "        super(Decoder, self).__init__()\n",
    "        # The decoder network.\n",
    "        self.decoder = decoder_net\n",
    "        \n",
    "        # The distribution used for the decoder.\n",
    "        self.distribution = distribution\n",
    "        \n",
    "        # The number of possible values (used for categorical distribution).\n",
    "        self.num_vals = num_vals\n",
    "\n",
    "    # This function calculates parameters of the likelihood function p(x|z).\n",
    "    def decode(self, z):\n",
    "        # Apply the decoder network.\n",
    "        h_d = self.decoder(z)\n",
    "        \n",
    "        if self.distribution == 'categorical':\n",
    "            # Reshape to (Batch size, Dimensionality, Number of Values).\n",
    "            b = h_d.shape[0]\n",
    "            d = h_d.shape[1] // self.num_vals\n",
    "            h_d = h_d.view(b, d, self.num_vals)\n",
    "            \n",
    "            # Apply softmax to get probabilities.\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "            return [mu_d]\n",
    "        \n",
    "        elif self.distribution == 'bernoulli':\n",
    "            # Apply sigmoid for Bernoulli distribution.\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            return [mu_d]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Only: \"categorical\", \"bernoulli\"')\n",
    "\n",
    "    # Sampling from the decoder.\n",
    "    def sample(self, z):\n",
    "        outs = self.decode(z)\n",
    "        \n",
    "        if self.distribution == 'categorical':\n",
    "            # Use the output of the decoder.\n",
    "            mu_d = outs[0]\n",
    "            return mu_d\n",
    "\n",
    "### Summary:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed69b9",
   "metadata": {},
   "source": [
    "- **Encoder**: Takes $ x $, computes the mean and log-variance, and applies the reparameterization trick to sample $ z $.\n",
    "- **Decoder**: Takes $ z $ and produces the parameters of the likelihood function, using a categorical or Bernoulli distribution.\n",
    "- **VAE Loss**: The ELBO is computed and used to train the model, where we sample from the variational posterior $ q_\\phi(z|x) $ using the reparameterization trick and maximize the likelihood of the observed data while regularizing the latent space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca35c1",
   "metadata": {},
   "source": [
    "##  VAE Implementation\n",
    "\n",
    "### Prior Class\n",
    "\n",
    "In the current implementation, the prior is a simple standard Gaussian distribution. Although we could use a built-in PyTorch distribution, we chose not to for two reasons:\n",
    "1. It is important to think of the prior as a crucial component in VAEs.\n",
    "2. We can implement a learnable prior (e.g., a flow-based prior, VampPrior, a mixture of distributions).\n",
    "\n",
    "```python\n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(Prior, self).__init__()\n",
    "        self.L = L\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # Sample from a standard Gaussian distribution.\n",
    "        z = torch.randn((batch_size, self.L))\n",
    "        return z\n",
    "\n",
    "    def log_prob(self, z):\n",
    "        # Log-probability of z from a standard normal distribution.\n",
    "        return log_standard_normal(z)\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net, num_vals=256, L=16, likelihood_type='categorical'):\n",
    "        super(VAE, self).__init__()\n",
    "        print('VAE by JT.')\n",
    "\n",
    "        self.encoder = Encoder(encoder_net=encoder_net)\n",
    "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net, num_vals=num_vals)\n",
    "        self.prior = Prior(L=L)\n",
    "\n",
    "        self.num_vals = num_vals\n",
    "        self.likelihood_type = likelihood_type\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        # Encoder\n",
    "        mu_e, log_var_e = self.encoder.encode(x)\n",
    "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "\n",
    "        # ELBO Calculation\n",
    "        RE = self.decoder.log_prob(x, z)\n",
    "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            return -(RE + KL).sum()\n",
    "        else:\n",
    "            return -(RE + KL).mean()\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)\n",
    "# Example of Encoder Network\n",
    "encoder = nn.Sequential(\n",
    "    nn.Linear(D, M), nn.LeakyReLU(),\n",
    "    nn.Linear(M, M), nn.LeakyReLU(),\n",
    "    nn.Linear(M, 2 * L)  # Output mean and log-variance\n",
    ")\n",
    "\n",
    "# Example of Decoder Network\n",
    "decoder = nn.Sequential(\n",
    "    nn.Linear(L, M), nn.LeakyReLU(),\n",
    "    nn.Linear(M, M), nn.LeakyReLU(),\n",
    "    nn.Linear(M, num_vals * D)  # Output the probability distribution\n",
    ")class VAE(nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net, num_vals=256, L=16, likelihood_type='categorical'):\n",
    "        super(VAE, self).__init__()\n",
    "        print('VAE by JT.')\n",
    "\n",
    "        # Encoder, Decoder, and Prior initialization\n",
    "        self.encoder = Encoder(encoder_net=encoder_net)\n",
    "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net, num_vals=num_vals)\n",
    "        self.prior = Prior(L=L)\n",
    "\n",
    "        self.num_vals = num_vals\n",
    "        self.likelihood_type = likelihood_type\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        # 1. Encoder: Calculate the mean (mu_e) and log variance (log_var_e) from the encoder\n",
    "        mu_e, log_var_e = self.encoder.encode(x)\n",
    "        \n",
    "        # 2. Sample the latent variable z using the reparameterization trick\n",
    "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "\n",
    "        # 3. ELBO Calculation\n",
    "        #   - RE (Reconstruction Error) is the negative log-likelihood of the data under the decoder\n",
    "        RE = self.decoder.log_prob(x, z)\n",
    "        \n",
    "        #   - KL Divergence between the posterior and the prior\n",
    "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
    "\n",
    "        # 4. Total Loss (Negative ELBO)\n",
    "        if reduction == 'sum':\n",
    "            total_loss = -(RE + KL).sum()\n",
    "        else:\n",
    "            total_loss = -(RE + KL).mean()\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        # Sampling from the prior and passing through the decoder\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8630772b",
   "metadata": {},
   "source": [
    "##  Typical Issues with VAEs\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.4 An example of outcomes after the training: (a) Randomly selected real images. (b) Unconditional generations from the VAE. (c) The validation curve during training.\n",
    "\n",
    "\n",
    "VAEs constitute a very powerful class of models, mainly due to their flexibility. Unlike flow-based models, they do not require the invertibility of neural networks; thus, we can use any arbitrary architecture for encoders and decoders. In contrast to ARMs, they learn a low-dimensional data representation, and we can control the bottleneck (i.e., the dimensionality of the latent space). However, they also suffer from several issues. Except for the ones mentioned before (i.e., a necessity of an efficient integral estimation, a gap between the ELBO and the log-likelihood function for too simplistic variational posteriors), the potential problems are the following:\n",
    "\n",
    "- **Posterior Collapse**: \n",
    "  Let us take a look at the ELBO and the regularization term. For a non-trainable prior like the standard Gaussian, the regularization term will be minimized if: \n",
    "  $$ \\forall x, q_\\phi(z|x) = p(z) $$ \n",
    "  This may happen if the decoder is so powerful that it treats $z$ as noise, e.g., when a decoder is expressed by an AR model [10]. This issue is known as **posterior collapse** [11].\n",
    "\n",
    "- **Hole Problem**:\n",
    "  Another issue is associated with a mismatch between the aggregated posterior, \n",
    "  $$ 1/N \\sum_{n=1}^{N} q_\\phi(z|x_n), $$ \n",
    "  and the prior $p(z)$. Imagine that we have the standard Gaussian prior and the aggregated posterior (i.e., an average of variational posteriors over all training data). As a result, there are regions where the prior assigns a high probability, but the aggregated posterior assigns a low probability, or vice versa. Then, sampling from these \"holes\" provides unrealistic latent values, and the decoder produces images of very low quality. This problem is referred to as the **hole problem** [12].\n",
    "\n",
    "- **Out-of-Distribution Problem**:\n",
    "  The last problem we want to discuss is more general and affects all deep generative models. As it was noticed in [13], deep generative models (including VAEs) fail to properly detect out-of-distribution examples. Out-of-distribution datapoints are examples that follow a totally different distribution than the one a model was trained on. For instance, let us assume that our model is trained on MNIST, and then FashionMNIST examples are out-of-distribution. Intuition tells us that a properly trained deep generative model should assign a high probability to in-distribution examples and a low probability to out-of-distribution points. Unfortunately, as shown in [13], this is not the case. The **out-of-distribution problem** remains one of the main unsolved problems in deep generative modeling [14].\n",
    "\n",
    "##  There Is More!\n",
    "\n",
    "There are a plethora of papers that extend VAEs and apply them to many problems. Below, we will list out selected papers and only touch upon the vast literature on the topic!\n",
    "\n",
    "### Estimation of the Log-Likelihood Using Importance Weighting\n",
    "As we indicated multiple times, the ELBO is the lower bound to the log-likelihood, and it rather should not be used as a good estimate of the log-likelihood. In [7, 15], an importance weighting procedure is advocated to better approximate the log-likelihood, namely:\n",
    "$$ \\ln p(x) \\approx \\frac{1}{K} \\sum_{k=1}^{K} \\ln \\frac{p(x, z_k)}{q_\\phi(z_k|x)} $$ \n",
    "where $z_k \\sim q_\\phi(z_k|x)$. Notice that the logarithm is outside the expected value. As shown in [15], using importance weighting with sufficiently large $K$ gives a good estimate of the log-likelihood. In practice, $K$ is taken to be 512 or more if the computational budget allows.\n",
    "\n",
    "### Enhancing VAEs\n",
    "\n",
    "- **Better Encoders**: After introducing the idea of VAEs, many papers focused on proposing a flexible family of variational posteriors. The most prominent direction is based on utilizing conditional flow-based models [16–21].\n",
    "\n",
    "- **Better Decoders**: VAEs allow using any neural network to parameterize the decoder. Therefore, we can use fully connected networks, fully convolutional networks, ResNets, or ARMs. For instance, in [22], a PixelCNN-based decoder was used in a VAE.\n",
    "\n",
    "- **Better Priors**: If there is a big mismatch between the aggregated posterior and the prior, it can be a serious issue. To alleviate this, many papers use multimodal priors, such as the **VampPrior** [23], a flow-based prior [24, 25], an ARM-based prior [26], or using resampling ideas [27].\n",
    "\n",
    "### Extending VAEs\n",
    "\n",
    "- **Semi-Supervised VAEs**: In [28], a semi-supervised VAE was proposed, which was further extended to the concept of **fair representations** [29, 30].\n",
    "\n",
    "- **VAEs for Non-Image Data**: Although VAEs have mostly been used for image data, they can also be applied to other domains, such as sequential data (e.g., text) [11] or molecular graph generation [32].\n",
    "\n",
    "- **Hierarchical VAEs**: Recently, many VAEs with a deep, hierarchical structure of latent variables have been proposed, achieving remarkable results. Notable models include **BIVA** [45], **NVAE** [46], and very deep VAEs [47].\n",
    "\n",
    "- **Adversarial Auto-Encoders**: An interesting perspective on VAEs is presented in [48], where the prior is trained with an adversarial loss, allowing the model to benefit from adversarial learning.\n",
    "\n",
    "- **Adversarial Attacks**: VAEs are known to be susceptible to adversarial attacks. A possible remedy for this is to apply **MCMC** techniques at the inference time [50].\n",
    "## Improving Variational Auto-encoders\n",
    "\n",
    "###  Priors\n",
    "\n",
    "####  Insights from Rewriting the ELBO\n",
    "\n",
    "One of the crucial components of VAEs is the marginal distribution over $ z $'s. Now, we will take a closer look at this distribution, also called the prior. Before we start thinking about improving it, we inspect the ELBO one more time. We can write the ELBO as follows:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x \\sim p_{\\text{data}}(x)}[\\ln p(x)] \\geq \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)} \\left[ \\ln p_\\theta(x|z) + \\ln p_\\lambda(z) - \\ln q_\\phi(z|x) \\right]\n",
    "$$\n",
    "\n",
    "where we explicitly highlight the summation over training data, namely, the expected value with respect to $ x $'s from the empirical distribution $ p_{\\text{data}}(x) = \\frac{1}{N} \\sum_{n=1}^{N} \\delta(x - x_n) $, and $ \\delta(\\cdot) $ is the Dirac delta. The ELBO consists of two parts:\n",
    "\n",
    "- The **reconstruction error** $ \\Delta_{\\text{RE}} $:\n",
    "$$\n",
    "\\text{RE} = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)}[\\ln p_\\theta(x|z)]\n",
    "$$\n",
    "\n",
    "- The **regularization term** between the encoder and the prior $ \\Delta_{\\Omega} $:\n",
    "$$\n",
    "\\Omega = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)}[\\ln p_\\lambda(z) - \\ln q_\\phi(z|x)]\n",
    "$$\n",
    "\n",
    "Further, let us play a little bit with the regularization term $ \\Omega $:\n",
    "\n",
    "$$\n",
    "\\Omega = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)}[\\ln p_\\lambda(z) - \\ln q_\\phi(z|x)]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int \\int \\ln p_\\lambda(z) - \\ln q_\\phi(z|x) \\, dz \\, dx\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{n=1}^{N} \\int \\delta(x - x_n) q_\\phi(z|x) \\ln p_\\lambda(z) - \\ln q_\\phi(z|x) \\, dz \\, dx\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{N} \\sum_{n=1}^{N} \\int q_\\phi(z|x_n) \\left[\\ln p_\\lambda(z) - \\ln q_\\phi(z|x_n)\\right] \\, dz\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{N} \\sum_{n=1}^{N} \\left[ \\int q_\\phi(z|x_n) \\ln p_\\lambda(z) \\, dz - \\int q_\\phi(z|x_n) \\ln q_\\phi(z|x_n) \\, dz \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "= -\\frac{1}{N} \\sum_{n=1}^{N} \\left[ \\text{CE}(q_\\phi(z) || p_\\lambda(z)) + H(q_\\phi(z|x)) \\right]\n",
    "$$\n",
    "\n",
    "where we use the property of the Dirac delta: \n",
    "$$\n",
    "\\delta(a - a') f(a) da = f(a')\n",
    "$$\n",
    "and we use the notion of the **aggregated posterior** $ q(z) $ defined as:\n",
    "$$\n",
    "q(z) = \\frac{1}{N} \\sum_{n=1}^{N} q_\\phi(z|x_n)\n",
    "$$\n",
    "\n",
    "An example of the aggregated posterior is schematically depicted in Fig.5. Eventually, we obtain two terms:\n",
    "\n",
    "1. The first term, $ \\text{CE}(q_\\phi(z) || p_\\lambda(z)) $, is the **cross-entropy** between the aggregated posterior and the prior.\n",
    "2. The second term, $ H(q_\\phi(z|x)) $, is the **conditional entropy** of $ q_\\phi(z|x) $ with the empirical distribution $ p_{\\text{data}}(x) $.\n",
    "\n",
    "I highly recommend doing this derivation step by step, as it helps a lot in understanding what is going on here. Interestingly, there is another possibility to rewrite $ \\Omega $ using three terms, with the **total correlation** [51]. We will not use it here, so it is left as a \"homework.\" Anyway, one may ask, why is it useful to rewrite the ELBO? The answer is rather straightforward: We can analyze it from a different perspective! In this section, we will focus on the prior, an important component in the generative part that is very often neglected. Many Bayesianists argue that a prior should not be learned, but VAEs are not Bayesian models, so who says we cannot learn the prior? As we will see shortly, a non-learnable prior could be quite problematic, especially for the generation process.\n",
    "##  Improving Variational Auto-encoders\n",
    "\n",
    "###  Priors\n",
    "\n",
    "####  Insights from Rewriting the ELBO\n",
    "\n",
    "One of the crucial components of VAEs is the marginal distribution over $ z $'s. Now, we will take a closer look at this distribution, also called the prior. Before we start thinking about improving it, we inspect the ELBO one more time. We can write the ELBO as follows:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x \\sim p_{\\text{data}}(x)}[\\ln p(x)] \\geq \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)} \\left[ \\ln p_\\theta(x|z) + \\ln p_\\lambda(z) - \\ln q_\\phi(z|x) \\right]\n",
    "$$\n",
    "\n",
    "where we explicitly highlight the summation over training data, namely, the expected value with respect to $ x $'s from the empirical distribution $ p_{\\text{data}}(x) = \\frac{1}{N} \\sum_{n=1}^{N} \\delta(x - x_n) $, and $ \\delta(\\cdot) $ is the Dirac delta. The ELBO consists of two parts:\n",
    "\n",
    "- The **reconstruction error** $ \\Delta_{\\text{RE}} $:\n",
    "$$\n",
    "\\text{RE} = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)}[\\ln p_\\theta(x|z)]\n",
    "$$\n",
    "\n",
    "- The **regularization term** between the encoder and the prior $ \\Delta_{\\Omega} $:\n",
    "$$\n",
    "\\Omega = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)}[\\ln p_\\lambda(z) - \\ln q_\\phi(z|x)]\n",
    "$$\n",
    "\n",
    "Further, let us play a little bit with the regularization term $ \\Omega $:\n",
    "\n",
    "$$\n",
    "\\Omega = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)} \\mathbb{E}_{q_\\phi(z|x)}[\\ln p_\\lambda(z) - \\ln q_\\phi(z|x)]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int \\int \\ln p_\\lambda(z) - \\ln q_\\phi(z|x) \\, dz \\, dx\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{n=1}^{N} \\int \\delta(x - x_n) q_\\phi(z|x) \\ln p_\\lambda(z) - \\ln q_\\phi(z|x) \\, dz \\, dx\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{N} \\sum_{n=1}^{N} \\int q_\\phi(z|x_n) \\left[\\ln p_\\lambda(z) - \\ln q_\\phi(z|x_n)\\right] \\, dz\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{N} \\sum_{n=1}^{N} \\left[ \\int q_\\phi(z|x_n) \\ln p_\\lambda(z) \\, dz - \\int q_\\phi(z|x_n) \\ln q_\\phi(z|x_n) \\, dz \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "= -\\frac{1}{N} \\sum_{n=1}^{N} \\left[ \\text{CE}(q_\\phi(z) || p_\\lambda(z)) + H(q_\\phi(z|x)) \\right]\n",
    "$$\n",
    "\n",
    "where we use the property of the Dirac delta: \n",
    "$$\n",
    "\\delta(a - a') f(a) da = f(a')\n",
    "$$\n",
    "and we use the notion of the **aggregated posterior** $ q(z) $ defined as:\n",
    "$$\n",
    "q(z) = \\frac{1}{N} \\sum_{n=1}^{N} q_\\phi(z|x_n)\n",
    "$$\n",
    "\n",
    "An example of the aggregated posterior is schematically depicted in Fig. 5.5. Eventually, we obtain two terms:\n",
    "\n",
    "1. The first term, $ \\text{CE}(q_\\phi(z) || p_\\lambda(z)) $, is the **cross-entropy** between the aggregated posterior and the prior.\n",
    "2. The second term, $ H(q_\\phi(z|x)) $, is the **conditional entropy** of $ q_\\phi(z|x) $ with the empirical distribution $ p_{\\text{data}}(x) $.\n",
    "\n",
    "I highly recommend doing this derivation step by step, as it helps a lot in understanding what is going on here. Interestingly, there is another possibility to rewrite $ \\Omega $ using three terms, with the **total correlation** [51]. We will not use it here, so it is left as a \"homework.\" Anyway, one may ask, why is it useful to rewrite the ELBO? The answer is rather straightforward: We can analyze it from a different perspective! In this section, we will focus on the prior, an important component in the generative part that is very often neglected. Many Bayesianists argue that a prior should not be learned, but VAEs are not Bayesian models, so who says we cannot learn the prior? As we will see shortly, a non-learnable prior could be quite problematic, especially for the generation process.\n",
    "\n",
    "\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "Fig.5 An example of the aggregated posterior. Individual points are encoded as Gaussians in the 2D latent space (magenta) and the mixture of variational posteriors (the aggregated posterior) is presented by contours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2533b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, MultivariateNormal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the encoder and decoder architectures (simplified for demonstration)\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        mean = self.fc2_mean(h)\n",
    "        logvar = self.fc2_logvar(h)\n",
    "        return mean, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = torch.relu(self.fc1(z))\n",
    "        output = torch.sigmoid(self.fc2(h))  # assuming binary data for simplicity\n",
    "        return output\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decoder(z), mean, logvar\n",
    "\n",
    "# Define the loss function (ELBO)\n",
    "def loss_function(recon_x, x, mean, logvar):\n",
    "    # Reconstruction term (RE)\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # Regularization term (Ω)\n",
    "    # Using a standard normal prior\n",
    "    p_lambda_z = Normal(torch.zeros_like(mean), torch.ones_like(mean))\n",
    "    q_phi_z = Normal(mean, torch.exp(0.5 * logvar))\n",
    "    \n",
    "    # Cross-entropy (CE) between the aggregated posterior and prior\n",
    "    # We use the KL divergence as a regularizer in VAEs\n",
    "    # The formula for the KL divergence is:\n",
    "    # D_KL(q(z|x) || p(z)) = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # Where sigma is the std deviation and mu is the mean of the posterior q(z|x)\n",
    "    # In this case, we assume p(z) is a standard normal (mean 0, variance 1)\n",
    "    \n",
    "    # KL divergence term\n",
    "    KL_divergence = torch.sum(0.5 * (torch.exp(logvar) + mean**2 - 1 - logvar))\n",
    "    \n",
    "    # Total loss = Reconstruction + KL divergence\n",
    "    return BCE + KL_divergence\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 784  # Example for MNIST (28x28)\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Set up the model, optimizer\n",
    "model = VAE(input_dim, hidden_dim, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Dummy data loader (Replace with actual dataset loading code)\n",
    "# For example, use MNIST data here\n",
    "# Assuming data is already flattened to (batch_size, 784) for MNIST\n",
    "# data_loader = ...\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):  # Replace with actual data loader\n",
    "        data = data.view(-1, input_dim)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        recon_batch, mean, logvar = model(data)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(recon_batch, data, mean, logvar)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch}, Average Loss: {train_loss / len(data_loader.dataset)}\")\n",
    "\n",
    "# To visualize the aggregated posterior, we can plot the distribution\n",
    "# Example for 2D latent space visualization\n",
    "z_samples = mean.detach().cpu().numpy()\n",
    "plt.scatter(z_samples[:, 0], z_samples[:, 1], alpha=0.5)\n",
    "plt.title('Aggregated Posterior in 2D Latent Space')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the architecture of the Encoder and Decoder networks\n",
    "def encoder(x, weights1, bias1, weights2, bias2, weights3, bias3):\n",
    "    \"\"\" Encoder Network: z_mean, z_logvar \"\"\"\n",
    "    h = np.tanh(np.dot(x, weights1) + bias1)  # First layer with tanh activation\n",
    "    z_mean = np.dot(h, weights2) + bias2     # Mean of the latent space\n",
    "    z_logvar = np.dot(h, weights3) + bias3   # Log variance of the latent space\n",
    "    return z_mean, z_logvar\n",
    "\n",
    "def decoder(z, weights1, bias1, weights2, bias2):\n",
    "    \"\"\" Decoder Network: Reconstruct the input data \"\"\"\n",
    "    h = np.tanh(np.dot(z, weights1) + bias1)  # First layer with tanh activation\n",
    "    x_reconstructed = np.dot(h, weights2) + bias2  # Output layer\n",
    "    return x_reconstructed\n",
    "\n",
    "def reparameterize(z_mean, z_logvar):\n",
    "    \"\"\" Reparameterization Trick to sample from q(z|x) \"\"\"\n",
    "    epsilon = np.random.randn(*z_mean.shape)  # Random noise from standard normal\n",
    "    z = z_mean + np.exp(0.5 * z_logvar) * epsilon  # Sample z\n",
    "    return z\n",
    "\n",
    "# Loss function (ELBO)\n",
    "def loss_function(x, x_reconstructed, z_mean, z_logvar):\n",
    "    \"\"\" Compute the ELBO loss: reconstruction error + KL divergence \"\"\"\n",
    "    # Reconstruction error (binary cross entropy)\n",
    "    recon_loss = np.sum((x - x_reconstructed) ** 2)\n",
    "\n",
    "    # KL divergence\n",
    "    kl_div = -0.5 * np.sum(1 + z_logvar - z_mean**2 - np.exp(z_logvar))\n",
    "\n",
    "    # Total loss\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "# Initialize network weights and biases\n",
    "input_dim = 784  # Example: MNIST data (28x28 images flattened)\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "output_dim = input_dim\n",
    "\n",
    "# Encoder weights and biases\n",
    "weights1_enc = np.random.randn(input_dim, hidden_dim) * 0.01\n",
    "bias1_enc = np.zeros(hidden_dim)\n",
    "weights2_enc = np.random.randn(hidden_dim, latent_dim) * 0.01\n",
    "bias2_enc = np.zeros(latent_dim)\n",
    "weights3_enc = np.random.randn(hidden_dim, latent_dim) * 0.01\n",
    "bias3_enc = np.zeros(latent_dim)\n",
    "\n",
    "# Decoder weights and biases\n",
    "weights1_dec = np.random.randn(latent_dim, hidden_dim) * 0.01\n",
    "bias1_dec = np.zeros(hidden_dim)\n",
    "weights2_dec = np.random.randn(hidden_dim, output_dim) * 0.01\n",
    "bias2_dec = np.zeros(output_dim)\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Dummy data (replace with real dataset, e.g., MNIST flattened images)\n",
    "# x_data is a batch of flattened images, size [batch_size, input_dim]\n",
    "x_data = np.random.randn(batch_size, input_dim)  # Random data for now\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(batch_size):  # Simulate a batch for training\n",
    "        x = x_data[i]  # Sample a single data point\n",
    "        \n",
    "        # Forward pass: Encoder\n",
    "        z_mean, z_logvar = encoder(x, weights1_enc, bias1_enc, weights2_enc, bias2_enc, weights3_enc, bias3_enc)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        z = reparameterize(z_mean, z_logvar)\n",
    "        \n",
    "        # Forward pass: Decoder\n",
    "        x_reconstructed = decoder(z, weights1_dec, bias1_dec, weights2_dec, bias2_dec)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(x, x_reconstructed, z_mean, z_logvar)\n",
    "        total_loss += loss\n",
    "        \n",
    "        # Backpropagation (gradient descent, simplified version)\n",
    "        # Compute gradients (manually for simplicity)\n",
    "        # Note: Here we would typically use backpropagation, but we'll skip it\n",
    "        # to keep things simple without frameworks like PyTorch\n",
    "\n",
    "        # Update parameters (gradient descent)\n",
    "        weights1_enc -= learning_rate * np.dot(x[:, None], (z_mean - x_reconstructed))  # Simplified update\n",
    "        bias1_enc -= learning_rate * np.sum(z_mean - x_reconstructed)\n",
    "        \n",
    "        # Add similar updates for the other weights and biases...\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Total Loss: {total_loss / batch_size}')\n",
    "    \n",
    "# Visualize aggregated posterior (assuming 2D latent space)\n",
    "# For demonstration, let's assume z_mean is 2D\n",
    "z_samples = np.random.randn(batch_size, 2)  # Placeholder, replace with real latents\n",
    "plt.scatter(z_samples[:, 0], z_samples[:, 1])\n",
    "plt.title('Aggregated Posterior in Latent Space')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Basic activation function: Tanh\n",
    "def tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "# Dot product function\n",
    "def dot_product(vec1, vec2):\n",
    "    return sum(a * b for a, b in zip(vec1, vec2))\n",
    "\n",
    "# Matrix multiplication (for layer transformation)\n",
    "def matmul(A, B):\n",
    "    # A is an m x n matrix, B is an n x p matrix\n",
    "    # Result will be an m x p matrix\n",
    "    result = []\n",
    "    for row in A:\n",
    "        result_row = []\n",
    "        for col in zip(*B):\n",
    "            result_row.append(dot_product(row, col))\n",
    "        result.append(result_row)\n",
    "    return result\n",
    "\n",
    "# Encoder Network: computes z_mean, z_logvar\n",
    "def encoder(x, weights1, bias1, weights2, bias2, weights3, bias3):\n",
    "    h = [tanh(dot_product(x, w) + b) for w, b in zip(weights1, bias1)]\n",
    "    z_mean = [dot_product(h, w) + b for w, b in zip(weights2, bias2)]\n",
    "    z_logvar = [dot_product(h, w) + b for w, b in zip(weights3, bias3)]\n",
    "    return z_mean, z_logvar\n",
    "\n",
    "# Decoder Network: reconstructs the input\n",
    "def decoder(z, weights1, bias1, weights2, bias2):\n",
    "    h = [tanh(dot_product(z, w) + b) for w, b in zip(weights1, bias1)]\n",
    "    x_reconstructed = [dot_product(h, w) + b for w, b in zip(weights2, bias2)]\n",
    "    return x_reconstructed\n",
    "\n",
    "# Reparameterization trick: sample from q(z|x)\n",
    "def reparameterize(z_mean, z_logvar):\n",
    "    epsilon = [random.gauss(0, 1) for _ in range(len(z_mean))]\n",
    "    return [z_m + math.exp(0.5 * z_lv) * e for z_m, z_lv, e in zip(z_mean, z_logvar, epsilon)]\n",
    "\n",
    "# Compute the loss function (ELBO)\n",
    "def loss_function(x, x_reconstructed, z_mean, z_logvar):\n",
    "    # Reconstruction error (mean squared error)\n",
    "    recon_loss = sum((xi - x_reconstructed[i]) ** 2 for i, xi in enumerate(x))\n",
    "    \n",
    "    # KL divergence\n",
    "    kl_div = -0.5 * sum(1 + z_lv - z_m**2 - math.exp(z_lv) for z_m, z_lv in zip(z_mean, z_logvar))\n",
    "    \n",
    "    # Total loss (ELBO)\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "# Initialize network weights and biases\n",
    "input_dim = 784  # Example: MNIST data (28x28 images flattened)\n",
    "hidden_dim = 400\n",
    "latent_dim = 20\n",
    "output_dim = input_dim\n",
    "\n",
    "# Encoder weights and biases (random initialization)\n",
    "weights1_enc = [[random.gauss(0, 0.01) for _ in range(input_dim)] for _ in range(hidden_dim)]\n",
    "bias1_enc = [random.gauss(0, 0.01) for _ in range(hidden_dim)]\n",
    "weights2_enc = [[random.gauss(0, 0.01) for _ in range(hidden_dim)] for _ in range(latent_dim)]\n",
    "bias2_enc = [random.gauss(0, 0.01) for _ in range(latent_dim)]\n",
    "weights3_enc = [[random.gauss(0, 0.01) for _ in range(hidden_dim)] for _ in range(latent_dim)]\n",
    "bias3_enc = [random.gauss(0, 0.01) for _ in range(latent_dim)]\n",
    "\n",
    "# Decoder weights and biases (random initialization)\n",
    "weights1_dec = [[random.gauss(0, 0.01) for _ in range(latent_dim)] for _ in range(hidden_dim)]\n",
    "bias1_dec = [random.gauss(0, 0.01) for _ in range(hidden_dim)]\n",
    "weights2_dec = [[random.gauss(0, 0.01) for _ in range(hidden_dim)] for _ in range(output_dim)]\n",
    "bias2_dec = [random.gauss(0, 0.01) for _ in range(output_dim)]\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Dummy data (replace with real dataset)\n",
    "x_data = [[random.gauss(0, 1) for _ in range(input_dim)] for _ in range(batch_size)]\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        x = x_data[i]\n",
    "        \n",
    "        # Forward pass: Encoder\n",
    "        z_mean, z_logvar = encoder(x, weights1_enc, bias1_enc, weights2_enc, bias2_enc, weights3_enc, bias3_enc)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        z = reparameterize(z_mean, z_logvar)\n",
    "        \n",
    "        # Forward pass: Decoder\n",
    "        x_reconstructed = decoder(z, weights1_dec, bias1_dec, weights2_dec, bias2_dec)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(x, x_reconstructed, z_mean, z_logvar)\n",
    "        total_loss += loss\n",
    "        \n",
    "        # Backpropagation (manual gradient updates are omitted for simplicity)\n",
    "        # In a real implementation, we'd compute gradients and update weights here\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Total Loss: {total_loss / batch_size}')\n",
    "    \n",
    "# Example visualization: Random latent samples\n",
    "latent_samples = [[random.gauss(0, 1) for _ in range(2)] for _ in range(batch_size)]  # Example 2D latent space\n",
    "plt.scatter([z[0] for z in latent_samples], [z[1] for z in latent_samples])\n",
    "plt.title('Aggregated Posterior in Latent Space')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5fb5a97d",
   "metadata": {},
   "source": [
    "###  What Does the ELBO Tell Us About the Prior?\n",
    "\n",
    "We know that the regularization term $ \\Omega $ consists of two parts: cross-entropy and entropy. Let's first focus on the entropy term, since it is easier to analyze.\n",
    "\n",
    "When optimizing, we want to maximize the ELBO, so we aim to maximize the entropy:\n",
    "\n",
    "$$ H(q_{\\phi}(z|x)) = - \\mathbb{E}_{q_{\\phi}(z|x_n)}[\\ln q_{\\phi}(z|x_n)] $$\n",
    "\n",
    "This is equivalent to:\n",
    "\n",
    "$$ \\frac{1}{N} \\sum_{n=1}^{N} \\int q_{\\phi}(z|x_n) \\ln q_{\\phi}(z|x_n) \\, dz $$\n",
    "\n",
    "We assume that we are using Gaussian encoders, i.e., $ q_{\\phi}(z|x) = \\mathcal{N}(z; \\mu(x), \\sigma^2(x)) $. The entropy of a Gaussian distribution with a diagonal covariance matrix is:\n",
    "\n",
    "$$ H(q_{\\phi}(z|x)) = \\frac{1}{2} \\sum_i \\ln(2\\pi e \\sigma_i^2) $$\n",
    "\n",
    "Now, the question arises: when is this entropy maximized?\n",
    "\n",
    "The answer is simple: **$ \\sigma_i^2 \\to +\\infty $**. In other words, the entropy tries to stretch the encoders as much as possible by enlarging their variances. However, this doesn't happen in practice, because the decoder works in conjunction with the encoder in the reconstruction error (RE) term. The decoder forces the encoder to be peaked, aiming for a one-to-one mapping from $ x $ to $ z $, much like in a non-stochastic autoencoder.\n",
    "\n",
    "#### Cross-Entropy Term:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.6 An example of the eﬀect of the cross-entropy optimization with a non-learnable prior. The aggregated posterior (purple contours) tries to match the non-learnable prior (in blue). The purple arrows indicate the change of the aggregated posterior. An example of a hole is presented as a dark gray ellipse.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Fig.7 An example of the eﬀect of the cross-entropy optimization with a learnable prior. The aggregated posterior (purple contours) tries to match the learnable prior (blue contours). Notice that the aggregated posterior is modiﬁed to ﬁt the prior (purple arrows), but also the prior is updated to cover the aggregated posterior (orange arrows).\n",
    "\n",
    "The second part of $ \\Omega $ is the cross-entropy:\n",
    "\n",
    "$$ \\text{CE}(q_{\\phi}(z) \\parallel p_{\\lambda}(z)) = - \\mathbb{E}_{q_{\\phi}(z)}[\\ln p_{\\lambda}(z)] $$\n",
    "\n",
    "This cross-entropy term influences the VAE differently. To interpret this, we can ask: *How can we understand the cross-entropy between $ q_{\\phi}(z) $ and $ p_{\\lambda}(z) $?*\n",
    "\n",
    "In general, the cross-entropy tells us the average number of bits (or nats, since we use the natural logarithm) needed to identify an event drawn from $ q_{\\phi}(z) $, when using a coding scheme based on $ p_{\\lambda}(z) $. Since we aim to maximize the ELBO, the negative cross-entropy pushes us to minimize the divergence between $ q_{\\phi}(z) $ and $ p_{\\lambda}(z) $. In other words, we want $ q_{\\phi}(z) $ to match $ p_{\\lambda}(z) $.\n",
    "\n",
    "But why is this important? The cross-entropy forces the aggregated posterior to match the prior. This is the key observation, as the prior $ p_{\\lambda}(z) $ acts like an anchor for the posterior distribution $ q_{\\phi}(z) $.\n",
    "\n",
    "#### What Happens with a Non-Learnable Prior?\n",
    "\n",
    "If the prior is fixed (non-learnable), say a standard Gaussian prior, then optimizing the cross-entropy term forces the aggregated posterior to match this fixed prior. The process can be visualized as follows:\n",
    "\n",
    "1. The aggregated posterior (purple contours) tries to match the non-learnable prior (in blue). \n",
    "2. The aggregated posterior adapts (indicated by the purple arrows) to fit the prior.\n",
    "\n",
    "However, this optimization can be problematic because the decoder forces the encoder to be peaked, making it nearly impossible to match the fixed-shaped prior perfectly. As a result, \"holes\" can appear in the latent space—regions where the aggregated posterior assigns low probability, while the prior assigns relatively high probability (as shown by the dark gray ellipse).\n",
    "\n",
    "This issue becomes especially problematic in generation tasks, as sampling from the prior in these \"holes\" may result in low-quality samples.\n",
    "\n",
    "#### What Happens with a Learnable Prior?\n",
    "\n",
    "If the prior is learnable, the optimization allows both the aggregated posterior and the prior to adapt. Both distributions try to match each other, as shown below:\n",
    "\n",
    "1. The aggregated posterior (purple contours) adjusts to match the learnable prior (blue contours).\n",
    "2. The prior is also updated to cover the aggregated posterior (indicated by the orange arrows).\n",
    "\n",
    "With a learnable prior, the issue of holes is less prominent, especially if the prior is flexible enough. However, other optimization challenges may arise, as both the prior and posterior chase each other during training.\n",
    "\n",
    "In practice, using a learnable prior seems to be a better approach, though it remains an open question whether training all components at once is the best solution. Additionally, the learnable prior does not impose specific constraints on the latent space representation, such as sparsity. This could result in undesirable problems, such as non-smooth encoders.\n",
    "\n",
    "#### What Is the Best Prior?\n",
    "\n",
    "The ultimate question is: What is the best prior?\n",
    "\n",
    "The answer is hidden in the cross-entropy term. The best prior is actually the **aggregated posterior**:\n",
    "\n",
    "$$ p_{\\lambda}(z) = \\frac{1}{N} \\sum_{n=1}^{N} q_{\\phi}(z|x_n) $$\n",
    "\n",
    "If we set the prior to be equal to the aggregated posterior, the cross-entropy term becomes the entropy of the posterior, and the regularization term \\( \\Omega \\) becomes minimal. However, this is generally infeasible because:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Define a basic Gaussian entropy calculation\n",
    "def gaussian_entropy(mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a Gaussian distribution with diagonal covariance matrix.\n",
    "    \n",
    "    Args:\n",
    "    - mu: Mean of the Gaussian (size of latent space)\n",
    "    - sigma: Standard deviation (size of latent space)\n",
    "\n",
    "    Returns:\n",
    "    - entropy: The entropy of the Gaussian distribution\n",
    "    \"\"\"\n",
    "    # Entropy of Gaussian with diagonal covariance: 1/2 * sum(ln(2 * pi * e * sigma^2))\n",
    "    entropy = 0.5 * sum([math.log(2 * math.pi * math.e * s**2) for s in sigma])\n",
    "    return entropy\n",
    "\n",
    "# Reconstruction Error (RE): sum of log-likelihood p(x|z)\n",
    "def reconstruction_error(x, z, model_decoder):\n",
    "    \"\"\"\n",
    "    Calculate the reconstruction error term of ELBO.\n",
    "    \n",
    "    Args:\n",
    "    - x: The input data\n",
    "    - z: Latent variables\n",
    "    - model_decoder: Function to decode z back to x (decoder network)\n",
    "    \n",
    "    Returns:\n",
    "    - RE: Reconstruction error\n",
    "    \"\"\"\n",
    "    reconstructed_x = model_decoder(z)  # decoded output for given z\n",
    "    # Assuming Gaussian likelihood, we calculate the negative log likelihood\n",
    "    # Assuming simple MSE for reconstruction\n",
    "    mse = sum((x_i - rec_x_i)**2 for x_i, rec_x_i in zip(x, reconstructed_x))\n",
    "    return mse\n",
    "\n",
    "# Cross-entropy between q(z) and p(z)\n",
    "def cross_entropy(q_phi_z, p_lambda_z):\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy between the aggregated posterior q(z) and the prior p(z).\n",
    "    \n",
    "    Args:\n",
    "    - q_phi_z: The aggregated posterior q(z) (mean of all latent variables)\n",
    "    - p_lambda_z: The prior p(z) (assumed to be Gaussian for simplicity)\n",
    "    \n",
    "    Returns:\n",
    "    - CE: Cross-entropy term\n",
    "    \"\"\"\n",
    "    cross_entropy_value = -sum(q * math.log(p) for q, p in zip(q_phi_z, p_lambda_z))\n",
    "    return cross_entropy_value\n",
    "\n",
    "# Implementing a simple model for the decoder (this should be replaced with your own model)\n",
    "def simple_decoder(z):\n",
    "    \"\"\"\n",
    "    A simple placeholder decoder function that mimics a reconstruction from z.\n",
    "    \"\"\"\n",
    "    return z  # In real-world cases, replace this with an actual decoder model\n",
    "\n",
    "# Define a sample latent space (for simplicity)\n",
    "latent_dim = 3\n",
    "sigma = [1.0] * latent_dim  # Simple standard deviation for each latent dimension\n",
    "mu = [0.0] * latent_dim     # Simple mean (zero) for each latent dimension\n",
    "\n",
    "# Example data\n",
    "x = [1.0, 2.0, 3.0]  # Example input data\n",
    "\n",
    "# Assume some random latent variables\n",
    "z = [0.1, 0.2, 0.3]  # Example latent vector\n",
    "\n",
    "# Calculate the entropy of the posterior q(z|x) (simple Gaussian)\n",
    "entropy_value = gaussian_entropy(mu, sigma)\n",
    "\n",
    "# Calculate the reconstruction error (RE) using a simple decoder model\n",
    "reconstruction_error_value = reconstruction_error(x, z, simple_decoder)\n",
    "\n",
    "# Assume an aggregated posterior q(z) (mean over all training samples)\n",
    "aggregated_posterior_q = [0.1, 0.1, 0.1]  # Example\n",
    "\n",
    "# Assume a prior p(z) (standard Gaussian prior)\n",
    "prior_p = [0.33, 0.33, 0.33]  # Example (normalized for simplicity)\n",
    "\n",
    "# Calculate cross-entropy term between q(z) and p(z)\n",
    "cross_entropy_value = cross_entropy(aggregated_posterior_q, prior_p)\n",
    "\n",
    "# Combine to form the full ELBO regularization term (Ω)\n",
    "Omega_value = entropy_value + cross_entropy_value\n",
    "\n",
    "# Print all calculated terms\n",
    "print(f\"Entropy: {entropy_value}\")\n",
    "print(f\"Reconstruction Error: {reconstruction_error_value}\")\n",
    "print(f\"Cross-Entropy: {cross_entropy_value}\")\n",
    "print(f\"Omega (Regularization term): {Omega_value}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
